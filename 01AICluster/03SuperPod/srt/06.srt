1
00:00:00,000 --> 00:00:01,883
内容/录制:Z0MI 酱，视频剪辑/字幕:梁嘉铭

2
00:00:02,000 --> 00:00:02,683
哈喽大家好

3
00:00:02,683 --> 00:00:03,533
我是 ZOMI

4
00:00:03,533 --> 00:00:04,600
今天我们来到了

5
00:00:04,600 --> 00:00:06,800
这一个系列里面的最后一个内容了

6
00:00:06,800 --> 00:00:09,800
看一下 10 万卡集群的一个整体的思考

7
00:00:10,050 --> 00:00:11,400
其实关于思考这方面

8
00:00:11,400 --> 00:00:12,733
ZOMI 最近有一个疑惑

9
00:00:12,733 --> 00:00:13,966
就是为什么新葡京

10
00:00:13,966 --> 00:00:16,600
总会给我这种喜欢看盗版的人

11
00:00:16,600 --> 00:00:17,333
打广告

12
00:00:22,766 --> 00:00:24,366
那回到我们这个系列里面

13
00:00:24,366 --> 00:00:26,800
我们主要是在上一期视频里

14
00:00:26,800 --> 00:00:28,600
我们最后其实遗留了一个问题

15
00:00:28,600 --> 00:00:30,250
就是构建入 10 万卡的机器

16
00:00:30,250 --> 00:00:33,200
说实话它是一个非常复杂的系统工程

17
00:00:33,200 --> 00:00:34,966
那这里面就有三个点

18
00:00:34,966 --> 00:00:35,366
第一点

19
00:00:35,366 --> 00:00:35,733
就是

20
00:00:35,733 --> 00:00:37,533
不仅意味着我们的算力的指数增长

21
00:00:37,533 --> 00:00:40,483
还会涉及到非常复杂的技术

22
00:00:40,483 --> 00:00:41,933
和运维的挑战

23
00:00:41,933 --> 00:00:43,333
其实你运维这两个字

24
00:00:43,333 --> 00:00:44,533
ZOMI 觉得更核心

25
00:00:44,533 --> 00:00:44,850
另外他

26
00:00:44,850 --> 00:00:48,133
我们需要解决各种各样的三高

27
00:00:48,200 --> 00:00:50,200
虽然 ZOMI 已经上年纪了

28
00:00:50,200 --> 00:00:51,050
已经有三高了

29
00:00:51,050 --> 00:00:52,133
但是这里面的三高

30
00:00:52,133 --> 00:00:54,083
主要是指高能耗的计算

31
00:00:54,083 --> 00:00:56,133
高能耗的管理和高能耗的密度

32
00:00:56,133 --> 00:00:57,650
高密度的一个计划的事情

33
00:00:57,650 --> 00:01:00,533
和高稳定性等一系列的问题

34
00:01:00,533 --> 00:01:02,933
ZOMI 的高血压高血糖高脂肪

35
00:01:03,200 --> 00:01:05,800
觉得这是一个很难解决的问题

36
00:01:05,800 --> 00:01:08,166
那面前的 10 万卡集群能不能解决

37
00:01:08,400 --> 00:01:09,600
那另外的话还有第三个点

38
00:01:09,600 --> 00:01:11,850
就是怎么去有效的去释放

39
00:01:11,933 --> 00:01:13,566
整体的软件的能力

40
00:01:13,566 --> 00:01:14,850
和我们澎湃的算力了

41
00:01:14,850 --> 00:01:16,566
这里面取决于我们的软件算法

42
00:01:16,566 --> 00:01:17,766
整体的调和能力

43
00:01:17,766 --> 00:01:20,366
因此今天我们的整体目录

44
00:01:20,366 --> 00:01:21,333
会分开几个内容

45
00:01:21,333 --> 00:01:23,450
跟大家一起去畅聊一些点

46
00:01:23,450 --> 00:01:23,733
当然

47
00:01:23,733 --> 00:01:25,600
证明所谓的畅聊只有钟一个人

48
00:01:25,600 --> 00:01:27,333
在唱单*簧

49
00:01:27,333 --> 00:01:28,050
那这里面

50
00:01:28,050 --> 00:01:30,133
可能会重点看四个内容

51
00:01:30,133 --> 00:01:30,450
第一个

52
00:01:30,450 --> 00:01:32,400
我们看一下整 10 万卡的集群

53
00:01:32,400 --> 00:01:33,766
都在训什么

54
00:01:33,766 --> 00:01:35,650
大家都用 10 万卡集群训啥

55
00:01:35,650 --> 00:01:35,966
第二个

56
00:01:35,966 --> 00:01:37,083
我们会一下看一下

57
00:01:37,083 --> 00:01:38,533
现在比较大的一个问题

58
00:01:38,533 --> 00:01:39,566
就是功耗的问题

59
00:01:39,566 --> 00:01:40,200
互联的问题

60
00:01:40,200 --> 00:01:41,566
还有可靠性的问题

61
00:01:41,566 --> 00:01:42,733
我们分开这 4 个点

62
00:01:42,733 --> 00:01:43,766
进行一个展开

63
00:01:45,133 --> 00:01:46,533
我们现在马上来到了第一个内容

64
00:01:46,533 --> 00:01:47,883
看一下整个 10 万卡集群

65
00:01:47,883 --> 00:01:49,733
都在训哪些东西

66
00:01:49,733 --> 00:01:52,600
说实话现在我们搞清楚在训什么

67
00:01:52,600 --> 00:01:54,483
我们先搞清楚谁在建

68
00:01:54,733 --> 00:01:56,566
那现在的大型的 AI 实验室

69
00:01:56,566 --> 00:01:57,683
在国外主要是 OpenAI

70
00:01:57,683 --> 00:01:58,533
微软 xai

71
00:01:58,533 --> 00:02:00,733
Mate 包括国内的字节

72
00:02:00,733 --> 00:02:03,600
都在竞相的去建一个 10 万卡的集群

73
00:02:03,600 --> 00:02:05,566
那国内可能没有几家

74
00:02:05,566 --> 00:02:07,166
可能真的在建 10 万卡的了

75
00:02:07,166 --> 00:02:08,000
现在太少了

76
00:02:08,050 --> 00:02:09,683
万卡倒是蛮多

77
00:02:09,683 --> 00:02:11,133
那建这些万卡的集群

78
00:02:11,133 --> 00:02:12,650
或者 10 万卡的集群有什么任务

79
00:02:12,850 --> 00:02:14,283
主要去利用海量的数据

80
00:02:14,283 --> 00:02:15,800
去训练多模态的数据

81
00:02:15,800 --> 00:02:17,566
或者多模态的大模型

82
00:02:17,566 --> 00:02:19,800
但这些已经不是业界的秘密了

83
00:02:19,800 --> 00:02:22,333
那虽然现在已经或者现在没有团队

84
00:02:22,333 --> 00:02:24,133
真正的去完成这个多模态

85
00:02:24,133 --> 00:02:25,250
大模型真正训练

86
00:02:25,250 --> 00:02:26,533
或者所谓的世界模型

87
00:02:26,533 --> 00:02:29,083
不过这个领域已经非常的激烈了

88
00:02:29,083 --> 00:02:30,566
只有头部的玩家在做

89
00:02:30,883 --> 00:02:31,333
那另外的话

90
00:02:31,333 --> 00:02:32,850
我们看一下整体的算列对比

91
00:02:32,850 --> 00:02:34,533
对比这里面还是蛮有意思

92
00:02:34,533 --> 00:02:37,850
证明拿了一个 GPT4 进行一个对比

93
00:02:37,850 --> 00:02:39,283
那所谓的 GPT4

94
00:02:39,283 --> 00:02:40,000
它实际上

95
00:02:40,000 --> 00:02:42,366
是在两年前发布的 OpenAI

96
00:02:42,366 --> 00:02:44,600
当时候用的是 2 万张 A100

97
00:02:44,600 --> 00:02:45,333
对 GPT4

98
00:02:45,333 --> 00:02:47,000
大概训了 3 个月左右的时间

99
00:02:47,000 --> 00:02:48,483
用的是 BF16 了

100
00:02:48,483 --> 00:02:50,166
然后算力的峰值吞吐

101
00:02:50,166 --> 00:02:52,900
是 6.28 ExaFLOP/s

102
00:02:52,900 --> 00:02:53,450
那现在

103
00:02:53,450 --> 00:02:56,400
大家都在建 10 万卡的 H100 集群

104
00:02:56,400 --> 00:02:57,683
整体的峰值算力

105
00:02:57,683 --> 00:03:01,650
跟当年 OpenAI 发布的 GPT4 相比

106
00:03:01,650 --> 00:03:04,966
已经提升了可能 30 多倍了

107
00:03:04,966 --> 00:03:05,850
那这里面

108
00:03:05,850 --> 00:03:07,800
小新就有一个问题了

109
00:03:08,050 --> 00:03:08,533
现在

110
00:03:08,533 --> 00:03:11,566
我们都已经见到 10 万卡的 H100 集群了

111
00:03:11,566 --> 00:03:13,283
为什么到现在为止

112
00:03:13,483 --> 00:03:16,733
都没有一个出现超过 GPT4 的模型

113
00:03:17,366 --> 00:03:18,766
这个问题还蛮有意思

114
00:03:18,766 --> 00:03:20,733
我们还得好好想想

115
00:03:20,733 --> 00:03:21,483
大模型训练

116
00:03:21,483 --> 00:03:23,533
是不是堆算力就能解决问题

117
00:03:23,600 --> 00:03:24,883
很明显不是

118
00:03:24,966 --> 00:03:27,000
但是如果不堆算力

119
00:03:27,200 --> 00:03:29,250
绝对是解决不了问题

120
00:03:29,400 --> 00:03:30,800
所以说大模型训练

121
00:03:30,800 --> 00:03:31,566
除了算力以外

122
00:03:31,566 --> 00:03:32,966
还有很多的内容

123
00:03:32,966 --> 00:03:34,200
我们在软件层面

124
00:03:34,200 --> 00:03:35,483
或者算法层面

125
00:03:35,483 --> 00:03:37,483
会跟大家分享很多相关的知识

126
00:03:37,650 --> 00:03:38,450
这期视频

127
00:03:38,450 --> 00:03:41,083
主要是跟大家分享底下的硬件

128
00:03:41,083 --> 00:03:42,200
或者算力的问题

129
00:03:42,250 --> 00:03:44,366
那针对单算力的性能提升

130
00:03:44,366 --> 00:03:46,600
其实现在业界有一些新的做法

131
00:03:46,600 --> 00:03:49,250
例如现在的研发的单 GPU 或者 NPU

132
00:03:49,250 --> 00:03:51,450
及时提供更多的并行的处理

133
00:03:51,450 --> 00:03:52,366
核心的能力

134
00:03:52,483 --> 00:03:54,283
而去提高我们运行的频率

135
00:03:54,283 --> 00:03:55,400
和运行的效率

136
00:03:55,400 --> 00:03:55,883
那这个

137
00:03:55,883 --> 00:03:57,200
是单芯片的能力

138
00:03:57,200 --> 00:03:57,800
另外的话

139
00:03:57,800 --> 00:03:58,933
现在做大模型

140
00:03:58,933 --> 00:04:00,600
说实话里面对 HBM

141
00:04:00,600 --> 00:04:01,733
或者对我们的显存

142 
00:04:01,733 --> 00:04:04,400
和高态化的缓存的要求非常的高

143
00:04:04,400 --> 00:04:06,566
因此为了减少我们 GPU 的显存

144
00:04:06,566 --> 00:04:07,933
或者访存的延迟

145
00:04:08,166 --> 00:04:10,250
越来越多的近存的计算的架构

146
00:04:10,250 --> 00:04:10,766
出现了

147
00:04:10,766 --> 00:04:13,133
我们现在能看到的很多的创业的公司

148
00:04:13,133 --> 00:04:14,283
或者英国的 ImageCore

149
00:04:14,283 --> 00:04:16,450
也在做这种新的架构的尝试

150
00:04:16,450 --> 00:04:17,133
另外的话

151
00:04:17,133 --> 00:04:19,083
我们反观回来英伟达

152
00:04:19,083 --> 00:04:20,733
他也在做一些

153
00:04:20,733 --> 00:04:23,283
浮点数的表示的格式的优化探索

154
00:04:23,283 --> 00:04:24,600
从 FP16 到 FP8

155
00:04:24,600 --> 00:04:26,933
包括华为推出自己的 HIF8 的标准

156
00:04:26,933 --> 00:04:27,966
相关的数据格式

157
00:04:27,966 --> 00:04:29,800
引入更低精度

158
00:04:29,800 --> 00:04:32,200
或者更新的一个计算精度的格式

159
00:04:32,200 --> 00:04:33,733
那这个事情还是蛮有意思

160
00:04:33,733 --> 00:04:34,683
整个单芯片算力

161
00:04:34,683 --> 00:04:37,483
都在往这个三个方向去不断的发展

162
00:04:38,683 --> 00:04:39,133
那另外的话

163
00:04:39,133 --> 00:04:39,733
我们看一下

164
00:04:39,733 --> 00:04:40,933
刚才看完单芯片

165
00:04:40,933 --> 00:04:41,766
我们还是要看一下

166
00:04:41,766 --> 00:04:43,366
超节点的一个计算能力

167
00:04:43,366 --> 00:04:44,333
现在来看

168
00:04:44,333 --> 00:04:45,850
至于一个万卡集群

169
00:04:45,850 --> 00:04:47,083
其实我们很多时候

170
00:04:47,083 --> 00:04:48,450
会看一个综合的指标

171
00:04:48,450 --> 00:04:49,966
就是我们的网络的利用率

172
00:04:49,966 --> 00:04:51,766
那这个可能会用线性度来代替

173
00:04:51,766 --> 00:04:52,166
另外的话

174
00:04:52,166 --> 00:04:53,883
我们会看模型的利用率

175
00:04:53,966 --> 00:04:55,566
MFU 或者 HFU 了

176
00:04:55,566 --> 00:04:56,450
那 MFU

177
00:04:56,450 --> 00:04:59,450
就是 model 的一个整体的利用率

178
00:04:59,450 --> 00:05:01,883
HFU 就是 hardware 硬件的利用率

179
00:05:01,883 --> 00:05:03,933
为了使得我们两个利用率的提升了

180
00:05:03,933 --> 00:05:06,366
我们主要是做一些通讯的时间的减少 

181
00:05:06,366 --> 00:05:07,850
和带宽能力的跃升

182
00:05:07,850 --> 00:05:09,083
就是提升我们的带宽

183
00:05:09,083 --> 00:05:10,450
减少我们的通讯的时延

184
00:05:10,450 --> 00:05:12,200
来提升我们整体

185
00:05:12,200 --> 00:05:13,850
超节点的计算的能力

186
00:05:13,850 --> 00:05:14,483
那这里面

187
00:05:14,483 --> 00:05:16,283
其实业界有几种做法

188
00:05:16,283 --> 00:05:16,683
第一种

189
00:05:16,683 --> 00:05:18,600
就是推出一些类似于 NV switch 

190
00:05:18,600 --> 00:05:22,083
这种或者 NVLswitch 的相关的一些芯片

191
00:05:22,083 --> 00:05:23,400
提升我们南向

192
00:05:23,400 --> 00:05:25,850
或者我们的 scale up 的一个整体的能力

193
00:05:25,850 --> 00:05:26,366
第二点

194
00:05:26,366 --> 00:05:29,283
就是增加卡间的一个 P2P

195
00:05:29,283 --> 00:05:30,800
也就 P2P 的一个整体带宽

196
00:05:30,800 --> 00:05:32,200
提升节点的利用率

197
00:05:32,200 --> 00:05:34,883
特别是对于现在的一些多模态大模型

198
00:05:34,883 --> 00:05:36,600
还有 MOE 架构的大模型

199
00:05:36,600 --> 00:05:38,966
其实是很有性能的提升的点

200
00:05:39,133 --> 00:05:39,450
另外的话

201
00:05:39,450 --> 00:05:42,450
可能业界也在推出一些新的一些协议

202
00:05:42,450 --> 00:05:44,850
对我们整体系统的进行一些优化的重构

203
00:05:44,850 --> 00:05:45,050
例如

204
00:05:45,050 --> 00:05:47,166
华为现在就提出了自己的灵渠架构了

205
00:05:47,166 --> 00:05:48,133
还有 AMD 谷歌

206
00:05:48,133 --> 00:05:50,566
就组成了一个 UAlink 的相关的联盟

207
00:05:50,566 --> 00:05:52,883
对应提出相关的一些协议

208
00:05:53,050 --> 00:05:53,283
另外它

209
00:05:53,283 --> 00:05:55,933
我们还会发现有一些公司或厂商

210
00:05:55,933 --> 00:05:57,283
特别是中国的华三

211
00:05:57,283 --> 00:05:58,200
还有国外的博通

212
00:05:58,200 --> 00:06:00,000
都在重新设计一些

213
00:06:00,000 --> 00:06:01,450
卡间的数据报告的格式

214
00:06:01,450 --> 00:06:02,800
等于 CPU 和 NPU 了

215
00:06:02,800 --> 00:06:05,250
提升和优化我们的创新接口的速率

216
00:06:05,250 --> 00:06:06,483
优化整体网络拥塞

217
00:06:06,483 --> 00:06:09,533
控制和重传机制的一些相关的内容

218
00:06:10,050 --> 00:06:12,050
那讲完单芯片整个节点

219
00:06:12,050 --> 00:06:12,600
我们看一下

220
00:06:12,600 --> 00:06:15,200
整个网络的一个计算能力

221
00:06:15,200 --> 00:06:17,450
现在其实你会发现越来越多的 DPU

222
00:06:17,450 --> 00:06:19,450
之前前几年还会提 DPU

223
00:06:19,450 --> 00:06:22,050
后来可能 AI 起来的这一两年

224
00:06:22,050 --> 00:06:22,766
又少提了

225
00:06:22,766 --> 00:06:23,333
那最近

226
00:06:23,333 --> 00:06:24,366
我们又提起来了

227
00:06:24,366 --> 00:06:25,883
我们希望 DPU

228
00:06:25,883 --> 00:06:26,966
集成在我们的网卡里面

229
00:06:26,966 --> 00:06:28,483
通过 RDMA 的网络

230
00:06:28,483 --> 00:06:29,933
去连接我们的存储

231
00:06:29,933 --> 00:06:31,200
还有其他的对象

232
00:06:31,450 --> 00:06:33,966
等相关的一些额外的接口了

233
00:06:33,966 --> 00:06:34,366
另外的话

234
00:06:34,366 --> 00:06:35,933
我们还会通过多机多卡

235
00:06:35,933 --> 00:06:36,933
一个端到端的时延

236
00:06:36,933 --> 00:06:40,166
去降低然后提升我们整体的带宽

237
00:06:40,166 --> 00:06:42,283
和节点内的数据交互的一个速率

238
00:06:42,650 --> 00:06:43,083
另外的话

239
00:06:43,083 --> 00:06:45,083
我觉得 ZOMI 觉得很有意思的就一点

240
00:06:45,083 --> 00:06:48,766
就是我们要理解 AI 计算的场景流量的特点到底是怎么样

241
00:06:48,966 --> 00:06:50,683
那我们这里面做了一个简单的总结

242
00:06:50,683 --> 00:06:52,450
就说我们的流数是非常的少

243
00:06:52,450 --> 00:06:55,133
但是单流量是非常的大

244
00:06:55,133 --> 00:06:57,050
那面向这个计算场景的特点

245
00:06:57,050 --> 00:06:58,000
特别是大模型

246
00:06:58,000 --> 00:06:59,533
这里面仅仅指大模型

247
00:06:59,766 --> 00:07:01,933
整体的端口的负载的均衡的能力

248
00:07:01,933 --> 00:07:03,050
非常的重要

249
00:07:03,050 --> 00:07:05,683
另外同我们还要做一些算网的协同

250
00:07:05,683 --> 00:07:07,650
均衡负载的一些工作

251
00:07:07,650 --> 00:07:08,933
那这里面我们可以看到

252
00:07:08,933 --> 00:07:10,450
从网络当芯片的超级点

253
00:07:10,450 --> 00:07:12,133
它还是有很多相关的点

254
00:07:12,166 --> 00:07:12,850
除了这些点

255
00:07:12,850 --> 00:07:15,166
我们还有最后一个就是智能管控

256
00:07:15,166 --> 00:07:16,366
那所谓的智能管控

257
00:07:16,366 --> 00:07:18,050
主要是对我们的存算网

258
00:07:18,166 --> 00:07:19,800
光模块相关的资源

259
00:07:19,800 --> 00:07:21,483
进行一些打 log

260
00:07:21,483 --> 00:07:23,650
打日志等信息的一些收集

261
00:07:23,733 --> 00:07:25,733
然后做一些服务的编排

262
00:07:25,733 --> 00:07:27,533
监控还有作业的运维调度

263
00:07:27,533 --> 00:07:30,400
那说实话主要是监控我们的健康度

264
00:07:30,400 --> 00:07:31,000
那这些

265
00:07:31,000 --> 00:07:32,850
都是云化的一些基本能力

266
00:07:32,850 --> 00:07:34,600
但是可能以前的云

267
00:07:34,600 --> 00:07:35,650
没有做到那么细致

268
00:07:35,650 --> 00:07:38,200
只是对整个 CPU 进行或整个 CPU 集群

269
00:07:38,200 --> 00:07:39,450
进行一个整体的运维

270
00:07:39,766 --> 00:07:40,850
现在一单卡

271
00:07:40,966 --> 00:07:42,333
或者我们的一个节点里面

272
00:07:42,333 --> 00:07:43,083
有八张卡

273
00:07:43,083 --> 00:07:44,533
或者两个 CPU 大八张卡

274
00:07:44,533 --> 00:07:45,400
那这种情况

275
00:07:45,400 --> 00:07:46,600
对我们整体的运维

276
00:07:46,600 --> 00:07:48,050
或者云化的服务能力

277
00:07:48,050 --> 00:07:50,933
其实是有更多的新的要求

278
00:07:51,566 --> 00:07:52,450
太艰难了

279
00:07:52,450 --> 00:07:54,166
如果觉得 ZOMI 的语速太快

280
00:07:54,166 --> 00:07:55,566
那很 sorry

281
00:07:55,566 --> 00:07:56,533
很抱歉

282
00:07:56,533 --> 00:07:58,566
ZOMI 实在是对自己熟悉的内容

283
00:07:58,566 --> 00:08:00,800
可能会相对的语速比较快

284
00:08:00,800 --> 00:08:01,883
那我们现在来看看

285
00:08:01,883 --> 00:08:03,333
接下来的第二个问题了

286
00:08:03,533 --> 00:08:05,683
就是功耗的挑战

287
00:08:05,733 --> 00:08:06,250
那这里面

288
00:08:06,250 --> 00:08:06,883
我们还有意思

289
00:08:06,883 --> 00:08:08,600
就是看一下 10 万卡的 AI 集群

290
00:08:08,600 --> 00:08:10,800
整体的技术资本的支出

291
00:08:10,800 --> 00:08:12,133
已经非常的夸张了

292
00:08:12,133 --> 00:08:14,200
40 亿刀那整个 AI 集群里面

293
00:08:14,200 --> 00:08:16,050
我们其实还会运

294
00:08:16,050 --> 00:08:17,600
受限到整个 IDC 的功耗

295
00:08:17,600 --> 00:08:19,133
和电力不足的整体的影响

296
00:08:19,133 --> 00:08:21,250
所以之前有同事或者

297
00:08:21,250 --> 00:08:23,250
今年年初的时候还是有朋友说哎

298
00:08:23,250 --> 00:08:24,366
我们要不要买一点

299
00:08:24,400 --> 00:08:27,766
或者投资一点能源的一些美股

300
00:08:27,766 --> 00:08:30,333
说说还是有很多人去慢慢的去投资

301
00:08:30,333 --> 00:08:31,566
不过我觉得这些投资

302
00:08:31,566 --> 00:08:32,600
都是合理

303
00:08:33,083 --> 00:08:35,250
能源嘛大家都很缺

304
00:08:35,250 --> 00:08:38,283
那我们看一下整个耗电的整体的情况

305
00:08:38,366 --> 00:08:39,450
说实话你现在

306
00:08:39,450 --> 00:08:41,800
单个 GPU 或者单个 H100 或者 B100

307
00:08:41,800 --> 00:08:44,083
假设它的能耗为 700 瓦

308
00:08:44,133 --> 00:08:46,000
但是每一个 H100 的节点

309
00:08:46,000 --> 00:08:47,283
或者每一张卡里面

310
00:08:47,283 --> 00:08:48,133
我们还有 CPU

311
00:08:48,133 --> 00:08:48,733
还有网卡

312
00:08:48,733 --> 00:08:50,766
还有电源相关的装置

313
00:08:50,966 --> 00:08:52,250
或者相关额外的内容

314
00:08:52,250 --> 00:08:53,800
基本上消耗每张 CPU

315
00:08:53,800 --> 00:08:56,000
会额外增加 400-500 瓦

316
00:08:56,000 --> 00:08:57,400
那在节点内

317
00:08:57,400 --> 00:09:00,133
当当时候是讲我们现在来看节点外

318
00:09:00,133 --> 00:09:01,283
节点外我们整个 AI 集群

319
00:09:01,283 --> 00:09:02,450
还需要我们的存储的 port

320
00:09:02,450 --> 00:09:03,483
网络的交换机

321
00:09:03,533 --> 00:09:04,366
CPU 的 port

322
00:09:04,366 --> 00:09:05,250
CPU 的节点

323
00:09:05,250 --> 00:09:07,566
还有光模块和其他相关的设备

324
00:09:07,600 --> 00:09:08,600
总体的能耗

325
00:09:08,600 --> 00:09:11,250
是占到我们的整个 IDC 的 10%

326
00:09:11,450 --> 00:09:12,850
非常的夸张的说

327
00:09:12,850 --> 00:09:14,483
我们为什么要除了液冷以外

328
00:09:14,483 --> 00:09:15,766
我们要加上风冷了

329
00:09:15,766 --> 00:09:18,533
整个 AI 集群里面的不仅仅只能有液冷

330
00:09:18,533 --> 00:09:20,133
我们必须还是有风冷

331
00:09:20,133 --> 00:09:21,250
所以我们现在

332
00:09:21,483 --> 00:09:23,800
来建一个 10 万卡集群的时候

333
00:09:23,800 --> 00:09:24,566
基本上

334
00:09:24,566 --> 00:09:26,000
就不是指一个机房了

335
00:09:26,000 --> 00:09:27,366
而是指一片园区了

336
00:09:27,366 --> 00:09:29,366
也不是单栋楼能够做

337
00:09:29,366 --> 00:09:30,966
特斯拉的 xAI

338
00:09:30,966 --> 00:09:32,133
或者马斯克的 xAI

339
00:09:32,133 --> 00:09:34,166
主要是基于孟菲斯的一个旧工厂

340
00:09:34,166 --> 00:09:35,850
来改造成为智算中心

341
00:09:35,850 --> 00:09:37,883
它里面是一个大的园区

342
00:09:37,883 --> 00:09:39,050
里面有四栋大楼

343
00:09:39,050 --> 00:09:41,333
而不是经营一指一个机房

344
00:09:41,333 --> 00:09:42,600
算我们 10 万卡集群

345
00:09:42,800 --> 00:09:43,533
算力

346
00:09:43,533 --> 00:09:43,733
或者

347
00:09:43,733 --> 00:09:46,083
我们整体的一个 IDC 的重新的建设

348
00:09:46,083 --> 00:09:47,683
还是非常的夸张

349
00:09:48,766 --> 00:09:50,533
我们现在来到了第三个内容

350
00:09:50,533 --> 00:09:52,200
看一下整个网络互联

351
00:09:52,200 --> 00:09:53,683
的整体的挑战

352
00:09:53,683 --> 00:09:55,933
都是针对我们的十万卡集群

353
00:09:55,933 --> 00:09:56,933
那网络互联

354
00:09:56,933 --> 00:09:57,766
很重要的一点

355
00:09:57,766 --> 00:09:58,800
我们就要搞清楚

356
00:09:58,933 --> 00:10:00,450
光模块的传输的距离

357
00:10:00,450 --> 00:10:01,650
我们现在的 AI 集群

358
00:10:01,650 --> 00:10:04,166
大部分都会通过非常非常多的光模块

359
00:10:04,166 --> 00:10:04,933
进行互联

360
00:10:04,933 --> 00:10:07,083
而光模块的成本跟它的覆盖范围

361
00:10:07,083 --> 00:10:08,766
是成一个正比

362
00:10:08,766 --> 00:10:09,883
那这里面的光模块

363
00:10:09,883 --> 00:10:10,600
主要分两种

364
00:10:10,600 --> 00:10:12,250
一种是多光模的光模块

365
00:10:12,250 --> 00:10:13,083
我们叫 SR

366
00:10:13,083 --> 00:10:14,283
还有 AOC 的光模块

367
00:10:14,283 --> 00:10:16,450
大概支持只有 50 米的传输距离

368
00:10:16,450 --> 00:10:16,883
另外的话

369
00:10:16,883 --> 00:10:18,000
我们长距离

370
00:10:18,000 --> 00:10:19,200
大部分都是用单模

371
00:10:19,200 --> 00:10:20,966
有 DR 跟 FR 的一个光模块

372
00:10:20,966 --> 00:10:22,933
那基本上支持 500 米到 2 千米

373
00:10:22,933 --> 00:10:24,483
的相关的一个传输距离

374
00:10:24,483 --> 00:10:25,166
那这里面

375
00:10:25,166 --> 00:10:25,683
大部分

376
00:10:25,683 --> 00:10:27,366
我们干一个在节点里面

377
00:10:27,366 --> 00:10:28,933
或者在一个计算岛里面

378
00:10:28,933 --> 00:10:30,333
大部分都是采用多模

379
00:10:30,333 --> 00:10:32,483
而是在一个园区内或者不同楼之间

380
00:10:32,483 --> 00:10:35,450
我们可能更多是采用单模的一个形态

381
00:10:35,450 --> 00:10:35,883
但是

382
00:10:35,883 --> 00:10:38,533
单模的一个造价是多模的一个 2.5 倍

383
00:10:38,850 --> 00:10:39,650
在园区内

384
00:10:39,650 --> 00:10:41,050
因为要做 10 万卡集群

385
00:10:41,050 --> 00:10:43,133
所以我们相关的干网络传输距离

386
00:10:43,133 --> 00:10:44,400
可以超过 2 千米

387
00:10:44,400 --> 00:10:46,600
但整体的造价也是非常的昂贵

388
00:10:46,600 --> 00:10:47,566
超过 10 倍以上

389
00:10:47,566 --> 00:10:49,250
所以整体来说

390
00:10:49,250 --> 00:10:49,966
现在来看

391
00:10:49,966 --> 00:10:52,883
我们会建多个岛或者多个计算岛

392
00:10:52,883 --> 00:10:53,366
那这里面

393
00:10:53,366 --> 00:10:55,283
我们可以看一下岛内跟岛外

394
00:10:55,283 --> 00:10:56,283
是怎么去算

395
00:10:56,533 --> 00:10:58,366
现在 H100 的一个小规模集群

396
00:10:58,366 --> 00:11:01,283
一般都会使用一个多模的光模块

397
00:11:01,283 --> 00:11:02,600
那所谓的小规模集群

398
00:11:02,600 --> 00:11:04,166
就是我们简单的一个数据岛了

399
00:11:04,166 --> 00:11:06,450
可能有千卡左右

400
00:11:06,450 --> 00:11:08,083
甚至一些小规模集群

401
00:11:08,083 --> 00:11:08,966
去到百卡

402
00:11:08,966 --> 00:11:10,850
那我们通过一到两层的交换机

403
00:11:10,850 --> 00:11:12,000
能够实现

404
00:11:12,883 --> 00:11:13,883
那现在来看

405
00:11:13,883 --> 00:11:14,650
另外一点

406
00:11:14,650 --> 00:11:16,683
就是每栋楼现在包含一个

407
00:11:16,683 --> 00:11:18,533
或者有多个计算的节点

408
00:11:18,533 --> 00:11:19,683
这些所谓的计算节点

409
00:11:19,683 --> 00:11:20,883
就所谓的计算岛了

410
00:11:20,883 --> 00:11:22,050
它其实一个概念

411
00:11:22,050 --> 00:11:23,283
那一个计算岛里面

412
00:11:23,283 --> 00:11:24,366
我们基本上

413
00:11:24,366 --> 00:11:26,450
都会用铜缆或者多模的一个光模块

414
00:11:26,450 --> 00:11:27,733
来进行一个连接

415
00:11:27,966 --> 00:11:30,133
实现我们成本跟效率的最大化

416
00:11:30,133 --> 00:11:31,533
那如果距离较长

417
00:11:31,533 --> 00:11:32,050
光模块了

418
00:11:32,050 --> 00:11:33,566
我们大部分都使用岛际

419
00:11:33,566 --> 00:11:35,083
来进行一个互联

420
00:11:35,133 --> 00:11:37,366
也就对应的一段话来计算岛内了

421
00:11:37,366 --> 00:11:38,850
我们使用高速的带宽

422
00:11:38,850 --> 00:11:39,533
计算岛外

423
00:11:39,533 --> 00:11:41,166
我们带宽会比较低

424
00:11:41,166 --> 00:11:42,000
那下面这个图

425
00:11:42,000 --> 00:11:44,133
就可能我们会有很多个计算岛

426
00:11:44,366 --> 00:11:44,883
那岛内

427
00:11:44,883 --> 00:11:47,133
我们可能会通过一个多模的光模块

428
00:11:47,133 --> 00:11:48,450
来进行连接

429
00:11:48,450 --> 00:11:49,966
那岛跟岛之间

430
00:11:49,966 --> 00:11:51,883
我们可能会通过单模的光模块

431
00:11:51,883 --> 00:11:53,283
来进行一个连接

432
00:11:55,166 --> 00:11:55,600
那这里面

433
00:11:55,600 --> 00:11:58,333
在 META 的一个 3.2 万卡的 GPU 集群里面

434
00:11:58,333 --> 00:12:00,533
就设计了八个全数的计算岛

435
00:12:00,533 --> 00:12:02,400
计算岛之上的一个异常的交换的网络

436
00:12:02,400 --> 00:12:03,250
带宽的过载比

437
00:12:03,250 --> 00:12:05,166
大概是 7:1

438
00:12:05,166 --> 00:12:05,733
那这里面

439
00:12:05,733 --> 00:12:07,483
也有相关的数据

440
00:12:07,483 --> 00:12:09,366
岛跟岛之间的一个网络

441
00:12:09,366 --> 00:12:12,133
就基本上就慢了非常的多了

442
00:12:12,533 --> 00:12:13,683
在互联里面

443
00:12:13,683 --> 00:12:15,450
我们还有一些蛮有意思的点

444
00:12:15,450 --> 00:12:17,283
就是整个轨道的优化

445
00:12:17,283 --> 00:12:19,133
还有中间的机架

446
00:12:19,133 --> 00:12:19,766
那这里面

447
00:12:19,766 --> 00:12:23,000
ZOMI 还是分开两个内容跟大家去介绍

448
00:12:23,000 --> 00:12:24,450
一个是轨道的优化

449
00:12:24,450 --> 00:12:26,766
所谓的多轨和单轨之间的问题

450
00:12:26,766 --> 00:12:28,683
还有一个中间的一个机架

451
00:12:28,683 --> 00:12:30,483
那这里面就提了一个问题

452
00:12:30,683 --> 00:12:32,283
什么是中间机架

453
00:12:32,766 --> 00:12:35,333
什么是轨道的一个优化

454
00:12:35,333 --> 00:12:36,283
那首先

455
00:12:36,283 --> 00:12:38,000
我们先来回答一个

456
00:12:38,000 --> 00:12:39,450
问题就是轨道的优化

457
00:12:39,450 --> 00:12:40,366
那轨道的优化

458
00:12:40,366 --> 00:12:42,683
ZOMI 在一期视频里面了

459
00:12:42,683 --> 00:12:45,650
特别是集合通讯里面的分析 XCCL

460
00:12:45,650 --> 00:12:47,333
也是 XCCL 的时候

461
00:12:47,333 --> 00:12:49,650
会重点的去讲了通讯的一个网络

462
00:12:49,650 --> 00:12:50,766
拓扑的协同的优化

463
00:12:50,766 --> 00:12:51,283
那这里面

464
00:12:51,283 --> 00:12:53,533
就讲了单轨跟多轨之间的区别

465
00:12:53,850 --> 00:12:55,933
在这一期视频里面就不再展示了

466
00:12:55,933 --> 00:12:57,450
那另外我们在这期视频里面

467
00:12:57,450 --> 00:12:59,400
重点去看一下 middle of Rack

468
00:12:59,400 --> 00:13:02,600
也就是机柜中部的这种一个部署了

469
00:13:02,600 --> 00:13:04,800
那我们看看右边的这个图

470
00:13:04,800 --> 00:13:05,133
实际上

471
00:13:05,133 --> 00:13:07,133
在我们的 IDC 的一个机柜方面

472
00:13:07,133 --> 00:13:09,000
我们的一些相关

473
00:13:09,000 --> 00:13:10,533
这一坨东西

474
00:13:10,533 --> 00:13:11,450
是我们的交换机

475
00:13:11,450 --> 00:13:12,850
交换机放在柜顶

476
00:13:12,850 --> 00:13:13,683
还是柜中间

477
00:13:13,683 --> 00:13:14,733
还是柜底

478
00:13:14,733 --> 00:13:16,933
我们就会变成 top of rack

479
00:13:16,933 --> 00:13:17,850
middle of rack

480
00:13:17,850 --> 00:13:19,166
还有 bottle of rack

481
00:13:19,166 --> 00:13:20,083
那多给的优化

482
00:13:20,083 --> 00:13:21,933
可以让我们每一台

483
00:13:21,933 --> 00:13:23,366
或者每一个 H100 的节点

484
00:13:23,366 --> 00:13:24,650
或者每一个计算节点

485
00:13:24,650 --> 00:13:27,250
连接到不同的叶交换机里面

486
00:13:27,333 --> 00:13:28,366
多轨的优化

487
00:13:28,366 --> 00:13:31,450
会使得我们每一个计算的节点

488
00:13:31,450 --> 00:13:33,933
可以连接到 8 个不同的叶交换机了

489
00:13:33,933 --> 00:13:34,600
那这里面

490
00:13:34,600 --> 00:13:35,283
每个 GPU

491
00:13:35,283 --> 00:13:37,250
只需要一个交换跃点

492
00:13:37,250 --> 00:13:38,733
也就是对应的 switch hop

493
00:13:38,733 --> 00:13:40,333
就能跟另外一个 GPU

494
00:13:40,333 --> 00:13:41,733
进行一个互联

495
00:13:41,733 --> 00:13:44,166
那这个就是多轨的一个优点

496
00:13:44,333 --> 00:13:45,766
我们在之前的一个视频里面

497
00:13:45,766 --> 00:13:48,000
已经跟大家详细的介绍过了

498
00:13:48,000 --> 00:13:50,133
这里面就不再论述了

499
00:13:50,133 --> 00:13:51,800
不过很有意思的就是

500
00:13:51,800 --> 00:13:52,733
我们看一下

501
00:13:52,733 --> 00:13:55,650
所谓的单轨跟多轨之间的一个区别

502
00:13:55,650 --> 00:13:56,533
那单轨

503
00:13:56,533 --> 00:13:57,200
也就是所谓

504
00:13:57,200 --> 00:13:58,733
我们 GPU 里面的一个接口

505
00:13:58,733 --> 00:14:00,200
直出连到另外

506
00:14:00,200 --> 00:14:01,650
一个连到同一个

507
00:14:01,650 --> 00:14:03,883
那个机位顶里面的交换机

508
00:14:04,083 --> 00:14:05,683
这种方式就是直连

509
00:14:05,683 --> 00:14:07,400
那为了实现多轨

510
00:14:07,400 --> 00:14:10,333
我们基本上了假设规中有个交换机

511
00:14:10,333 --> 00:14:11,683
我们所有的计算节点

512
00:14:11,683 --> 00:14:13,366
都会往外去连

513
00:14:13,533 --> 00:14:14,683
每个 GPU 节点

514
00:14:14,683 --> 00:14:17,250
单独的连到一个交换机上面

515
00:14:17,250 --> 00:14:20,283
那这就是单轨跟多轨之间的一个区别

516
00:14:20,400 --> 00:14:21,533
那我们了解完

517
00:14:21,533 --> 00:14:22,850
单轨跟多轨之间的区别

518
00:14:22,850 --> 00:14:25,083
还是要看一下这种方式

519
00:14:25,083 --> 00:14:28,166
现在大部分是使用这种 middle of rack

520
00:14:28,250 --> 00:14:28,566
是因为

521
00:14:28,566 --> 00:14:30,600
我们使用了一个无轨的优化方案

522
00:14:30,600 --> 00:14:32,200
使用更廉价的铜缆

523
00:14:32,200 --> 00:14:34,283
去取代 GPU 和叶交换机

524
00:14:34,283 --> 00:14:36,200
一个整体的光模块

525
00:14:36,200 --> 00:14:38,050
也是用铜缆或者用 ADC

526
00:14:38,050 --> 00:14:40,083
来去代替我们的传统的光模块

527
00:14:40,083 --> 00:14:42,050
那在整个 GPU 的网络里面

528
00:14:42,050 --> 00:14:43,283
就实现了百分之

529
00:14:43,483 --> 00:14:45,600
或者在整个集群里面

530
00:14:45,600 --> 00:14:46,483
万卡集群

531
00:14:46,483 --> 00:14:47,650
甚至 10 万卡集群

532
00:14:47,650 --> 00:14:50,733
就实现了 25%-33%的一个铜缆的覆盖

533
00:14:50,733 --> 00:14:51,483
那这种方式

534
00:14:51,483 --> 00:14:53,283
我们看看右边的这个图案

535
00:14:53,333 --> 00:14:54,733
也就是意味着我们现在

536
00:14:54,733 --> 00:14:55,733
已经聊到了

537
00:14:55,733 --> 00:14:58,283
像 B100 这种新的组网方案

538
00:14:58,283 --> 00:14:59,933
或者像 H200

539
00:14:59,933 --> 00:15:02,200
或者 H100 相关的新的组网方案

540
00:15:02,200 --> 00:15:03,850
或者新的一个互联网方案

541
00:15:03,933 --> 00:15:06,050
每一个计算节点里面的 GPU

542
00:15:06,050 --> 00:15:07,166
它们的之间的连接

543
00:15:07,166 --> 00:15:10,333
不再是先连接到电缆的托架上面

544
00:15:10,333 --> 00:15:12,133
再从上面的托架

545
00:15:12,133 --> 00:15:12,600
再连

546
00:15:12,600 --> 00:15:16,200
穿到对应的一个轨道的叶交换机上面

547
00:15:16,483 --> 00:15:18,133
而是将叶交换机

548
00:15:18,133 --> 00:15:19,450
像我们看到的 IB

549
00:15:19,450 --> 00:15:21,450
这个放在我们的机架的中间

550
00:15:21,450 --> 00:15:22,483
让每个 GPU

551
00:15:22,483 --> 00:15:25,883
都使用 DAC 的铜缆进行一个连接

552
00:15:25,883 --> 00:15:27,250
那为什么使用这种方式

553
00:15:27,250 --> 00:15:28,650
是因为整个 DAC 的电缆

554
00:15:28,650 --> 00:15:30,883
或者我们铜缆地心的温度更低

555
00:15:30,883 --> 00:15:31,683
说实话

556
00:15:31,683 --> 00:15:34,050
光模块还是非常的消耗我们的能源

557
00:15:34,050 --> 00:15:34,683
另外的话

558
00:15:34,683 --> 00:15:36,733
整个电缆或者我们的铜缆

559
00:15:36,733 --> 00:15:37,766
可靠性更高

560
00:15:37,766 --> 00:15:38,733
但是这个可靠性

561
00:15:38,733 --> 00:15:40,483
会不会带来我们的研发的成本更高

562
00:15:40,483 --> 00:15:42,000
那是另外一个话题了

563
00:15:42,000 --> 00:15:42,883
不过

564
00:15:42,883 --> 00:15:43,850
整个铜缆的方案

565
00:15:43,850 --> 00:15:46,000
其实能够实现更少的 flapping

566
00:15:46,000 --> 00:15:47,400
也是我们的网络的一个中断

567
00:15:47,400 --> 00:15:49,050
和瘫痪相关的故障

568
00:15:49,283 --> 00:15:49,533
不过

569
00:15:49,533 --> 00:15:51,533
整体的 B100 现在还没有推出出来

570
00:15:51,533 --> 00:15:53,566
是不是铜揽或者这种造价的方式

571
00:15:53,566 --> 00:15:55,533
或者这种新的解决方会出问题

572
00:15:55,533 --> 00:15:57,600
嗯 ZOMI 觉得也有可能

573
00:15:57,600 --> 00:15:58,450
那我们现在来

574
00:15:58,450 --> 00:15:59,650
来对比起一下

575
00:15:59,650 --> 00:16:01,800
刚才讲到的一个 middle of rack

576
00:16:01,800 --> 00:16:03,483
还有那个多轨方案

577
00:16:03,483 --> 00:16:04,800
之间的两个的差异

578
00:16:04,800 --> 00:16:06,400
那左边这个就多轨的方案

579
00:16:06,400 --> 00:16:07,533
我们每一个计算节点

580
00:16:07,533 --> 00:16:08,650
其实是通过铜缆

581
00:16:08,650 --> 00:16:10,400
或者通过我们的光模块

582
00:16:10,400 --> 00:16:12,000
走到我们的中间交换机

583
00:16:12,000 --> 00:16:13,600
然后每一个都是这么走

584
00:16:13,600 --> 00:16:15,800
所以上面你会看到有一些机房里面

585
00:16:16,133 --> 00:16:17,766
上面是密密麻麻的布线

586
00:16:17,766 --> 00:16:19,533
这种就是多轨的方案

587
00:16:19,533 --> 00:16:21,566
那后面可能采用单轨的方案

588
00:16:21,566 --> 00:16:23,600
或者会直接连到中间的服务器

589
00:16:23,600 --> 00:16:24,166
那当然了

590
00:16:24,166 --> 00:16:26,766
我们还会采用那个 middle of rack 的方式

591
00:16:27,083 --> 00:16:29,166
所有的光模块都变成我们的铜缆

592
00:16:29,166 --> 00:16:31,166
因此我们可以采用 middle of rack 的方式

593
00:16:31,166 --> 00:16:32,883
因此我们对比有两种方式

594
00:16:32,883 --> 00:16:34,000
一种是左边

595
00:16:34,000 --> 00:16:35,483
第二种是右边

596
00:16:35,483 --> 00:16:36,133
那另外的话

597
00:16:36,133 --> 00:16:38,166
我们采用的铜缆的能耗

598
00:16:38,166 --> 00:16:41,250
确实比整体使用多模的光模块会少

599
00:16:41,250 --> 00:16:43,133
那为什么单独的强调多模

600
00:16:43,133 --> 00:16:44,933
是因为我们在一个计算岛里面

601
00:16:44,933 --> 00:16:46,450
或者一个小规模的集群里面

602
00:16:46,450 --> 00:16:48,966
大部分都是采用一个多模的形态

603
00:16:49,483 --> 00:16:51,683
我们好不容易来到了第四个内容了

604
00:16:51,683 --> 00:16:53,733
整体的故障恢复运维来了

605
00:16:53,733 --> 00:16:55,333
这里面其实没多大东西

606
00:16:55,333 --> 00:16:57,050
主要是讲讲可靠性

607
00:16:57,050 --> 00:16:59,283
现在从 meta 他训练

608
00:16:59,283 --> 00:17:02,850
那个 Llama3.1 的一个论文

609
00:17:02,850 --> 00:17:04,483
或者相关的一个技术文章发布

610
00:17:04,483 --> 00:17:05,600
其实是我现在

611
00:17:05,600 --> 00:17:07,000
在整个训练过程当中

612
00:17:07,000 --> 00:17:08,550
GPU、HBM、ECC 错误

613
00:17:08,550 --> 00:17:09,716
还有 GPS 驱动卡死

614
00:17:09,716 --> 00:17:10,483
光模块的故障

615
00:17:10,483 --> 00:17:11,966
还有网卡的过热

616
00:17:12,366 --> 00:17:13,333
硬件的问题

617
00:17:13,333 --> 00:17:15,483
其实是占的非常比例非常高

618
00:17:15,483 --> 00:17:16,766
占 70%左右

619
00:17:16,766 --> 00:17:17,733
所以训练的时候

620
00:17:17,733 --> 00:17:19,966
我们为了防止各种各样的硬件问题

621
00:17:19,966 --> 00:17:22,966
所以会做了一些新的可靠性的分析

622
00:17:22,966 --> 00:17:24,966
和新的可靠性的一些运维的方案

623
00:17:25,533 --> 00:17:28,400
终于跟大家去一起思考和分享了

624
00:17:28,400 --> 00:17:29,883
10 万卡现在的训什么

625
00:17:29,883 --> 00:17:31,566
还有面临功耗互联

626
00:17:31,566 --> 00:17:34,166
和可靠性相关的一些分析

627
00:17:34,166 --> 00:17:34,966
那今天内容

628
00:17:34,966 --> 00:17:36,333
我们就分享到这了

629
00:17:36,333 --> 00:17:36,800
谢谢各位

630
00:17:36,800 --> 00:17:37,600
拜了个拜

