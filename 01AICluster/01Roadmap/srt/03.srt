1
00:00:00,000 --> 00:00:01,333
内容/录制:Z0MI酱，视频后期/字幕:梁嘉铭

2
00:00:01,333 --> 00:00:02,566
hello

3
00:00:02,566 --> 00:00:04,966
大家好高性能的ZOMI又回来了

4
00:00:07,100 --> 00:00:07,633
今天

5
00:00:07,633 --> 00:00:09,966
还是在高性能计算的发展趋势

6
00:00:10,033 --> 00:00:11,466
但是今天看的内容

7
00:00:11,500 --> 00:00:13,500
可能跟之前的不太一样了

8
00:00:13,500 --> 00:00:14,366
之前看了

9
00:00:14,366 --> 00:00:17,400
整个高性能发展趋势的硬件架构

10
00:00:17,433 --> 00:00:20,433
今天重点的是在软件跟应用了

11
00:00:20,433 --> 00:00:21,633
还不是编程

12
00:00:21,800 --> 00:00:23,566
那在整个计算集群之路

13
00:00:23,566 --> 00:00:26,700
现在才来到了前面的1/3的内容

14
00:00:26,733 --> 00:00:28,366
还有很多相关内容

15
00:00:28,366 --> 00:00:30,266
去跟大家去介绍

16
00:00:30,300 --> 00:00:31,700
在整个AI Infra层
  
17
00:00:31,700 --> 00:00:34,766
现在来到了AI集群这个环节

17
00:00:34,766 --> 00:00:36,666
去看看传统的HPC

18
00:00:36,700 --> 00:00:39,966
跟AI Infra里面的AI的智算中心

19
00:00:39,966 --> 00:00:41,066
有什么区别

20
00:00:41,133 --> 00:00:42,800
从HPC高性能计算里面

21
00:00:42,800 --> 00:00:45,433
可以借鉴很多相关的内容

22
00:00:45,433 --> 00:00:47,400
给到AI计算

23
00:00:47,966 --> 00:00:49,033
那不管怎么样

24
00:00:49,033 --> 00:00:49,866
这个图

25
00:00:49,900 --> 00:00:52,233
其实已经跟大家强调过很多回了

26
00:00:52,233 --> 00:00:54,666
现在是在计算领域

27
00:00:54,700 --> 00:00:55,500
那计算领域

28
00:00:55,500 --> 00:00:58,200
特别是以AI人工智能为主

29
00:00:58,233 --> 00:01:00,600
里面用到更多的是高并发

30
00:01:00,600 --> 00:01:03,433
计算密集型的一个具体的产业

31
00:01:03,500 --> 00:01:04,333
那今天

32
00:01:04,333 --> 00:01:06,033
主要是跟大家分享的内容

33
00:01:06,033 --> 00:01:08,100
就是后面两个

34
00:01:08,200 --> 00:01:10,700
基础软件跟应用软件

35
00:01:10,733 --> 00:01:12,933
基础软件更多的是指编译器

36
00:01:12,933 --> 00:01:13,500
运行时

37
00:01:13,500 --> 00:01:14,033
计算库

38
00:01:14,033 --> 00:01:15,266
通讯的中间件

39
00:01:15,300 --> 00:01:18,633
存储和调度相关的系统了

40
00:01:18,633 --> 00:01:19,400
那应用软件

41
00:01:19,400 --> 00:01:21,033
可能会更加简单一点

42
00:01:21,033 --> 00:01:22,766
因为ZOMI不是搞应用

43
00:01:22,766 --> 00:01:25,400
更多集中在一个基础软件

44
00:01:25,400 --> 00:01:26,200
这一块

45
00:01:27,333 --> 00:01:28,733
在基础软件层面

46
00:01:28,733 --> 00:01:29,433
首先

47
00:01:29,433 --> 00:01:31,666
要看看整个基础软件有哪些事情

48
00:01:31,933 --> 00:01:34,100
首先HPC里面的基础软件

49
00:01:34,100 --> 00:01:37,033
是连接硬件跟应用的核心桥梁

50
00:01:37,033 --> 00:01:38,300
所以说基础

51
00:01:38,333 --> 00:01:39,433
软件很重要

52
00:01:39,433 --> 00:01:41,800
而不是随便的应用软件或者其他软件

53
00:01:41,800 --> 00:01:44,500
那整个基础软件的发展历程

54
00:01:44,566 --> 00:01:47,266
主要是围绕着资源的高效的调度

55
00:01:47,300 --> 00:01:49,533
数据的高效的流转

56
00:01:49,533 --> 00:01:51,600
还有计算极致的性能优化

57
00:01:51,600 --> 00:01:54,500
那说白了整个基础软件做的三个事情

58
00:01:54,533 --> 00:01:56,333
第一个帮做调度

59
00:01:56,333 --> 00:01:56,800
第二个

60
00:01:56,800 --> 00:01:58,400
帮做数据的处理

61
00:01:58,400 --> 00:01:59,033
第三个

62
00:01:59,033 --> 00:02:01,033
做性能的优化

63
00:02:01,100 --> 00:02:02,433
三个方面去展开

64
00:02:02,433 --> 00:02:04,100
一个基础软件

65
00:02:04,133 --> 00:02:06,333
不管是哪一层哪个类型

66
00:02:06,366 --> 00:02:08,500
最核心的工作就这三

67
00:02:08,900 --> 00:02:09,366
接下来

68
00:02:09,366 --> 00:02:11,466
看一下第三点

69
00:02:11,733 --> 00:02:14,166
在整个通讯软件的最核心的有调度

70
00:02:14,166 --> 00:02:16,400
存储通讯编译计算库

71
00:02:16,400 --> 00:02:18,566
还有基础的算法六大维度

72
00:02:18,566 --> 00:02:19,366
这六大维度

73
00:02:19,366 --> 00:02:20,266
同样的去支撑

74
00:02:20,300 --> 00:02:22,500
刚才讲到的三个重点

75
00:02:22,500 --> 00:02:24,366
调度数据处理

76
00:02:24,366 --> 00:02:26,966
还有计算的性能的优化

77
00:02:26,966 --> 00:02:28,500
所以说一定要记住这3个点

78
00:02:28,533 --> 00:02:30,366
是整个技术软件最核心

79
00:02:30,366 --> 00:02:32,766
最想要解决的内容

80
00:02:33,233 --> 00:02:34,066
那事不宜迟

81
00:02:34,100 --> 00:02:35,200
马上展开

82
00:02:35,200 --> 00:02:37,766
第一个就是编译器跟运行时

83
00:02:37,766 --> 00:02:38,833
那编译器跟运行时

84
00:02:38,833 --> 00:02:39,833
很大的一个改变

85
00:02:39,833 --> 00:02:41,800
就是从手动的优化

86
00:02:41,800 --> 00:02:45,766
慢慢的转向自动的代码的生成了

87
00:02:47,300 --> 00:02:48,366
那现在看一下

88
00:02:48,366 --> 00:02:50,366
整个传统编译器的一个发展趋势

89
00:02:50,366 --> 00:02:51,066
传统编译器

90
00:02:51,100 --> 00:02:51,533
实际上

91
00:02:51,533 --> 00:02:54,533
是从1980年到2,000年的这段时间

92
00:02:54,533 --> 00:02:55,366
那一开始

93
00:02:55,366 --> 00:02:57,366
你会发现大家都在用Fortran 

94
00:02:57,366 --> 00:02:59,500
就大型机或者HPC

95
00:02:59,533 --> 00:03:01,633
主要是以Fortran 为主导

96
00:03:01,633 --> 00:03:02,566
那重点

97
00:03:02,566 --> 00:03:04,900
就是通过量化和循环展开

98
00:03:05,133 --> 00:03:07,800
去提升HPC的性能

99
00:03:07,800 --> 00:03:09,033
所以说Fortran 语言

100
00:03:09,033 --> 00:03:10,833
是更偏向于底层

101
00:03:10,833 --> 00:03:12,200
跟硬件打交道的语言

102
00:03:12,200 --> 00:03:14,066
现在用的非常的少了

103
00:03:14,100 --> 00:03:14,733
那第二个

104
00:03:14,733 --> 00:03:16,833
就是OpenMP

105
00:03:16,833 --> 00:03:20,300
OpenMP实际上就是Open Multi parallel

106
00:03:20,333 --> 00:03:23,800
就专门做并行编程模型

107
00:03:23,800 --> 00:03:25,766
那在1997年的时候推出

108
00:03:25,766 --> 00:03:26,633
就马上了

109
00:03:26,633 --> 00:03:29,000
就受到HPC的一个广泛关注

110
00:03:29,000 --> 00:03:30,300
认为整个HPC

111
00:03:30,333 --> 00:03:32,000
对于多线程的优化

112
00:03:32,000 --> 00:03:33,600
对于并行的优化

113
00:03:33,600 --> 00:03:37,300
对于大型的计算的高效率很重要

114
00:03:37,333 --> 00:03:40,300
于是就出现了OpenMP

115
00:03:40,900 --> 00:03:42,366
那再看一下

116
00:03:42,366 --> 00:03:45,400
所谓的编译的一个异构的时代

117
00:03:45,400 --> 00:03:47,766
也就2010年到现在了

118
00:03:47,766 --> 00:03:48,600
蛮有意思

119
00:03:48,600 --> 00:03:48,833
就是

120
00:03:48,833 --> 00:03:51,900
在整个底层的兵器的发展历程里面

121
00:03:51,933 --> 00:03:53,366
讲到LVM这些

122
00:03:53,366 --> 00:03:55,700
因为它是传统的PC都有

123
00:03:55,800 --> 00:03:58,066
在HPC高性能计算里面

124
00:03:58,100 --> 00:03:59,200
它会比较特殊

125
00:03:59,200 --> 00:04:01,033
从Fortran 到OpenMP

126
00:04:01,100 --> 00:04:05,033
然后到现在的一个CUDA跟OpenCL

127
00:04:05,033 --> 00:04:06,900
现在来看一下英伟达

128
00:04:06,933 --> 00:04:07,833
CUDA的语言

129
00:04:07,833 --> 00:04:08,833
就.cu了

130
00:04:08,933 --> 00:04:10,566
通过NVCC

131
00:04:10,566 --> 00:04:12,866
去实现CUDA的代码的生成

132
00:04:12,900 --> 00:04:14,366
生成完了代码之后

133
00:04:14,366 --> 00:04:16,766
就给到GPU进行一个执行

134
00:04:16,766 --> 00:04:17,600
那另外的话

135
00:04:17,600 --> 00:04:18,400
OpenCL

136
00:04:18,400 --> 00:04:20,600
就支持跨厂商的设备

137
00:04:20,600 --> 00:04:22,166
AMD苹果这些

138
00:04:22,166 --> 00:04:23,900
都是专门做OpenCL

139
00:04:23,933 --> 00:04:26,700
那这个c就是compute的意思

140
00:04:26,733 --> 00:04:27,933
那可以看到英特尔

141
00:04:27,933 --> 00:04:29,300
也有自己的one API

142
00:04:29,300 --> 00:04:31,366
华为有自己的毕昇的编译器

143
00:04:31,366 --> 00:04:34,433
去连接鲲鹏跟昇腾的一个异构

144
00:04:34,433 --> 00:04:35,366
所以可以看到

145
00:04:35,366 --> 00:04:36,633
最近基本上

146
00:04:36,633 --> 00:04:39,366
大家都在往着这个方向去发展

147
00:04:39,366 --> 00:04:42,166
那更多的是以英伟达的CUDA为主

148
00:04:42,366 --> 00:04:43,700
那未来的编译器的趋势

149
00:04:43,700 --> 00:04:45,966
可以简单的跟大家一起去畅想一

150
00:04:45,966 --> 00:04:47,066
下首先第一个

151
00:04:47,100 --> 00:04:49,300
就是AI的驱动自动调优了

152
00:04:49,300 --> 00:04:49,800
那这个

153
00:04:49,800 --> 00:04:51,366
其实在最近的这5年

154
00:04:51,366 --> 00:04:52,466
用的特别的多

155
00:04:52,500 --> 00:04:54,333
特别是TVM跟Ansor  

156
00:04:54,433 --> 00:04:56,033
通过一些ML

157
00:04:56,033 --> 00:04:59,466
机器学习的算法来做自动的生成

158
00:04:59,500 --> 00:05:01,300
对算子自动的生成

159
00:05:01,300 --> 00:05:04,733
对计算类和kernal自动的生成

160
00:05:04,933 --> 00:05:05,333
第二个

161
00:05:05,333 --> 00:05:06,700
就是谷歌还有LVN

162
00:05:06,700 --> 00:05:08,766
推出了多层的中间表示

163
00:05:08,766 --> 00:05:10,233
那MLIR这个项目

164
00:05:10,233 --> 00:05:12,600
就实现了跨平台的代码转换

165
00:05:12,600 --> 00:05:14,433
降低整个编译的开发

166
00:05:14,433 --> 00:05:16,400
说实话你可能听不懂编译

167
00:05:16,400 --> 00:05:18,066
但是你知道平时写的代码

168
00:05:18,100 --> 00:05:19,366
平时的应用

169
00:05:19,366 --> 00:05:20,300
都是用代码写

170
00:05:20,333 --> 00:05:21,233
那这些代码

171
00:05:21,233 --> 00:05:23,700
那执行在具体的HPC的硬件里面

172
00:05:23,733 --> 00:05:25,133
希望提升性能

173
00:05:25,133 --> 00:05:28,200
这个时候编译器就是帮翻译

174
00:05:28,200 --> 00:05:29,633
把高级语言

175
00:05:29,633 --> 00:05:32,666
翻译成机器能够理解的一些机器码

176
00:05:32,700 --> 00:05:33,966
那怎么提升性能

177
00:05:33,966 --> 00:05:36,100
就在编译器内部去实现

178
00:05:36,133 --> 00:05:37,100
那另外第三种

179
00:05:37,100 --> 00:05:38,100
就是现在

180
00:05:38,100 --> 00:05:40,966
特别的火的面向新的编程方式

181
00:05:40,966 --> 00:05:41,766
例如Triton

182
00:05:41,800 --> 00:05:42,633
那下面这个图

183
00:05:42,633 --> 00:05:44,933
就是Triton的一个具体内容了

184
00:05:44,966 --> 00:05:47,000
它最主要的就基于数据块

185
00:05:47,000 --> 00:05:48,633
帮分析对应的代码

186
00:05:48,633 --> 00:05:50,433
然后基于数据流

187
00:05:50,533 --> 00:05:52,300
变成一个AI编辑器

188
00:05:52,300 --> 00:05:54,766
变成一个对应的硬件抽象过来

189
00:05:54,766 --> 00:05:57,200
变成所谓的一些硬件的语言

190
00:05:57,200 --> 00:05:59,833
然后基于数据块来做加速

191
00:05:59,833 --> 00:06:00,600
那不管怎么样

192
00:06:00,600 --> 00:06:02,366
不再详细的展开

193
00:06:03,033 --> 00:06:04,000
现在

194
00:06:04,000 --> 00:06:05,966
好不容易来到了第二个内容

195
00:06:05,966 --> 00:06:06,633
计算库

196
00:06:06,633 --> 00:06:07,233
那计算库

197
00:06:07,233 --> 00:06:08,766
也是从基础的数学

198
00:06:08,766 --> 00:06:10,633
到领域的专用

199
00:06:10,633 --> 00:06:12,266
从通用到专用

200
00:06:12,300 --> 00:06:14,166
那基础数学肯定是要有

201
00:06:14,166 --> 00:06:14,900
加减乘除

202
00:06:14,933 --> 00:06:15,700
求根号开根号

203
00:06:15,700 --> 00:06:19,000
微分还有求导相关的功能

204
00:06:19,033 --> 00:06:19,666
那不管怎么样

205
00:06:19,700 --> 00:06:22,333
看一下所谓的经典的数学库

206
00:06:22,333 --> 00:06:23,300
math库

207
00:06:23,300 --> 00:06:24,733
一开始怎么实现

208
00:06:24,766 --> 00:06:25,566
那主要是

209
00:06:25,566 --> 00:06:28,200
是在1970年到2,000年的过程当中

210
00:06:28,200 --> 00:06:30,100
快速的去发展

211
00:06:30,333 --> 00:06:30,600
第一个

212
00:06:30,600 --> 00:06:33,666
就是BLAS/LAPACK相关的库了

213
00:06:33,700 --> 00:06:35,000
那所谓的这两个库

214
00:06:35,000 --> 00:06:37,100
主要是提供一些线性代数

215
00:06:37,133 --> 00:06:38,333
基础的功能

216
00:06:38,333 --> 00:06:40,033
例如矩阵乘矩阵

217
00:06:40,033 --> 00:06:41,766
加减乘除相关的功能

218
00:06:41,766 --> 00:06:42,900
那业界比较明确

219
00:06:42,933 --> 00:06:44,366
有那个Intel的MLK

220
00:06:44,366 --> 00:06:45,166
有OpenBLAS

221
00:06:45,166 --> 00:06:46,966
相关的优化矩阵的库

222
00:06:47,000 --> 00:06:49,200
你会发现现在大量的数据的计算

223
00:06:49,200 --> 00:06:50,233
大量的并行计算

224
00:06:50,233 --> 00:06:52,566
实际上都是对矩阵进行计算

225
00:06:52,566 --> 00:06:53,900
包括现在的AI

226
00:06:53,933 --> 00:06:54,566
神经网络

227
00:06:54,566 --> 00:06:56,800
 transformer q k v的相乘

228
00:06:56,800 --> 00:06:58,166
所有的这些概念

229
00:06:58,166 --> 00:07:00,700
都是基于最基础的数学库

230
00:07:00,733 --> 00:07:03,300
BLAS或者LAPACK进行一个实现

231
00:07:03,300 --> 00:07:04,900
当然它的实现方式有很多种

232
00:07:04,900 --> 00:07:05,966
有用CUDA去实现

233
00:07:05,966 --> 00:07:06,800
变成CUDNN

234
00:07:06,800 --> 00:07:07,600
各种各样

235
00:07:07,633 --> 00:07:08,433
那不管怎么样

236
00:07:08,433 --> 00:07:09,766
现在回到这个库

237
00:07:09,766 --> 00:07:11,866
后面有有了快速傅里叶变换

238
00:07:11,900 --> 00:07:14,900
就f f t w通过快速傅里叶变换

239
00:07:14,900 --> 00:07:17,733
来支持千万级的数据进行计算

240
00:07:18,633 --> 00:07:19,700
到了10年之后

241
00:07:19,733 --> 00:07:20,400
你会发现

242
00:07:20,400 --> 00:07:23,500
可能面向于传统的这些数学库

243
00:07:23,533 --> 00:07:24,333
已经不满足了

244
00:07:24,333 --> 00:07:26,966
希望能够面向重点的一些场景

245
00:07:26,966 --> 00:07:28,200
专门做加速

246
00:07:28,200 --> 00:07:28,800
那第一个

247
00:07:28,800 --> 00:07:30,633
就例如稀疏的矩阵

248
00:07:30,633 --> 00:07:31,833
因为矩阵说实话

249
00:07:31,833 --> 00:07:33,066
有大量的是0

250
00:07:33,100 --> 00:07:33,300
矩阵

251
00:07:33,300 --> 00:07:35,200
里面可能不一定所有东西都有用

252
00:07:35,200 --> 00:07:36,633
所以又出现了各种各样

253
00:07:36,633 --> 00:07:38,833
BLAS的库来去支持

254
00:07:38,833 --> 00:07:39,666
网格的库

255
00:07:39,700 --> 00:07:40,733
来去支持

256
00:07:40,733 --> 00:07:41,833
那面向AI

257
00:07:41,833 --> 00:07:42,600
这个比较明确

258
00:07:42,600 --> 00:07:44,566
现在大家用的特别的多

259
00:07:44,566 --> 00:07:46,700
英伟达要推出自己的cuDNN

260
00:07:46,733 --> 00:07:47,366
那英特尔

261
00:07:47,366 --> 00:07:48,700
推出自己的oneDNN

262
00:07:48,733 --> 00:07:50,400
那华为有自己的昇腾的CANN

263
00:07:50,400 --> 00:07:51,433
相关的内容

264
00:07:51,433 --> 00:07:53,700
提供各种各样的AI算子库

265
00:07:53,733 --> 00:07:55,900
实际上在整个HPC里面

266
00:07:55,900 --> 00:07:57,400
把这些叫做kernel

267
00:07:57,400 --> 00:08:01,000
计算的核心

268
00:08:01,000 --> 00:08:02,266
计算的kernel

269
00:08:02,400 --> 00:08:04,500
通过计算的kernel来去实现

270
00:08:04,533 --> 00:08:08,733
针对具体的计算的加速

271
00:08:09,066 --> 00:08:09,800
那不管怎么样

272
00:08:09,800 --> 00:08:11,833
现在打开一个业界非常火

273
00:08:11,833 --> 00:08:14,066
一个英伟达的CUDA的库

274
00:08:14,100 --> 00:08:14,700
那首先

275
00:08:14,700 --> 00:08:15,366
可以看到

276
00:08:15,366 --> 00:08:16,800
整个CUDA下面的一层

277
00:08:16,800 --> 00:08:18,200
就是我有一层CUDA

278
00:08:18,333 --> 00:08:20,600
它的一个英伟达的一个编程

279
00:08:20,600 --> 00:08:22,033
编译的计算工具

280
00:08:22,033 --> 00:08:24,033
那或者提供的编译语言

281
00:08:24,033 --> 00:08:24,833
然后最上层

282
00:08:24,833 --> 00:08:26,300
就提供了CUDA xlibrary

283
00:08:26,333 --> 00:08:27,200
CUDA xlibrary

284
00:08:27,200 --> 00:08:30,600
就承载了很多的各种各样的库啦

285
00:08:30,600 --> 00:08:31,666
有CUTLASS，

286
00:08:31,700 --> 00:08:33,000
CuDF，CU graph，

287
00:08:33,000 --> 00:08:33,900
CuOPT

288
00:08:33,933 --> 00:08:35,600
还有那个cuTensor

289
00:08:35,600 --> 00:08:36,233
cuSolver

290
00:08:36,233 --> 00:08:38,300
那现在做一个简单的分类

291
00:08:38,333 --> 00:08:38,833
就讲到了

292
00:08:38,833 --> 00:08:40,833
可能从一开始的通用

293
00:08:40,933 --> 00:08:43,100
那慢慢的转向现在的专用了

294
00:08:43,100 --> 00:08:43,900
那所谓的专用

295
00:08:43,900 --> 00:08:45,366
就变成现在来看到

296
00:08:45,433 --> 00:08:47,066
AI的一个机器学习库啦

297
00:08:47,100 --> 00:08:47,966
CuDNN、cuML、

298
00:08:47,966 --> 00:08:51,033
Cugraph那数学跟科学计算库

299
00:08:51,033 --> 00:08:51,500
有CuBLAS

300
00:08:51,533 --> 00:08:52,566
CUFFT，CUSPARSE

301
00:08:52,566 --> 00:08:53,400
cuSolver

302
00:08:53,600 --> 00:08:54,966
CuRAND

303
00:08:54,966 --> 00:08:58,500
随机生成的一些数据

304
00:08:58,533 --> 00:08:59,933
当然还有一些专门针对

305
00:08:59,933 --> 00:09:02,200
数据处理和数据分析的CuDF

306
00:09:02,200 --> 00:09:04,433
还有多媒体的NPP

307
00:09:04,433 --> 00:09:06,200
相关的功能越来越多

308
00:09:06,200 --> 00:09:07,466
所以可以看到整个

309
00:09:07,500 --> 00:09:10,133
就变成了CUDAx的library

310
00:09:10,133 --> 00:09:13,433
x就是指各种各样的专用的数学库

311
00:09:13,433 --> 00:09:15,433
或官专用的领域库了

312
00:09:16,033 --> 00:09:16,766
那看一下

313
00:09:16,766 --> 00:09:19,233
在整个AI的计算库里面

314
00:09:19,233 --> 00:09:21,166
它的一个未来的发展趋势

315
00:09:21,166 --> 00:09:21,666
首先

316
00:09:21,700 --> 00:09:24,400
比较明确的就是自动微分的库

317
00:09:24,400 --> 00:09:26,100
已经开始慢慢的越来越多了

318
00:09:26,266 --> 00:09:28,966
专门支持Hessian矩阵的自动微分

319
00:09:29,000 --> 00:09:29,466
那第二个

320
00:09:29,500 --> 00:09:30,966
就是量子的算法库

321
00:09:30,966 --> 00:09:32,266
也看到慢慢的出现了

322
00:09:32,300 --> 00:09:33,533
因为量子计算

323
00:09:33,533 --> 00:09:36,633
未来可能是一个非常大的新的场景

324
00:09:36,633 --> 00:09:37,600
所以会出现了一些

325
00:09:37,600 --> 00:09:40,000
模拟量子计算的量子算法库

326
00:09:40,000 --> 00:09:41,866
但还有专门针对特需语言

327
00:09:41,900 --> 00:09:43,500
一些定义的库

328
00:09:43,500 --> 00:09:45,000
DOMAIN specific language

329
00:09:45,000 --> 00:09:45,766
特殊语言

330
00:09:45,766 --> 00:09:46,566
例如Julia

331
00:09:46,566 --> 00:09:48,266
就专门针对SciML

332
00:09:48,300 --> 00:09:50,800
一个实现自动微分的求解

333
00:09:51,900 --> 00:09:54,633
接着看一下整个存储的系统

334
00:09:54,633 --> 00:09:56,766
那存储系统的变化也比较明显

335
00:09:56,766 --> 00:09:58,066
从本地的i o

336
00:09:58,100 --> 00:10:00,966
开始慢慢到分布式的高速的访问

337
00:10:00,966 --> 00:10:01,300
然后

338
00:10:01,333 --> 00:10:03,333
又出现了各种各样的file system

339
00:10:03,333 --> 00:10:04,433
文件系统

340
00:10:04,433 --> 00:10:05,400
文件存储库

341
00:10:05,400 --> 00:10:08,100
文件调度算法相关的内容了

342
00:10:08,133 --> 00:10:09,600
那看一下整体的发展历程

343
00:10:09,600 --> 00:10:11,166
主要是从本地的存储

344
00:10:11,166 --> 00:10:11,900
那本地存储

345
00:10:11,933 --> 00:10:13,533
其实因为HPC嘛

346
00:10:13,533 --> 00:10:15,500
有很多个不同

347
00:10:15,500 --> 00:10:17,033
小的计算的单元

348
00:10:17,033 --> 00:10:18,300
有很多小的节点

349
00:10:18,333 --> 00:10:18,966
那这里面

350
00:10:18,966 --> 00:10:20,966
就出现了一个网络的文件系统

351
00:10:20,966 --> 00:10:22,166
和区域

352
00:10:22,400 --> 00:10:23,600
局域网的文件系统

353
00:10:23,600 --> 00:10:25,200
就是NFS

354
00:10:25,200 --> 00:10:28,500
还有NAS还有SAN相关的对应

355
00:10:28,533 --> 00:10:29,000
文件系统

356
00:10:29,000 --> 00:10:31,200
来去解决局部存储的问题

357
00:10:31,200 --> 00:10:32,633
但是这种存储的方式

358
00:10:32,633 --> 00:10:35,300
对于带宽来说还是比较敏感

359
00:10:35,533 --> 00:10:36,933
那发展的第二个历程

360
00:10:36,933 --> 00:10:38,433
就出现了分布式文件系统

361
00:10:38,433 --> 00:10:40,166
特别是大数据来临的时代

362
00:10:40,166 --> 00:10:42,600
那就是从2010年到现在了

363
00:10:42,600 --> 00:10:44,833
可以看到有很多像Luster啦

364
00:10:44,833 --> 00:10:45,900
开源文件系统

365
00:10:45,933 --> 00:10:48,333
支撑全球TOP500的超算

366
00:10:48,333 --> 00:10:49,233
基本上

367
00:10:49,233 --> 00:10:51,366
都用Lustre进行一个存储

368
00:10:51,366 --> 00:10:53,366
还有对应的对象的存储Ceph了

369
00:10:53,366 --> 00:10:55,900
还有相对应的其他的数据库

370
00:10:55,933 --> 00:10:57,433
相对应的国产DeepSeek了

371
00:10:57,433 --> 00:11:00,000
幻方了就推出了自己的3FS

372
00:11:00,000 --> 00:11:02,633
通过优化数据的存储和访问流

373
00:11:02,833 --> 00:11:05,966
降低了整个MoE的训练推理的成本

374
00:11:05,966 --> 00:11:06,866
所以可以看到

375
00:11:06,900 --> 00:11:09,900
分布式的并行的文件存储系统

376
00:11:09,900 --> 00:11:10,733
和文件系统

377
00:11:10,733 --> 00:11:13,400
现在基本上非常的多了

378
00:11:13,433 --> 00:11:14,233
那未来

379
00:11:14,233 --> 00:11:15,766
在存储系统里面

380
00:11:15,766 --> 00:11:16,500
可以看到

381
00:11:16,533 --> 00:11:17,966
或者存储文件里面

382
00:11:18,000 --> 00:11:21,800
存算融合肯定是一个比较明确的方案

383
00:11:21,933 --> 00:11:22,433
那第二个

384
00:11:22,433 --> 00:11:24,833
就是智能的数据的预取

385
00:11:24,833 --> 00:11:26,966
基于AI进行一个预测

386
00:11:26,966 --> 00:11:29,400
减少数据的读写的i o的延时

387
00:11:29,400 --> 00:11:30,700
还有针对数据

388
00:11:30,733 --> 00:11:32,633
进行分层分级

389
00:11:32,633 --> 00:11:34,100
例如针对SSD

390
00:11:34,133 --> 00:11:34,900
还有HBM

391
00:11:34,900 --> 00:11:37,766
还有跟HDD混合的存储架构

392
00:11:37,866 --> 00:11:39,066
针对训练场景

393
00:11:39,100 --> 00:11:40,533
或者执行场景

394
00:11:40,533 --> 00:11:43,100
中断的一个快速恢复了

395
00:11:43,100 --> 00:11:45,300
所以你会发现现在很多技术

396
00:11:45,300 --> 00:11:46,133
都不是未来了

397
00:11:46,133 --> 00:11:49,333
而是正在快速的演进的过程

398
00:11:51,300 --> 00:11:52,566
通讯的内容太多了

399
00:11:52,566 --> 00:11:54,566
ZOMI的脑容量已经不够了

400
00:11:54,566 --> 00:11:56,166
来到了第四个内容

401
00:11:56,166 --> 00:11:58,033
看一下通讯的中间件

402
00:11:58,033 --> 00:11:58,766
这个我熟

403
00:11:58,766 --> 00:12:01,300
从传统的MPI到现在的跨柜

404
00:12:01,333 --> 00:12:02,233
或者跨机架

405
00:12:02,233 --> 00:12:03,900
跨架构的互联

406
00:12:04,166 --> 00:12:05,066
那整体来说

407
00:12:05,100 --> 00:12:06,133
整个发展历程

408
00:12:06,133 --> 00:12:07,900
是经历的蛮长

409
00:12:07,900 --> 00:12:08,900
整个通讯

410
00:12:08,900 --> 00:12:10,333
因为它是随着那个互联网

411
00:12:10,333 --> 00:12:11,966
移动互联网时代发展

412
00:12:11,966 --> 00:12:12,800
所以它的时间

413
00:12:12,800 --> 00:12:14,000
不会说太早

414
00:12:14,000 --> 00:12:15,233
从1990年

415
00:12:15,233 --> 00:12:18,166
就互联网发展到2010年

416
00:12:18,166 --> 00:12:19,700
也就是英伟达

417
00:12:19,733 --> 00:12:21,933
后面就通过share memory

418
00:12:21,933 --> 00:12:24,100
那就是SHMEM相关的库

419
00:12:24,100 --> 00:12:26,700
来去实现跨机主跨机柜

420
00:12:26,700 --> 00:12:28,533
GPU跟CPU之间的一个互联

421
00:12:28,533 --> 00:12:30,433
或者GPU跟专用的CPU

422
00:12:30,433 --> 00:12:32,800
跟专用的处理器来进行互联

423
00:12:33,033 --> 00:12:33,666
那不管怎么样

424
00:12:33,700 --> 00:12:35,933
看一下MPI的一个统治的时代

425
00:12:35,933 --> 00:12:36,533
蛮有意思

426
00:12:36,533 --> 00:12:39,133
就是一个message process Interface

427
00:12:39,133 --> 00:12:41,233
叫消息传递接口MPI

428
00:12:41,233 --> 00:12:41,766
那这里面

429
00:12:41,766 --> 00:12:43,766
HPC的通讯的标准

430
00:12:43,766 --> 00:12:44,600
就OpenMPI

431
00:12:44,600 --> 00:12:46,366
包括英特尔的MPI了

432
00:12:46,400 --> 00:12:48,866
支持点对点的通讯或者集合通讯

433
00:12:48,900 --> 00:12:51,266
那现在的一些通讯库

434
00:12:51,266 --> 00:12:52,200
NCCL

435
00:12:52,200 --> 00:12:53,666
HCCL，VCCL

436
00:12:53,700 --> 00:12:54,966
各种各样的通讯库

437
00:12:54,966 --> 00:12:57,266
都是按照传统HPC

438
00:12:57,300 --> 00:12:58,400
这种消息传递

439
00:12:58,400 --> 00:13:01,433
就是MPI相关的一个标准来去实现

440
00:13:01,433 --> 00:13:02,300
对外提供

441
00:13:02,333 --> 00:13:04,233
所以现在很多AI的功能

442
00:13:04,233 --> 00:13:05,266
或者AI Infra的功能

443
00:13:05,300 --> 00:13:07,366
都借鉴整个HPC的内容

444
00:13:07,366 --> 00:13:09,633
所以为什么会大力的去讲HPC

445
00:13:09,633 --> 00:13:12,033
那另外的就是一个性能优化

446
00:13:12,033 --> 00:13:13,066
那专门针对网络

447
00:13:13,100 --> 00:13:14,200
就是RDMA的技术

448
00:13:14,200 --> 00:13:17,466
就能够实现1毫秒的延迟

449
00:13:17,533 --> 00:13:20,033
包括可能基于RDMA的IB了

450
00:13:20,033 --> 00:13:23,200
还有一个RoCE相关的网络

451
00:13:23,633 --> 00:13:24,800
往下继续看一下

452
00:13:24,800 --> 00:13:26,100
就是2020年之后

453
00:13:26,133 --> 00:13:28,100
就多协议的一个协同

454
00:13:28,100 --> 00:13:29,133
那看到

455
00:13:29,133 --> 00:13:30,433
支持MPI

456
00:13:30,433 --> 00:13:32,100
还有OpenSHMEM

457
00:13:32,233 --> 00:13:34,833
share memory等相关的多模式的编程

458
00:13:34,833 --> 00:13:36,366
或者多编程的模型

459
00:13:36,366 --> 00:13:37,566
就越来越多了

460
00:13:37,566 --> 00:13:38,366
那后面

461
00:13:38,366 --> 00:13:40,766
英伟达就基于这个OpenSHMEM

462
00:13:40,766 --> 00:13:44,000
做了一个nvSHMEM

463
00:13:44,000 --> 00:13:46,666
英伟达的GPU跟GPU把它连接起来

464
00:13:46,700 --> 00:13:48,933
就看成一个共享内存池的方式

465
00:13:48,933 --> 00:13:50,000
来去实现

466
00:13:50,000 --> 00:13:50,700
那后面

467
00:13:50,733 --> 00:13:52,133
你会发现很多人

468
00:13:52,133 --> 00:13:54,200
DeepSeek用了这种技术之后

469
00:13:54,200 --> 00:13:56,833
现在越来越多人去了解这相关的技术

470
00:13:56,833 --> 00:13:59,366
其实在整个HPC时代呀

471
00:13:59,366 --> 00:14:01,233
已经是相对成熟

472
00:14:01,233 --> 00:14:02,800
具体的概念和技术了

473
00:14:02,800 --> 00:14:04,400
现在才来学呀

474
00:14:09,900 --> 00:14:11,233
那不管怎么样了哈

475
00:14:11,233 --> 00:14:12,700
回到一个云

476
00:14:12,733 --> 00:14:13,533
原生的通讯

477
00:14:13,533 --> 00:14:14,566
现在基本上

478
00:14:14,566 --> 00:14:16,100
gRPC跟RDMA的结合

479
00:14:16,133 --> 00:14:16,933
能够有效

480
00:14:16,933 --> 00:14:19,766
降低跨容器的通讯的开销

481
00:14:19,766 --> 00:14:21,266
因为在云里面

482
00:14:21,300 --> 00:14:22,966
会有非常多的容器

483
00:14:22,966 --> 00:14:25,166
有非常多的Docker和租户

484
00:14:25,200 --> 00:14:26,700
于是就通过新的技术

485
00:14:26,700 --> 00:14:27,966
和多协议的协同

486
00:14:27,966 --> 00:14:29,900
降低i o的开销

487
00:14:29,933 --> 00:14:31,166
提升存储

488
00:14:31,366 --> 00:14:31,900
那未来

489
00:14:31,933 --> 00:14:33,333
在整个通讯的中

490
00:14:33,333 --> 00:14:35,300
基建会随着硬件的发展

491
00:14:35,300 --> 00:14:36,400
也在不断的发展

492
00:14:36,400 --> 00:14:39,466
第一个就是光网络的一个抽象层

493
00:14:39,466 --> 00:14:40,900
可以看到现在的硅光

494
00:14:40,933 --> 00:14:43,100
OSC已经越来越多了

495
00:14:43,100 --> 00:14:46,166
那至少谷歌的TPU就走在前列了

496
00:14:46,166 --> 00:14:46,500
那未来

497
00:14:46,533 --> 00:14:49,033
可能会出现新的一些通讯的协议

498
00:14:49,100 --> 00:14:49,733
另外的话

499
00:14:49,733 --> 00:14:51,166
可以自适应的路由

500
00:14:51,166 --> 00:14:53,466
基于拓扑的感知进行路由的选择

501
00:14:53,500 --> 00:14:55,133
那包括现在训练大模型

502
00:14:55,133 --> 00:14:56,366
也会尽量

503
00:14:56,466 --> 00:14:58,500
尽可能的做一些自适应的路由

504
00:14:58,533 --> 00:14:58,766
因为

505
00:14:58,766 --> 00:15:01,033
集群的组网的方式是不一样

506
00:15:01,033 --> 00:15:02,700
要拉起一个千卡的集群

507
00:15:02,733 --> 00:15:04,433
万卡的集群有可能

508
00:15:04,433 --> 00:15:07,066
有些集群或有些节点是被占用

509
00:15:07,100 --> 00:15:09,833
所以自适应的路由很重要

510
00:15:11,133 --> 00:15:12,800
接下来到第五个点了

511
00:15:12,800 --> 00:15:14,600
基础软件的调度系统了

512
00:15:14,600 --> 00:15:17,000
调度系统也是经过的一个发展

513
00:15:17,000 --> 00:15:18,200
从静态分配

514
00:15:18,200 --> 00:15:21,600
到智能的动态的管理

515
00:15:21,833 --> 00:15:23,266
那在整个早期阶段

516
00:15:23,300 --> 00:15:25,633
也是从90年开始

517
00:15:25,633 --> 00:15:26,633
因为整个HPC

518
00:15:26,633 --> 00:15:27,833
其实90年的时候

519
00:15:27,833 --> 00:15:30,566
慢慢的进入了真正意义的HPC

520
00:15:30,600 --> 00:15:32,633
而不是以前传统的大型机

521
00:15:32,633 --> 00:15:33,266
那这个时候

522
00:15:33,300 --> 00:15:34,300
单机的调度系统

523
00:15:34,300 --> 00:15:35,766
Unix的 at 还有cron

524
00:15:35,766 --> 00:15:37,966
其实一开始只是本地调度

525
00:15:37,966 --> 00:15:39,633
后来随着HPC的发展

526
00:15:39,633 --> 00:15:42,233
就迎来了一个调度系统了

527
00:15:42,233 --> 00:15:43,766
因为节点也越来越多

528
00:15:43,766 --> 00:15:44,866
互联网越来越多

529
00:15:44,900 --> 00:15:46,333
就分开很多个节点

530
00:15:46,333 --> 00:15:47,633
很多个一个服务器

531
00:15:47,700 --> 00:15:50,533
那比较明确的就有一个PBS啦

532
00:15:50,533 --> 00:15:52,433
还有LSF的相关

533
00:15:52,433 --> 00:15:54,000
作队列的调度

534
00:15:54,033 --> 00:15:56,033
那支持很多个跨节点

535
00:15:56,033 --> 00:15:56,833
这里面一个节点

536
00:15:56,833 --> 00:15:57,300
两个节点

537
00:15:57,333 --> 00:15:57,966
三个节点

538
00:15:57,966 --> 00:15:59,766
跨节点的资源的分配

539
00:15:59,766 --> 00:16:01,833
不同节点的资源的分配

540
00:16:01,833 --> 00:16:05,200
那基本上就是做相关的资源的调度

541
00:16:05,633 --> 00:16:07,166
那到了现在

542
00:16:07,166 --> 00:16:08,200
2010年之后

543
00:16:08,200 --> 00:16:10,566
你会发现现在调度系统用的更多

544
00:16:10,566 --> 00:16:12,233
第一个大家应该听过Slurm

545
00:16:12,533 --> 00:16:13,833
那现在拉起大模型

546
00:16:13,833 --> 00:16:15,400
可能有部分的大模型是用

547
00:16:15,400 --> 00:16:18,033
Slurm来进行一个拉起

548
00:16:18,033 --> 00:16:18,766
那整个Slurm

549
00:16:18,766 --> 00:16:20,266
主要是由开源社区来主导

550
00:16:20,300 --> 00:16:22,133
支持千万级的核心的调度

551
00:16:22,133 --> 00:16:23,900
特别是对于任务的调度

552
00:16:23,900 --> 00:16:26,566
还有NPU资源的细粒化的分配

553
00:16:26,566 --> 00:16:27,100
那第二个

554
00:16:27,133 --> 00:16:28,333
就是现在的云

555
00:16:28,333 --> 00:16:30,200
基本上都会用的就是K8S

556
00:16:30,200 --> 00:16:30,900
那K8S

557
00:16:30,933 --> 00:16:32,833
就支持这个整体的架构

558
00:16:32,833 --> 00:16:34,966
支持整个HPC的混合负载

559
00:16:35,000 --> 00:16:37,466
那实现容器的弹性化伸缩

560
00:16:37,500 --> 00:16:39,166
所以说在整个云里面

561
00:16:39,166 --> 00:16:40,700
K8S可能用的更多

562
00:16:40,733 --> 00:16:42,333
那在传统的HPC里面

563
00:16:42,333 --> 00:16:44,933
Slurm可能会用的非常的多

564
00:16:44,933 --> 00:16:46,233
相关的作业调度

565
00:16:46,233 --> 00:16:47,233
那基本上现在

566
00:16:47,233 --> 00:16:49,466
还是以这两个作为主导

567
00:16:49,500 --> 00:16:50,500
特别是K8S

568
00:16:50,500 --> 00:16:51,500
因为AI

569
00:16:51,500 --> 00:16:53,433
结合云用的也越来越多了

570
00:16:53,433 --> 00:16:57,033
所以K8S可能会用的在AI大模型里面

571
00:16:57,033 --> 00:16:57,966
非常的多

572
00:16:57,966 --> 00:16:58,800
那看一下

573
00:16:58,800 --> 00:17:01,033
整个调度系统的一个趋势

574
00:17:01,033 --> 00:17:02,800
就AI驱动的一个调度

575
00:17:02,800 --> 00:17:04,066
可能会越来越多了

576
00:17:04,100 --> 00:17:06,533
特别是用一些算法

577
00:17:06,533 --> 00:17:08,166
而不是用人工写死

578
00:17:08,166 --> 00:17:09,900
或者一个很trick的手段

579
00:17:10,000 --> 00:17:10,566
那接着

580
00:17:10,566 --> 00:17:12,200
就是异构的协同

581
00:17:12,200 --> 00:17:13,033
既然调度

582
00:17:13,033 --> 00:17:15,366
就需要对CPU GPU NPU

583
00:17:15,366 --> 00:17:17,833
还有各种各样的协处理器混合的调度

584
00:17:17,833 --> 00:17:19,566
混合的作业控制

585
00:17:20,033 --> 00:17:21,300
那有了这些之后

586
00:17:21,333 --> 00:17:23,300
可能会发展一些绿色

587
00:17:23,300 --> 00:17:24,400
节能的调度

588
00:17:24,400 --> 00:17:26,066
根据硬件的情况

589
00:17:26,100 --> 00:17:27,433
自适应的调度

590
00:17:27,433 --> 00:17:29,466
降低整体的PUE

591
00:17:29,700 --> 00:17:31,433
那基本上调度的方式

592
00:17:31,433 --> 00:17:33,100
已经讲的差不多了

593
00:17:33,133 --> 00:17:34,566
最后看一下

594
00:17:34,566 --> 00:17:38,000
整体的基础软件面临的几个问题

595
00:17:38,233 --> 00:17:40,166
第一个我觉得比较痛苦的就是硬件

596
00:17:40,166 --> 00:17:40,966
碎片化

597
00:17:40,966 --> 00:17:43,233
随着各种各样的PU都加进来

598
00:17:43,233 --> 00:17:45,400
你会发现大家都希望做异构

599
00:17:45,433 --> 00:17:47,866
因为硬件的碎片化越来越多了

600
00:17:47,900 --> 00:17:49,900
所以说开放的标准

601
00:17:49,900 --> 00:17:50,833
统一的标准

602
00:17:50,833 --> 00:17:52,166
统一的中间件

603
00:17:52,233 --> 00:17:53,433
底层的基础软件

604
00:17:53,433 --> 00:17:54,766
很重要的原因

605
00:17:54,766 --> 00:17:56,633
在这里不是仔细写个应用

606
00:17:56,633 --> 00:17:57,700
在自己的笔记本

607
00:17:57,733 --> 00:18:00,033
因为现在笔记本都基本上大统一了

608
00:18:00,033 --> 00:18:02,166
就是我的window手机也大统一了

609
00:18:02,166 --> 00:18:05,166
要不就是苹果安卓鸿蒙三大潮流系统

610
00:18:05,166 --> 00:18:06,766
但是AI越来越多

611
00:18:06,766 --> 00:18:08,033
AI往上

612
00:18:08,033 --> 00:18:10,633
你会发现有很多不同的接口和硬件

613
00:18:10,633 --> 00:18:11,400
还有算法

614
00:18:11,400 --> 00:18:13,566
往下有各种各样的硬件

615
00:18:13,933 --> 00:18:15,033
可以看到第二个

616
00:18:15,033 --> 00:18:16,766
就是存储跟计算的失衡了

617
00:18:16,766 --> 00:18:19,800
现在越来越多的讲究纯算一体的架构

618
00:18:19,800 --> 00:18:22,000
还有内存磁化的概念

619
00:18:22,000 --> 00:18:23,366
因为整体的存储

620
00:18:23,366 --> 00:18:25,666
跟计算的关系越来越密切了

621
00:18:25,700 --> 00:18:27,500
不像以前分的还是蛮开

622
00:18:27,500 --> 00:18:28,033
那第三个

623
00:18:28,033 --> 00:18:29,566
就是能源的问题

624
00:18:29,566 --> 00:18:31,100
说实话虽然中国

625
00:18:31,133 --> 00:18:32,233
说是说不缺电

626
00:18:32,233 --> 00:18:33,900
但是一个计算中心

627
00:18:33,933 --> 00:18:35,000
一个节点

628
00:18:35,000 --> 00:18:38,033
就已经能够去到20千瓦的一个功率了

629
00:18:38,033 --> 00:18:39,100
非常的高

630
00:18:39,133 --> 00:18:41,900
所以节能还是非常的重要

631
00:18:41,900 --> 00:18:43,166
国家的电网的调度

632
00:18:43,166 --> 00:18:44,433
也是很不容易

633
00:18:44,433 --> 00:18:46,100
特别是在国外

634
00:18:46,133 --> 00:18:48,033
那看到未来的HPC

635
00:18:48,033 --> 00:18:48,966
简单的一句话

636
00:18:48,966 --> 00:18:49,900
基础软件

637
00:18:49,933 --> 00:18:52,166
肯定向更加智能一体化

638
00:18:52,166 --> 00:18:54,200
开放的生态去引进

639
00:18:54,200 --> 00:18:56,466
这个也是ZOMI的一个简单的想法

640
00:18:56,500 --> 00:18:57,733
有觉得不对的小伙伴

641
00:18:57,733 --> 00:18:59,500
也欢迎拍砖

642
00:19:00,366 --> 00:19:02,266
可能不是ZOMI最熟悉

643
00:19:02,300 --> 00:19:04,333
也就是HPC里面的应用软件

644
00:19:04,333 --> 00:19:06,700
主要是集中ZOMI之前去管用所拜访

645
00:19:06,700 --> 00:19:07,900
去中科微电子所

646
00:19:07,900 --> 00:19:08,833
原子能源所呀

647
00:19:08,833 --> 00:19:12,033
还有深圳气象局去了解相关的内容

648
00:19:12,033 --> 00:19:12,833
那现在来看

649
00:19:12,833 --> 00:19:15,100
一些HPC里面的应用软件

650
00:19:15,133 --> 00:19:17,100
首先它可能会分为好几个

651
00:19:17,100 --> 00:19:19,300
一开始就是专用的代码时代

652
00:19:19,300 --> 00:19:21,133
那专用代码时代这个时候

653
00:19:21,133 --> 00:19:23,033
主要指自研的封闭式的代码

654
00:19:23,033 --> 00:19:24,766
强依赖于底层的硬件

655
00:19:24,766 --> 00:19:27,200
例如核爆模拟器LASNEX

656
00:19:27,200 --> 00:19:30,633
气象的软件WRF相关的内容

657
00:19:30,666 --> 00:19:32,833
当时候专用的这些软件

658
00:19:32,833 --> 00:19:36,033
最大的问题就是扩展性比较差

659
00:19:36,200 --> 00:19:37,700
维护的成本也比较高

660
00:19:37,733 --> 00:19:39,333
代码动辄上百万行

661
00:19:39,333 --> 00:19:40,533
Fortran/C 为主导

662
00:19:40,533 --> 00:19:42,100
而且移植非常的困难

663
00:19:42,100 --> 00:19:43,366
特别是从向量机

664
00:19:43,366 --> 00:19:44,866
转向AI集群

665
00:19:44,900 --> 00:19:46,900
从大型机转向AI集群

666
00:19:46,900 --> 00:19:48,100
后面可以看到

667
00:19:48,100 --> 00:19:49,900
从2,000年到2010年

668
00:19:49,900 --> 00:19:52,166
整体是社区软件的崛起

669
00:19:52,233 --> 00:19:53,966
出现了越来越多可复用

670
00:19:53,966 --> 00:19:56,000
开源的框架和开源的代码库

671
00:19:56,000 --> 00:19:57,400
和开源的软件

672
00:19:57,400 --> 00:19:58,300
那可以看到

673
00:19:58,333 --> 00:19:59,800
不管是流体力学

674
00:19:59,800 --> 00:20:00,266
分子模拟

675
00:20:00,300 --> 00:20:00,933
天气预报

676
00:20:00,933 --> 00:20:03,533
宇宙学还有分子结构

677
00:20:03,533 --> 00:20:06,166
里面的代表的开源的软件也很多

678
00:20:06,166 --> 00:20:07,900
而且掌握的基础的内容

679
00:20:07,933 --> 00:20:09,000
也慢慢偏向于底层

680
00:20:09,000 --> 00:20:10,866
AI计算的相关的内容

681
00:20:10,900 --> 00:20:12,500
所以现在就越往后

682
00:20:12,500 --> 00:20:13,766
可以分两个

683
00:20:13,766 --> 00:20:15,100
第一个就是专业人员

684
00:20:15,133 --> 00:20:16,600
使用专业的工具

685
00:20:16,600 --> 00:20:18,100
那关于计算机的人员

686
00:20:18,133 --> 00:20:21,200
就可以更好地去抽象出底层的能力

687
00:20:21,200 --> 00:20:23,833
去支撑专业的软件

688
00:20:24,900 --> 00:20:26,233
那到了第三个阶段

689
00:20:26,233 --> 00:20:28,366
也就是最近多学科

690
00:20:28,366 --> 00:20:30,600
跟AI进行一个融合

691
00:20:30,600 --> 00:20:31,633
例如气象预测中

692
00:20:31,633 --> 00:20:32,666
盘古大模型

693
00:20:32,700 --> 00:20:34,233
这种Diffusion model

694
00:20:34,300 --> 00:20:36,733
跟气候预测相关的应用

695
00:20:36,733 --> 00:20:37,600
连接在一起

696
00:20:37,600 --> 00:20:39,600
所以又出现了各种各样的伏羲大模型

697
00:20:39,600 --> 00:20:41,466
是吧可能大家连名字都没听过

698
00:20:41,500 --> 00:20:43,433
因为这是个非常垂直的领域

699
00:20:43,433 --> 00:20:44,633
当然还有Kubernetes

700
00:20:44,633 --> 00:20:47,066
加HPC加AI的工作流

701
00:20:47,100 --> 00:20:48,433
进行一个融合

702
00:20:48,566 --> 00:20:50,700
回到行业应用

703
00:20:50,733 --> 00:20:51,100
第一个

704
00:20:51,100 --> 00:20:52,900
就是基础的学科的应用

705
00:20:52,900 --> 00:20:55,100
包括往右边看看的核爆的模拟

706
00:20:55,100 --> 00:20:56,600
还有高性能的物理

707
00:20:56,600 --> 00:20:57,000
这里面

708
00:20:57,000 --> 00:20:58,100
可以发现

709
00:20:58,233 --> 00:21:00,266
不管是行业应用软件也好

710
00:21:00,300 --> 00:21:01,933
还是基础应用软件也好

711
00:21:01,933 --> 00:21:03,233
更多的提供了

712
00:21:03,233 --> 00:21:04,800
为计算机的人员

713
00:21:04,800 --> 00:21:06,366
就提供了更多相关的内容

714
00:21:06,366 --> 00:21:07,800
例如自适应网格的加密了

715
00:21:07,800 --> 00:21:08,666
异步的通讯

716
00:21:08,700 --> 00:21:10,833
还有流式的处理器的框架了

717
00:21:10,833 --> 00:21:13,166
这些都是能够做的事情

718
00:21:13,166 --> 00:21:14,200
当然了边缘的计算

719
00:21:14,200 --> 00:21:14,966
物理的处理了

720
00:21:14,966 --> 00:21:17,300
还有一些非常专业的术语

721
00:21:17,333 --> 00:21:18,766
或者非常专业的内容

722
00:21:18,766 --> 00:21:21,966
就由对应学科的专家去完成

723
00:21:21,966 --> 00:21:23,200
所以现在来看到

724
00:21:23,200 --> 00:21:24,200
基本上应用软件

725
00:21:24,200 --> 00:21:25,300
也分开了

726
00:21:25,333 --> 00:21:27,333
专门提供应用软件

727
00:21:27,333 --> 00:21:30,733
然后专门提供应用软件的加速的算法

728
00:21:30,733 --> 00:21:32,333
那包括在工程制造里面

729
00:21:32,333 --> 00:21:33,566
可以看到飞机的制造

730
00:21:33,566 --> 00:21:35,566
还有汽车的碰撞的实验

731
00:21:35,566 --> 00:21:38,000
现在大量用了英伟达的GPU

732
00:21:38,000 --> 00:21:40,400
去进行一个并行的计算和并行的模拟

733
00:21:40,400 --> 00:21:42,500
也提供了很多混合计算精度

734
00:21:42,533 --> 00:21:43,833
还有很多数字孪生

735
00:21:43,833 --> 00:21:47,100
实时校准相关的一些功能

736
00:21:47,233 --> 00:21:49,600
当然了还离不开算地

737
00:21:49,600 --> 00:21:51,433
地球科学相关的领域了

738
00:21:51,433 --> 00:21:51,866
这里面

739
00:21:51,900 --> 00:21:53,166
更多的网格的计算

740
00:21:53,166 --> 00:21:55,966
还有波形的推演相关的内容

741
00:21:55,966 --> 00:21:57,233
很多人是用了Tensor core

742
00:21:57,233 --> 00:22:00,233
英伟达的一些硬件去做加速

743
00:22:00,233 --> 00:22:01,466
那可以看到这里面

744
00:22:01,500 --> 00:22:02,933
就像刚才ZOMI讲到

745
00:22:02,933 --> 00:22:03,400
基本上

746
00:22:03,400 --> 00:22:05,233
也慢慢的做了一个分开

747
00:22:05,233 --> 00:22:06,566
从专业的软件

748
00:22:06,566 --> 00:22:08,166
到了后面的专业的软件

749
00:22:08,166 --> 00:22:09,166
开源的组件

750
00:22:09,166 --> 00:22:10,900
到AI计算机

751
00:22:10,933 --> 00:22:13,166
能够做并行加速的优化的算法

752
00:22:14,033 --> 00:22:14,833
每一期视频

753
00:22:14,833 --> 00:22:17,866
都是来一个总结跟思考

754
00:22:18,633 --> 00:22:19,966
在这一系列视频里面

755
00:22:19,966 --> 00:22:21,600
了解了高性能计算

756
00:22:21,600 --> 00:22:23,866
HPC里面的核心的运算

757
00:22:23,900 --> 00:22:24,733
基础的软件

758
00:22:24,733 --> 00:22:26,900
还有应用软件相关的内容

759
00:22:26,900 --> 00:22:27,633
那底层硬件

760
00:22:27,633 --> 00:22:28,833
主要是高性能的处理器

761
00:22:28,833 --> 00:22:31,500
存储网络和服务器

762
00:22:31,566 --> 00:22:32,900
那基础的软件

763
00:22:32,933 --> 00:22:34,833
有编译器运行时计算库

764
00:22:36,500 --> 00:22:38,166
中间的通讯中间件

765
00:22:38,166 --> 00:22:39,966
还有存储调度相关的系统

766
00:22:39,966 --> 00:22:41,033
而应用软件

767
00:22:41,033 --> 00:22:44,733
更多的是跟行业相关相结合

768
00:22:44,733 --> 00:22:46,533
了解HPC最重要的作用

769
00:22:46,533 --> 00:22:49,000
就是帮更好的去了解AI集群

770
00:22:49,000 --> 00:22:50,500
现在其实是大量的借鉴了

771
00:22:50,533 --> 00:22:53,000
HPC相关的技术和概念

772
00:22:53,000 --> 00:22:53,700
那现在

773
00:22:53,733 --> 00:22:55,500
也有很多相关的技术点

774
00:22:55,500 --> 00:22:56,300
继承下来

775
00:22:56,300 --> 00:22:59,200
因此再聊AI Infra

776
00:22:59,200 --> 00:23:00,700
底层的集群的时候

777
00:23:00,733 --> 00:23:04,533
更多的会去借鉴HPC相关的内容

778
00:23:04,533 --> 00:23:06,933
那今天的视频就到这里为止了

779
00:23:06,933 --> 00:23:07,433
谢谢各位

780
00:23:07,433 --> 00:23:08,400
拜了个拜

