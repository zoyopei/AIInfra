1
00:00:00,000 --> 00:00:02,433
内容/录制:Z0MI酱，视频后期/字幕:梁嘉铭

2
00:00:02,433 --> 00:00:03,866
hello家人们大家好

3
00:00:03,900 --> 00:00:04,833
锄禾日当午

4
00:00:04,833 --> 00:00:06,500
上班好辛苦

5
00:00:07,533 --> 00:00:09,233
这里是ZOMI电台

6
00:00:09,233 --> 00:00:11,266
今天来了一个新的内容

7
00:00:11,300 --> 00:00:14,600
看一下高性能计算的整体的发展趋势

8
00:00:14,833 --> 00:00:16,766
在整一个系列里面

9
00:00:16,766 --> 00:00:19,033
现在来到了计算集群之路

10
00:00:19,033 --> 00:00:20,200
那在上一个视频

11
00:00:20,200 --> 00:00:21,066
跟大家分享了

12
00:00:21,100 --> 00:00:23,233
高性能计算的一个整体的定义

13
00:00:23,233 --> 00:00:24,100
现在看一下

14
00:00:24,133 --> 00:00:26,533
高性能计算的发展趋势

15
00:00:26,533 --> 00:00:27,000
说实话

16
00:00:27,000 --> 00:00:29,766
ZOMI觉得集群计算的发展历程

17
00:00:29,766 --> 00:00:31,633
跟发展的一个趋势

18
00:00:31,633 --> 00:00:33,366
可能调换一下更合适

19
00:00:33,366 --> 00:00:36,100
不过没关系大家倒着来看也行

20
00:00:36,133 --> 00:00:38,100
那在今天的这期视频

21
00:00:38,100 --> 00:00:39,100
主要是看一下

22
00:00:39,100 --> 00:00:41,800
HPC整体的发展的趋势

23
00:00:41,800 --> 00:00:45,433
包括软硬件的架构跟相关的应用

24
00:00:46,000 --> 00:00:48,466
那当然会有一些小伙伴会问ZOMI诶

25
00:00:48,500 --> 00:00:49,633
到底你分享的东西

26
00:00:49,633 --> 00:00:51,066
有没有一个序列可以看

27
00:00:51,100 --> 00:00:52,433
来欢迎大家

28
00:00:52,433 --> 00:00:54,633
因为每一期视频都会有一个链接

29
00:00:54,633 --> 00:00:56,033
github里面的AI infra

30
00:00:56,033 --> 00:00:57,400
这里面的这条链接

31
00:00:57,400 --> 00:01:00,300
去看一下ZOMI关于整个AI infra

32
00:01:00,466 --> 00:01:02,033
分享相关的内容

33
00:01:02,033 --> 00:01:02,633
那今天

34
00:01:02,633 --> 00:01:06,200
现在已经到了AI的集群这个模块

35
00:01:06,233 --> 00:01:07,500
对应的知识点

36
00:01:07,533 --> 00:01:11,200
就是这里面AI集群相关的内容了

37
00:01:12,633 --> 00:01:14,866
在深入了解高性能计算发展趋势

38
00:01:14,900 --> 00:01:15,566
之前

39
00:01:15,566 --> 00:01:19,266
看一下整个计算集群的三类区别

40
00:01:19,300 --> 00:01:22,033
也就是上一节的一个简单的小总结

41
00:01:22,033 --> 00:01:23,000
那比较明确

42
00:01:23,000 --> 00:01:24,600
现在的计算

43
00:01:24,600 --> 00:01:25,800
主要是高性能计算

44
00:01:25,800 --> 00:01:27,833
或者人工智能的计算

45
00:01:27,933 --> 00:01:29,933
当然了高性能计算用的数据类型

46
00:01:29,933 --> 00:01:31,733
更多是FP64

47
00:01:31,733 --> 00:01:33,133
那AI的计算 

48
00:01:33,133 --> 00:01:36,433
通用的格式是FP16和BF16它们两个

49
00:01:36,433 --> 00:01:38,233
都是高并行

50
00:01:38,233 --> 00:01:40,666
也就需要非常非常多的AI

51
00:01:40,700 --> 00:01:44,900
GPU NPU或者特殊的计算单元去实现

52
00:01:45,366 --> 00:01:47,100
除了计算密集型以外

53
00:01:47,133 --> 00:01:49,200
你们也需要通讯密集

54
00:01:49,200 --> 00:01:51,900
这个就是计算产业最大的区别

55
00:01:51,966 --> 00:01:53,200
那云数据中心

56
00:01:53,200 --> 00:01:55,866
更多的是互联网里面的云

57
00:01:55,900 --> 00:01:56,633
阿里云腾讯云

58
00:01:56,633 --> 00:01:58,866
百度云各种各样的里面

59
00:01:58,900 --> 00:02:00,400
更多强调的是高并发

60
00:02:00,400 --> 00:02:02,033
高吞吐可以同一时间

61
00:02:02,033 --> 00:02:03,900
容纳非常大量的用户

62
00:02:03,933 --> 00:02:05,966
进行服务的访问请求

63
00:02:05,966 --> 00:02:06,966
整体的通讯

64
00:02:06,966 --> 00:02:08,300
是松耦合

65
00:02:08,333 --> 00:02:09,500
今天重点

66
00:02:09,500 --> 00:02:11,633
去看一下高性能计算的发展趋势

67
00:02:11,633 --> 00:02:13,600
因为人工智能计算

68
00:02:13,600 --> 00:02:17,200
AIinfra其实有非常非常多的内容

69
00:02:17,200 --> 00:02:19,433
借鉴高性能计算

70
00:02:19,600 --> 00:02:21,233
还是了解前人

71
00:02:21,233 --> 00:02:22,100
了解先辈

72
00:02:22,200 --> 00:02:23,566
了解高性能计算

73
00:02:23,566 --> 00:02:25,633
之前做的很多相关的工作

74
00:02:25,633 --> 00:02:26,800
然后再反过来看

75
00:02:26,800 --> 00:02:29,666
人工智能计算到底有哪些区别

76
00:02:29,700 --> 00:02:31,300
需要新增哪些东西

77
00:02:31,833 --> 00:02:33,066
那在这期视频里面

78
00:02:33,100 --> 00:02:36,166
可能会分开三个内容跟大家去分享

79
00:02:36,166 --> 00:02:37,233
每一个内容

80
00:02:37,233 --> 00:02:38,700
里面的东西也比较多

81
00:02:38,733 --> 00:02:40,533
有可能拆分成2到3个视频

82
00:02:40,533 --> 00:02:40,900
第一个

83
00:02:40,900 --> 00:02:44,000
就是看一下最核心的硬件

84
00:02:44,000 --> 00:02:45,866
包括高性能的处理器了

85
00:02:45,900 --> 00:02:46,900
高性能的存储了

86
00:02:46,900 --> 00:02:49,400
高性能的网络和高性能的服务器

87
00:02:49,600 --> 00:02:51,166
存算网一体

88
00:02:51,166 --> 00:02:54,433
组成整体的HPC的核心的硬件

89
00:02:54,733 --> 00:02:55,133
第二个

90
00:02:55,133 --> 00:02:56,733
看一下基础的软件

91
00:02:56,733 --> 00:02:58,200
HPC的基础软件

92
00:02:58,200 --> 00:02:59,466
就包括编译器

93
00:02:59,500 --> 00:03:00,133
运行时

94
00:03:00,133 --> 00:03:00,800
计算库

95
00:03:00,800 --> 00:03:02,066
通讯的中间件

96
00:03:02,100 --> 00:03:04,033
存储系统和调度系统

97
00:03:04,033 --> 00:03:05,366
当然了像操作系统

98
00:03:05,366 --> 00:03:06,166
还有数据库

99
00:03:06,166 --> 00:03:09,066
最传统最基础的就不再赘述了

100
00:03:09,066 --> 00:03:09,800
那第三个

101
00:03:09,800 --> 00:03:10,566
就比较简单了

102
00:03:10,566 --> 00:03:11,833
看一下整个HPC

103
00:03:11,833 --> 00:03:13,166
的应用软件发展历程

104
00:03:13,166 --> 00:03:15,100
和行业的应用的趋势

105
00:03:15,133 --> 00:03:17,000
HPC主要是算什么

106
00:03:17,000 --> 00:03:18,566
在之前已经讲过了

107
00:03:18,566 --> 00:03:20,566
算天算年算地算物

108
00:03:20,800 --> 00:03:21,833
各种各样

109
00:03:21,833 --> 00:03:23,600
可能平时接触的比较少

110
00:03:23,600 --> 00:03:27,066
但是对于科研还有最高技术领域

111
00:03:27,100 --> 00:03:28,733
非常的有作用

112
00:03:29,466 --> 00:03:32,900
现在马上来到了高性能的硬件

113
00:03:32,933 --> 00:03:34,566
HPC的最核心的硬件

114
00:03:34,566 --> 00:03:35,266
说实话

115
00:03:35,300 --> 00:03:38,033
整个HPC的硬件发展和未来趋势

116
00:03:38,100 --> 00:03:40,766
主要是从四个维度去看

117
00:03:40,766 --> 00:03:43,066
第一个就是高性能的网络

118
00:03:43,100 --> 00:03:43,766
网络很重要

119
00:03:43,766 --> 00:03:46,166
互联第二个就高性能的处理器

120
00:03:46,166 --> 00:03:48,366
从X86到高性能的arm

121
00:03:48,566 --> 00:03:50,266
到了服务器

122
00:03:50,300 --> 00:03:52,600
高性能的服务器和高性能的存储

123
00:03:52,600 --> 00:03:54,600
所以你会发现整体的逻辑

124
00:03:54,600 --> 00:03:57,166
都是围绕着这4方面进行展开

125
00:03:57,166 --> 00:03:57,866
那首先

126
00:03:57,900 --> 00:03:58,600
这里面

127
00:03:58,600 --> 00:04:00,800
笼统的跟大家去分享一下

128
00:04:00,800 --> 00:04:03,066
第一个就是高性能的处理器

129
00:04:03,100 --> 00:04:06,000
从通用的多核到异构的计算

130
00:04:06,000 --> 00:04:08,366
就是有很多个CPU

131
00:04:08,366 --> 00:04:09,200
然后再向NPU

132
00:04:09,200 --> 00:04:10,866
还有各种各样的协处理器

133
00:04:11,000 --> 00:04:12,966
这个就是高性能的网络

134
00:04:12,966 --> 00:04:15,566
网络其实经历了很多的发展

135
00:04:15,566 --> 00:04:16,966
从一开始的低延迟

136
00:04:16,966 --> 00:04:20,033
到现在的高带宽互联互通

137
00:04:20,100 --> 00:04:21,700
那存储也蛮有意思

138
00:04:21,700 --> 00:04:24,100
从容量扩展到存算协同

139
00:04:24,100 --> 00:04:25,133
也就越做越细

140
00:04:25,133 --> 00:04:26,433
到分层存储

141
00:04:26,433 --> 00:04:27,766
所以说高性能存储里面

142
00:04:27,766 --> 00:04:29,433
也有很多新的事情

143
00:04:29,433 --> 00:04:31,766
那最后就是高性能的服务器

144
00:04:31,800 --> 00:04:33,766
更多的强调风火水电

145
00:04:33,766 --> 00:04:34,766
从单机的性能

146
00:04:34,766 --> 00:04:37,833
到绿色化的一个整体的集群的建设

147
00:04:39,133 --> 00:04:39,933
事不宜迟

148
00:04:39,933 --> 00:04:41,500
马上来到了第一个内容

149
00:04:41,500 --> 00:04:42,766
今天的内容特别的多

150
00:04:42,766 --> 00:04:46,100
简单看一下高性能的处理器那

151
00:04:46,133 --> 00:04:47,400
首先高性能处理器

152
00:04:47,400 --> 00:04:48,700
其实整体发展

153
00:04:48,733 --> 00:04:50,900
是经历了蛮多的一个历程

154
00:04:50,900 --> 00:04:51,600
一开始

155
00:04:51,600 --> 00:04:54,033
主要是由CPU进行一个主导

156
00:04:54,100 --> 00:04:55,533
早期HPC

157
00:04:55,533 --> 00:04:58,200
主要是依赖于大规模并行的CPU

158
00:04:58,200 --> 00:04:59,233
所以这里面的CPU

159
00:04:59,233 --> 00:05:02,466
就不再是家用的或者PC上面的CPU

160
00:05:02,500 --> 00:05:04,300
比较明确的英特尔的CPU

161
00:05:04,300 --> 00:05:06,700
你会发现它会比较长

162
00:05:06,700 --> 00:05:08,733
就是英特尔的xeon的一个系列

163
00:05:08,733 --> 00:05:12,400
另外的话AMD相对来说方正一点

164
00:05:12,600 --> 00:05:13,566
在技术上

165
00:05:13,566 --> 00:05:14,800
除了提供

166
00:05:14,800 --> 00:05:17,900
就是增加更多的核心数量以外

167
00:05:17,933 --> 00:05:19,233
还有两个主要的功能

168
00:05:19,233 --> 00:05:21,033
第一个就是提频

169
00:05:21,033 --> 00:05:23,233
因为在整个集群里面

170
00:05:23,233 --> 00:05:25,400
HPC是计算中心嘛

171
00:05:25,400 --> 00:05:27,500
功耗可以做的非常的高

172
00:05:27,533 --> 00:05:29,633
一个液冷或者风冷

173
00:05:29,633 --> 00:05:31,166
也提供的非常的充足

174
00:05:31,166 --> 00:05:32,600
所以说提升频率

175
00:05:32,600 --> 00:05:35,166
会使得整个CPU的功耗上去

176
00:05:35,166 --> 00:05:36,066
但是没关系

177
00:05:36,100 --> 00:05:37,966
因为整体的服务器形态

178
00:05:37,966 --> 00:05:39,866
能够很好的降温

179
00:05:39,900 --> 00:05:40,566
那第三点

180
00:05:40,566 --> 00:05:42,266
就是优化指令集

181
00:05:42,300 --> 00:05:44,100
实现更好的性能

182
00:05:44,100 --> 00:05:46,566
主要是三个不同的技术点

183
00:05:46,566 --> 00:05:47,400
那可以看到

184
00:05:47,400 --> 00:05:49,300
刚才两个英调的xeon

185
00:05:49,333 --> 00:05:50,900
还有AMD的opteron

186
00:05:50,900 --> 00:05:54,100
都会组成对应的机架式的服务器

187
00:05:54,100 --> 00:05:54,966
那现在后面

188
00:05:54,966 --> 00:05:56,033
讲服务器的时候

189
00:05:56,033 --> 00:05:57,100
也会重点的强调

190
00:05:57,133 --> 00:05:59,800
现在已经不再是用刀片式的服务器

191
00:05:59,800 --> 00:06:02,633
都是用机架式的服务器的形态了

192
00:06:02,966 --> 00:06:03,566
那另外的话

193
00:06:03,566 --> 00:06:04,400
看一下

194
00:06:04,400 --> 00:06:06,800
处理器的第二个发展历程

195
00:06:06,800 --> 00:06:09,033
也就是协处理器的一个兴起

196
00:06:09,100 --> 00:06:10,800
看一下协处理器

197
00:06:10,800 --> 00:06:12,066
主要是有好几种

198
00:06:12,066 --> 00:06:14,033
一种就是专用的加速

199
00:06:14,033 --> 00:06:15,766
例如英特尔的那个

200
00:06:15,766 --> 00:06:17,233
xeon的phi里面

201
00:06:17,233 --> 00:06:19,000
就用的是Mic的架构

202
00:06:19,000 --> 00:06:21,200
那尝试过众核的路线

203
00:06:21,200 --> 00:06:23,700
也就这里面有非常非常多

204
00:06:23,733 --> 00:06:24,766
大家可以看到

205
00:06:24,766 --> 00:06:28,366
非常多这种小的小圈圈或者小的芯粒

206
00:06:28,366 --> 00:06:31,633
那这个就是引入了众核的架构

207
00:06:31,633 --> 00:06:32,633
众核的CPU

208
00:06:32,633 --> 00:06:33,700
众核的X86

209
00:06:33,733 --> 00:06:34,366
那另外的话

210
00:06:34,366 --> 00:06:36,900
现在用的特别特别的多

211
00:06:36,933 --> 00:06:39,933
就是GPU的加速了

212
00:06:40,100 --> 00:06:42,966
英伟达是第一个把CUDA

213
00:06:42,966 --> 00:06:47,300
革命性的把GPU然后变成GP GPU

214
00:06:47,333 --> 00:06:50,600
所谓的GPU一开始叫做GRAPH pRoCEss unit

215
00:06:50,633 --> 00:06:52,033
那现在的GPU

216
00:06:52,033 --> 00:06:54,000
实际上叫做GP GPU

217
00:06:54,000 --> 00:06:55,666
所谓的GP

218
00:06:55,700 --> 00:06:59,100
就是通用计算了

219
00:06:59,100 --> 00:07:03,133
那整体来说应该是2016年的那一代

220
00:07:03,133 --> 00:07:04,800
英伟达的Tesla的架构

221
00:07:04,800 --> 00:07:06,466
就成为了HPC里面

222
00:07:06,500 --> 00:07:09,166
通用并行计算的一个标杆

223
00:07:09,333 --> 00:07:11,833
那可以往右边的这个图看一下

224
00:07:11,833 --> 00:07:14,366
里面有非常非常多的SM

225
00:07:14,366 --> 00:07:15,600
放大看一看

226
00:07:15,600 --> 00:07:17,666
有非常多的计算的处

227
00:07:17,700 --> 00:07:19,366
这里面这些所有的计算簇

228
00:07:19,366 --> 00:07:22,200
都可以算各种各样通用的算力

229
00:07:22,200 --> 00:07:22,433
当然

230
00:07:22,433 --> 00:07:26,400
它提供的是大规模的通用的并行能力

231
00:07:27,500 --> 00:07:30,100
那到了第三个阶段

232
00:07:30,100 --> 00:07:32,400
就是国产的突破了

233
00:07:32,400 --> 00:07:34,500
例如国产的申威

234
00:07:34,533 --> 00:07:37,733
就是他做成集群计算的时候叫做申威

235
00:07:37,800 --> 00:07:40,200
那申威的SW 26010

236
00:07:40,200 --> 00:07:44,000
也就是256个核加一个主核

237
00:07:44,000 --> 00:07:45,633
通过这种方式

238
00:07:45,633 --> 00:07:46,633
就是一个主核

239
00:07:46,633 --> 00:07:48,766
然后加很多个小核的方式

240
00:07:48,766 --> 00:07:51,466
实现每秒3亿万次的浮点运算

241
00:07:51,500 --> 00:07:54,600
就3亿万次的FP64的Flops的支撑

242
00:07:54,600 --> 00:07:56,000
国产E级的算力

243
00:07:56,000 --> 00:07:57,766
在上一集视频已经讲过

244
00:07:57,766 --> 00:08:00,100
跟大家分享过E级的算力

245
00:08:00,133 --> 00:08:01,333
基本上超算

246
00:08:01,333 --> 00:08:02,033
然后

247
00:08:02,033 --> 00:08:06,500
他最主要的就是采用了自主的指令集

248
00:08:06,566 --> 00:08:07,300
那当然

249
00:08:07,333 --> 00:08:08,633
前十年

250
00:08:08,633 --> 00:08:11,566
其实都会在整个超算的TOP500上面

251
00:08:11,566 --> 00:08:12,500
去打榜

252
00:08:12,533 --> 00:08:14,233
但是基于国家战略的发展

253
00:08:14,233 --> 00:08:15,466
你没有发现

254
00:08:15,500 --> 00:08:17,633
最近这五年是没有打榜

255
00:08:17,633 --> 00:08:18,300
最近这五年

256
00:08:18,333 --> 00:08:19,633
国家就再没有宣传

257
00:08:19,633 --> 00:08:21,600
说他的一个超级计算机

258
00:08:21,600 --> 00:08:23,433
HPC特别的牛逼

259
00:08:23,433 --> 00:08:25,800
都开始低调起来了

260
00:08:26,000 --> 00:08:26,433
那现在

261
00:08:26,433 --> 00:08:28,633
看一下第三个发展阶段里面

262
00:08:28,633 --> 00:08:30,066
还有一个很重要的事件

263
00:08:30,100 --> 00:08:32,533
就是Arm的架构的突破

264
00:08:32,533 --> 00:08:34,433
在HPC场景蛮有意思

265
00:08:34,433 --> 00:08:35,700
以前以为Arm的架构

266
00:08:35,733 --> 00:08:38,300
只能用于手机或者魔改协处理器

267
00:08:38,300 --> 00:08:39,933
还有做一些MCU

268
00:08:40,066 --> 00:08:41,433
现在arm的架构

269
00:08:41,433 --> 00:08:44,666
开始慢慢的进入了HPC的时代

270
00:08:44,700 --> 00:08:47,100
去打破整个X86

271
00:08:47,100 --> 00:08:49,366
不管是英特尔的还是AMD

272
00:08:49,366 --> 00:08:51,866
一个关于HPC的垄断了

273
00:08:51,900 --> 00:08:54,933
因为HPC这块蛋糕实在是太大了

274
00:08:54,933 --> 00:08:56,000
那往下面看一下

275
00:08:56,000 --> 00:08:57,233
有两个标志性

276
00:08:57,233 --> 00:08:59,166
ZOMI觉得整个产业很有意思

277
00:08:59,166 --> 00:08:59,500
第一个

278
00:08:59,533 --> 00:09:01,833
就是英伟达的Grace的CPU

279
00:09:01,833 --> 00:09:02,600
那知道

280
00:09:02,600 --> 00:09:03,966
英伟达推出

281
00:09:03,966 --> 00:09:04,833
左边的这个

282
00:09:04,833 --> 00:09:06,300
就是Grace的CPU

283
00:09:06,333 --> 00:09:07,033
右边这个

284
00:09:07,033 --> 00:09:09,233
就是hope架构的GPU

285
00:09:09,366 --> 00:09:09,966
那英伟达

286
00:09:09,966 --> 00:09:11,800
就推出了一个Grace跟Hopper

287
00:09:11,900 --> 00:09:15,100
就Grace Hopper的一个整体的产品形态

288
00:09:15,100 --> 00:09:17,333
提供非常澎湃的算力

289
00:09:17,333 --> 00:09:18,833
那ZOMI觉得有两个特性

290
00:09:18,833 --> 00:09:21,300
是特别特别的重要

291
00:09:21,333 --> 00:09:21,700
第一个

292
00:09:21,700 --> 00:09:24,233
就是提供内存的子系统的革新

293
00:09:24,233 --> 00:09:25,366
就是左边看一下

294
00:09:25,366 --> 00:09:25,800
这里面

295
00:09:25,800 --> 00:09:28,466
有很多个这种小的贴片

296
00:09:28,500 --> 00:09:29,100
那这些

297
00:09:29,100 --> 00:09:31,133
都是LPDDR5

298
00:09:31,133 --> 00:09:34,333
那它接上纠错码能够提升两倍的性能

299
00:09:34,366 --> 00:09:34,766
第二个

300
00:09:34,766 --> 00:09:37,766
就是CPU跟GPU的一致性缓存

301
00:09:37,766 --> 00:09:40,266
可以看到这里面是DDR

302
00:09:40,300 --> 00:09:42,433
然后右边的这几块

303
00:09:42,433 --> 00:09:45,800
是HBM通过一致性的缓存

304
00:09:45,800 --> 00:09:48,600
让这整一款整一款产品

305
00:09:48,600 --> 00:09:49,966
而不是一款芯片

306
00:09:49,966 --> 00:09:53,700
能够实现NV link的C2C的一个互传

307
00:09:53,733 --> 00:09:56,133
整体直接时延降到1/10

308
00:09:56,133 --> 00:09:59,033
如果我用X86 跟Hopper就是GPU

309
00:09:59,033 --> 00:10:00,900
它可能整体的时延没降到那么多

310
00:10:00,933 --> 00:10:02,766
而且不能做一致性的缓存

311
00:10:02,766 --> 00:10:04,666
也就是DDR跟HBM合起来

312
00:10:04,700 --> 00:10:07,033
可以看作一个大的内存池

313
00:10:07,066 --> 00:10:08,033
非常的有意思

314
00:10:08,033 --> 00:10:08,500
而这里面

315
00:10:08,533 --> 00:10:10,533
看一下右边的架构

316
00:10:10,533 --> 00:10:13,033
里面有很多的一个小块块

317
00:10:13,033 --> 00:10:14,766
这里面就有很多的计算核

318
00:10:14,766 --> 00:10:16,066
橙色的是计算核

319
00:10:16,100 --> 00:10:18,533
然后对应的绿色的就是内存

320
00:10:18,533 --> 00:10:20,233
那可以看一下光照

321
00:10:20,233 --> 00:10:21,633
就紫外线光照图

322
00:10:21,633 --> 00:10:22,500
这里面也可以看到

323
00:10:22,533 --> 00:10:24,766
有很多个这种小块块了

324
00:10:24,766 --> 00:10:27,266
但可以放大了自己去看一看了

325
00:10:27,433 --> 00:10:28,466
那第二个

326
00:10:28,500 --> 00:10:29,733
ZOMI觉得特别有意思

327
00:10:29,733 --> 00:10:32,033
就是要聊一聊华为了

328
00:10:32,133 --> 00:10:32,566
那华为

329
00:10:32,566 --> 00:10:34,366
可以看到这一个板卡里面

330
00:10:34,366 --> 00:10:37,266
挂的是两块鲲鹏的920

331
00:10:37,300 --> 00:10:39,966
最终组成一个泰山的服务器

332
00:10:40,066 --> 00:10:41,766
在1U的服务器里面

333
00:10:41,766 --> 00:10:43,600
可以挂两块

334
00:10:43,600 --> 00:10:46,266
在一个AI的集群里面

335
00:10:46,300 --> 00:10:49,533
可以挂四块的一个鲲鹏的920

336
00:10:49,533 --> 00:10:51,000
让看一下它的主要特性

337
00:10:51,000 --> 00:10:52,833
那鲲鹏的920

338
00:10:52,833 --> 00:10:55,166
主要是arm base的一个处理器

339
00:10:55,166 --> 00:10:57,033
那arm base就很重要了

340
00:10:57,033 --> 00:10:59,900
那整体是使用7纳米的工艺

341
00:10:59,933 --> 00:11:00,733
arm授权华为自

342
00:11:00,733 --> 00:11:01,833
主去设计

343
00:11:01,833 --> 00:11:03,800
那最主要的做一些性能的改进

344
00:11:03,800 --> 00:11:06,700
就是优化分支预测的一些算法

345
00:11:06,733 --> 00:11:08,133
提升预算单元的数量

346
00:11:08,133 --> 00:11:09,566
哎就是ALU增加

347
00:11:09,566 --> 00:11:10,900
核心增加

348
00:11:10,933 --> 00:11:12,766
还有改进内存子系统的架构

349
00:11:12,766 --> 00:11:14,800
从而提升性能

350
00:11:14,933 --> 00:11:19,100
那提到整体的arm跟HPC

351
00:11:19,100 --> 00:11:20,033
arm进入HPC

352
00:11:20,033 --> 00:11:22,200
其实有几个事情要改变

353
00:11:22,200 --> 00:11:23,966
因为手机端的arm

354
00:11:23,966 --> 00:11:26,666
最重要的是采用精简的指令集

355
00:11:26,700 --> 00:11:28,533
尽可能的指令不要太多

356
00:11:28,533 --> 00:11:29,233
不要太复杂

357
00:11:29,233 --> 00:11:30,600
方便做控制

358
00:11:30,666 --> 00:11:31,166
另外的话

359
00:11:31,166 --> 00:11:33,800
核心大部分都是多核低频

360
00:11:33,800 --> 00:11:36,200
所以基本上经常会调频

361
00:11:36,200 --> 00:11:37,266
手机里面

362
00:11:37,300 --> 00:11:39,633
不同的任务执行在不同的核心里面

363
00:11:39,633 --> 00:11:40,066
但是

364
00:11:40,100 --> 00:11:42,700
手机的任务不会说都非常的重要

365
00:11:42,700 --> 00:11:43,733
基本上屏幕小嘛

366
00:11:43,733 --> 00:11:45,600
所以会聚焦到几个任务

367
00:11:45,600 --> 00:11:48,000
或者几个对应的大的APP里面

368
00:11:48,000 --> 00:11:48,633
那另外的话

369
00:11:48,633 --> 00:11:51,966
手机主要是提供一个低带宽的LPDDR

370
00:11:51,966 --> 00:11:53,600
还有动态的频率

371
00:11:53,600 --> 00:11:57,166
那对应的如果arm架构想进入HPC

372
00:11:57,166 --> 00:11:59,600
就要经过几个新的改变

373
00:11:59,600 --> 00:12:00,000
第一个

374
00:12:00,000 --> 00:12:01,400
就扩展SIMD

375
00:12:01,400 --> 00:12:04,633
单指令多数据的一个对应的指令集

376
00:12:04,700 --> 00:12:08,400
让指令集满足HPC的场景

377
00:12:08,500 --> 00:12:11,533
第二个就是核心非常的多

378
00:12:11,533 --> 00:12:12,766
整体的复式操算

379
00:12:12,766 --> 00:12:15,100
用的是512个众核

380
00:12:15,133 --> 00:12:17,500
另外的话可能HPC里面

381
00:12:17,500 --> 00:12:19,900
就不再简单的用LPDDR了 

382
00:12:19,900 --> 00:12:23,233
更多的可能会采用HBM

383
00:12:23,233 --> 00:12:26,033
还有一些精细化的一个功耗的控制

384
00:12:26,033 --> 00:12:26,800
那不管怎么样

385
00:12:26,800 --> 00:12:27,566
看一下

386
00:12:27,566 --> 00:12:31,266
未来又朝哪个方向去发展

387
00:12:31,300 --> 00:12:33,200
刚才主要是跟大家分享了一下

388
00:12:33,200 --> 00:12:36,366
高性能处理器的一个具体的历史过往

389
00:12:36,433 --> 00:12:37,200
那未来

390
00:12:37,200 --> 00:12:39,700
整个HPC的处理的发展趋势

391
00:12:39,733 --> 00:12:40,633
也比较明确

392
00:12:40,633 --> 00:12:43,400
从异构的多算力到国产化

393
00:12:43,400 --> 00:12:44,066
那现在

394
00:12:44,100 --> 00:12:46,566
比较明确的还是以GPU作为主导

395
00:12:46,566 --> 00:12:49,066
去加速整个HPC的市场

396
00:12:49,100 --> 00:12:50,433
因为现在整个HPC

397
00:12:50,433 --> 00:12:52,300
跟GP GPU跟并行

398
00:12:52,333 --> 00:12:54,566
跟AI的融合越来越多了

399
00:12:54,566 --> 00:12:55,966
英伟达的H100

400
00:12:55,966 --> 00:12:57,600
或者AMD的M I 300

401
00:12:57,600 --> 00:12:58,066
现在

402
00:12:58,100 --> 00:13:01,333
是整个HPC里面的一个核心的算力

403
00:13:01,333 --> 00:13:02,600
至少在国外

404
00:13:02,600 --> 00:13:03,500
但是在国内

405
00:13:03,533 --> 00:13:06,300
慢慢的出现了越来越多的代替了

406
00:13:06,300 --> 00:13:08,233
例如华为的昇腾

407
00:13:08,233 --> 00:13:09,666
还有寒武纪

408
00:13:09,700 --> 00:13:10,633
那下面这个图

409
00:13:10,633 --> 00:13:12,800
就华为昇腾的一个超节点

410
00:13:12,966 --> 00:13:15,700
左边跟右边就是昇腾的服务器

411
00:13:15,700 --> 00:13:17,566
A3对应的服务器

412
00:13:17,566 --> 00:13:20,366
那中间就是光模块

413
00:13:20,366 --> 00:13:22,366
光网络的传输

414
00:13:22,366 --> 00:13:25,233
通过上面的非常多的光缆

415
00:13:25,233 --> 00:13:27,833
去跟各种各样的服务器

416
00:13:27,833 --> 00:13:31,600
进行一个数据的交互的和数据的互存

417
00:13:33,566 --> 00:13:34,633
那另外看一下

418
00:13:34,633 --> 00:13:36,666
整体的发展趋势还有哪些

419
00:13:36,700 --> 00:13:38,200
对于单芯片来说

420
00:13:38,200 --> 00:13:40,700
还有chiplet的一个技术的封装

421
00:13:40,733 --> 00:13:42,566
可以看到AMD跟英特尔

422
00:13:42,566 --> 00:13:44,966
其实现在已经通过了多芯片

423
00:13:45,100 --> 00:13:46,000
多芯粒的封装

424
00:13:46,000 --> 00:13:48,433
来提升它的一个集成度和良率

425
00:13:48,433 --> 00:13:50,666
说实话现在的纳米制成的工艺

426
00:13:50,700 --> 00:13:51,833
已经受限了

427
00:13:51,833 --> 00:13:54,466
所以可能更多的会用更多的chiplet

428
00:13:54,500 --> 00:13:55,966
更多的芯粒

429
00:13:55,966 --> 00:13:57,700
通过一起的核封了

430
00:13:57,733 --> 00:13:58,366
当然核封了

431
00:13:58,366 --> 00:14:00,833
这里面有一个中间的介质

432
00:14:00,833 --> 00:14:02,633
通过中间的半导体的介质

433
00:14:02,633 --> 00:14:05,500
把它封装在一个硅的基底下面

434
00:14:05,566 --> 00:14:07,266
另外的话还有一些新的技术

435
00:14:07,300 --> 00:14:09,300
就是存算一体了

436
00:14:09,300 --> 00:14:10,433
现在业界

437
00:14:10,433 --> 00:14:10,900
对于存算

438
00:14:10,933 --> 00:14:13,933
一体用的最多的是台积电的fabric

439
00:14:14,000 --> 00:14:17,100
将单个计算单元进行一个堆叠

440
00:14:17,133 --> 00:14:18,733
假设现在这里面

441
00:14:18,733 --> 00:14:20,900
有一块计算的芯粒了

442
00:14:20,900 --> 00:14:22,600
就会把存储的芯粒

443
00:14:22,600 --> 00:14:24,466
或者存储的元器件

444
00:14:24,500 --> 00:14:27,300
L2的Cache或者L1的Cache封装在上面

445
00:14:27,300 --> 00:14:29,333
进行一个互存的整体

446
00:14:29,333 --> 00:14:32,100
希望通过突破冯诺依曼架构

447
00:14:32,100 --> 00:14:33,233
整体的体系

448
00:14:33,333 --> 00:14:35,000
是存算一体在发展

449
00:14:35,000 --> 00:14:36,766
但是现在存算一体

450
00:14:36,766 --> 00:14:40,033
用的更多的可能是协处理器或者MCU

451
00:14:40,033 --> 00:14:43,000
真正在AI芯片上面用的比较少

452
00:14:43,000 --> 00:14:44,833
因为AI芯片你要改造的话

453
00:14:44,833 --> 00:14:47,233
整个AIinfra层全都要变了

454
00:14:47,233 --> 00:14:48,033
所以现在

455
00:14:48,033 --> 00:14:51,400
还是尽可能的做chiplet的封装

456
00:14:51,400 --> 00:14:52,500
两两配对

457
00:14:52,533 --> 00:14:54,633
两两进行一个堆叠

458
00:14:54,633 --> 00:14:58,033
往上堆叠也是个发展的趋势

459
00:14:59,000 --> 00:15:01,500
果然HPC内容还是很多

460
00:15:02,633 --> 00:15:03,600
讲了这么久了

461
00:15:03,600 --> 00:15:06,666
才来到了高性能的网络

462
00:15:06,833 --> 00:15:07,833
高性能网络

463
00:15:07,933 --> 00:15:08,566
那看一下

464
00:15:08,566 --> 00:15:10,166
高性能网络的整体的发展

465
00:15:10,166 --> 00:15:13,066
实际上也是经过几个历程

466
00:15:13,100 --> 00:15:14,766
第一个就是早期阶段

467
00:15:14,766 --> 00:15:18,433
就是从90年到千禧年之间

468
00:15:18,433 --> 00:15:20,800
那当时候还是以以太网为主

469
00:15:20,800 --> 00:15:23,166
那第一个就是像左边的这个图

470
00:15:23,166 --> 00:15:25,033
就是千兆的一个以太网

471
00:15:25,033 --> 00:15:27,033
整体是因为它的成本比较低

472
00:15:27,033 --> 00:15:28,466
但是延迟比较高

473
00:15:28,500 --> 00:15:29,700
大于100微秒

474
00:15:29,700 --> 00:15:32,533
带宽就成为主要的瓶颈了

475
00:15:32,533 --> 00:15:34,300
那这个就是早期的以太网

476
00:15:34,300 --> 00:15:36,300
但是当时候串服务器

477
00:15:36,300 --> 00:15:38,166
也只能用这种方案

478
00:15:38,433 --> 00:15:38,900
但是

479
00:15:38,933 --> 00:15:42,333
也兴起了像右边的这些专有的网络

480
00:15:42,333 --> 00:15:44,733
例如Myrinet跟Quadrics

481
00:15:44,733 --> 00:15:46,733
这些私有的协议的网络

482
00:15:46,733 --> 00:15:50,100
整体可以把延迟降的非常的低

483
00:15:50,100 --> 00:15:51,433
但是生态

484
00:15:51,433 --> 00:15:53,233
整体来说还是相对比较封闭

485
00:15:53,233 --> 00:15:54,100
而且

486
00:15:54,133 --> 00:15:56,133
看一下左边的这个接口

487
00:15:56,133 --> 00:15:57,433
主要是有网络接口

488
00:15:57,433 --> 00:15:58,666
而右边的这个

489
00:15:58,700 --> 00:16:02,100
接口是特殊的定制化的形态

490
00:16:03,200 --> 00:16:06,233
那网络肯定是在逐步的发展

491
00:16:06,233 --> 00:16:06,700
整体

492
00:16:06,733 --> 00:16:09,366
现在已经形成了一个新的格局

493
00:16:09,366 --> 00:16:12,100
也就是从2010年到现在

494
00:16:12,166 --> 00:16:13,900
有三个内容

495
00:16:13,933 --> 00:16:14,800
或者两个吧

496
00:16:14,800 --> 00:16:17,100
第一个就是以IB为主导

497
00:16:17,133 --> 00:16:18,766
那IB就是Mellanox

498
00:16:18,766 --> 00:16:22,200
虽然现在Mellanox已经被英伟达收购了

499
00:16:22,200 --> 00:16:23,833
整体它是基于RDMA

500
00:16:23,833 --> 00:16:25,666
也就是远程服务访问协议

501
00:16:25,700 --> 00:16:27,900
来实现一个微秒级别的延迟

502
00:16:27,900 --> 00:16:29,833
跟百GB的一个带宽

503
00:16:29,833 --> 00:16:31,966
整体整个Mellanox

504
00:16:32,000 --> 00:16:33,866
在没有被英伟达收购的时候

505
00:16:33,900 --> 00:16:36,133
已经成为了HPC的主流了

506
00:16:36,133 --> 00:16:38,700
所以说整个Mellanox还是做的非常好

507
00:16:38,700 --> 00:16:40,033
这个英伟达的收购

508
00:16:40,033 --> 00:16:42,166
也是非常的优秀

509
00:16:42,333 --> 00:16:43,733
英伟达收购它之后

510
00:16:43,733 --> 00:16:45,566
其实还做了一个事情

511
00:16:45,566 --> 00:16:47,033
就是Nvlink了

512
00:16:47,100 --> 00:16:49,733
整体为GPU跟GPU的之间的互联

513
00:16:49,733 --> 00:16:51,733
设置一个高速的总线

514
00:16:51,766 --> 00:16:53,400
不仅仅用于节点内

515
00:16:53,400 --> 00:16:56,600
而且还用于节点外之间的多卡互联

516
00:16:56,600 --> 00:16:57,366
那节点外

517
00:16:57,366 --> 00:17:00,866
就有一个具体的产品名称叫做nvswitch

518
00:17:00,966 --> 00:17:04,500
现在已经引进成到了NV Fusion

519
00:17:04,533 --> 00:17:07,300
把其他的就通过英伟达的网络

520
00:17:07,300 --> 00:17:10,933
把其他的寒武纪这些额外的厂商

521
00:17:10,933 --> 00:17:13,366
都能够接入到NV link这个网络里面

522
00:17:13,366 --> 00:17:14,033
蛮有意思

523
00:17:14,033 --> 00:17:16,266
后面ZOMI想单独出一期视频

524
00:17:16,333 --> 00:17:18,600
去重点的讲讲最新的NV Fusion

525
00:17:18,600 --> 00:17:20,666
对整个业界带来的一些变化

526
00:17:21,033 --> 00:17:21,633
那当然了

527
00:17:21,633 --> 00:17:23,566
现在业界的一个主要大

528
00:17:23,566 --> 00:17:26,033
标准就除了英伟达自身之外

529
00:17:26,100 --> 00:17:29,100
就用的是RoCE

530
00:17:29,100 --> 00:17:31,533
那它还是基于以太网的RDMA

531
00:17:31,533 --> 00:17:33,366
主要兼顾了低成本跟高性能

532
00:17:33,366 --> 00:17:33,800
现在

533
00:17:33,800 --> 00:17:36,233
华为阿里寒武纪等国产的厂商

534 
00:17:36,233 --> 00:17:38,766
在大量的去布局RoCE v2

535
00:17:38,766 --> 00:17:41,866
相关的一些协议和产品

536
00:17:42,800 --> 00:17:43,700
现在看一下

537
00:17:43,733 --> 00:17:46,800
高性能处理器的一个目标

538
00:17:46,800 --> 00:17:48,266
主要是或者未来的发展

539
00:17:48,300 --> 00:17:51,533
主要是提供一个低延迟跟新的融合

540
00:17:51,566 --> 00:17:52,200
那首先

541
00:17:52,200 --> 00:17:54,200
比较明确的就是IB

542
00:17:54,200 --> 00:17:55,800
英伟达的收购的IB

543
00:17:55,800 --> 00:17:58,000
其实还在持续性的领先

544
00:17:58,000 --> 00:18:00,466
至少现在英伟达就推出了Quantum

545
00:18:00,666 --> 00:18:02,400
现在已经到了quantum的7了

546
00:18:02,400 --> 00:18:04,100
那未来会发第八代

547
00:18:04,133 --> 00:18:07,500
整体支持的带宽也是非常的高

548
00:18:07,500 --> 00:18:08,400
还有时延

549
00:18:08,566 --> 00:18:09,266
那另外一方面

550
00:18:09,300 --> 00:18:11,100
看一下RoCE来到了第二代了

551
00:18:11,100 --> 00:18:12,633
还有一些智能的网卡

552
00:18:12,633 --> 00:18:13,700
那借助于现在

553
00:18:13,733 --> 00:18:15,400
可能会越来越多的DPU

554
00:18:15,400 --> 00:18:18,300
IPU整体去降低CPU的负载

555
00:18:18,333 --> 00:18:19,833
提升以太网的竞争力

556
00:18:19,900 --> 00:18:20,433
另外的话

557
00:18:20,433 --> 00:18:22,766
已经开始出现了光互联的技术了

558
00:18:22,766 --> 00:18:23,900
硅光的集成

559
00:18:23,933 --> 00:18:25,600
还有共封装光学了

560
00:18:25,600 --> 00:18:28,066
CPU还有一个光学链路开关OCS

561
00:18:28,133 --> 00:18:30,500
那谷歌就推出了自己的OCS

562
00:18:30,500 --> 00:18:33,600
针对谷歌的TPU 4跟TPU第五代

563
00:18:33,600 --> 00:18:34,966
甚至到了第六代

564
00:18:35,133 --> 00:18:37,633
也会用更新的新一代的技术

565
00:18:37,633 --> 00:18:38,233
那另外的话

566
00:18:38,233 --> 00:18:40,766
还会发现有一些新的互联的协议

567
00:18:40,766 --> 00:18:43,066
例如华为的一个灵渠总线的互联

568
00:18:43,100 --> 00:18:45,100
实现CPU跟NPU

569
00:18:45,100 --> 00:18:46,500
NPU跟NPU之间

570
00:18:46,500 --> 00:18:48,566
节点内到节点外的所

571
00:18:48,566 --> 00:18:49,666
有统一总线

572
00:18:49,700 --> 00:18:51,966
一个新一代的集群互联的协议

573
00:18:52,966 --> 00:18:54,600
看完之后是不是有一种感觉

574
00:18:54,600 --> 00:18:56,433
就是网络的发展

575
00:18:56,433 --> 00:18:58,800
没有计算的发展快

576
00:18:58,800 --> 00:19:01,633
确实是然后高性能存储

577
00:19:01,633 --> 00:19:02,766
存储的发展

578
00:19:02,766 --> 00:19:04,700
也更没有网络的快

579
00:19:04,733 --> 00:19:06,133
所以是这么去排序

580
00:19:06,233 --> 00:19:08,166
那存储的发展

581
00:19:08,166 --> 00:19:09,500
主要是有几个历程

582
00:19:09,533 --> 00:19:09,833
第一个

583
00:19:09,833 --> 00:19:11,066
就是硬盘的时代

584
00:19:11,100 --> 00:19:11,500
这里面

585
00:19:11,500 --> 00:19:14,400
就不讲传统的那个磁带了

586
00:19:14,400 --> 00:19:15,833
因为在整个HPC里面

587
00:19:15,833 --> 00:19:17,300
就不可能放磁带了

588
00:19:17,333 --> 00:19:18,200
那整体来说

589
00:19:18,200 --> 00:19:20,000
主要是由SSD

590
00:19:20,000 --> 00:19:23,366
慢慢的去取代了传统的HDD

591
00:19:23,433 --> 00:19:24,433
容量上面

592
00:19:24,433 --> 00:19:26,566
一开始应该是HDD的大头

593
00:19:26,566 --> 00:19:28,600
就是西数跟希捷了

594
00:19:28,600 --> 00:19:30,100
推出HDD然后但是

595
00:19:30,133 --> 00:19:30,900
最大的问题就是

596
00:19:30,900 --> 00:19:32,500
它的io的延迟比较大

597
00:19:32,500 --> 00:19:34,333
很难满足HPC的场景

598
00:19:34,333 --> 00:19:35,366
所以说现在

599
00:19:35,366 --> 00:19:36,833
大量的HPC

600
00:19:36,833 --> 00:19:39,066
都是用SSD来去代替

601
00:19:39,100 --> 00:19:40,533
它的一个读写的IO

602
00:19:40,533 --> 00:19:42,166
还有延迟非常的好

603
00:19:42,166 --> 00:19:42,700
那右边

604
00:19:42,733 --> 00:19:45,200
就是它的一个具体的产品的形态

605
00:19:45,200 --> 00:19:46,100
做的非常的薄

606
00:19:46,133 --> 00:19:48,533
不需要实现磁盘的一个轮转了

607
00:19:48,533 --> 00:19:51,600
然后还有那个指针的读写

608
00:19:51,600 --> 00:19:54,400
通过半导体的存储单元

609
00:19:54,400 --> 00:19:55,866
进行一个快速的读写

610
00:19:57,133 --> 00:19:58,600
在存储方面

611
00:19:58,600 --> 00:20:00,366
除了刚才硬件的发展

612
00:20:00,366 --> 00:20:01,700
看一下软件

613
00:20:01,733 --> 00:20:03,233
还有系统上面的发展

614
00:20:03,300 --> 00:20:04,000
软件跟系统

615
00:20:04,000 --> 00:20:06,833
其实比较明确的就是分布式的存储

616
00:20:06,833 --> 00:20:09,066
跟新的存储的文件系统

617
00:20:09,100 --> 00:20:11,200
file system越来越多了

618
00:20:11,200 --> 00:20:11,700
那第一个

619
00:20:11,733 --> 00:20:14,600
就是分布式的文件系统

620
00:20:14,600 --> 00:20:16,000
文件系统一开始

621
00:20:16,000 --> 00:20:17,100
其实还是单机

622
00:20:17,133 --> 00:20:17,900
现在

623
00:20:17,900 --> 00:20:19,333
在HPC的催生下

624
00:20:19,333 --> 00:20:20,400
已经来到了分

625
00:20:20,400 --> 00:20:21,700
布式的文件系统

626
00:20:21,733 --> 00:20:22,800
现在的AI

627
00:20:22,800 --> 00:20:25,200
也很多的采用分布式的文件系统

628
00:20:25,200 --> 00:20:26,700
和云服务器

629
00:20:26,966 --> 00:20:27,633
那第一个

630
00:20:27,633 --> 00:20:29,000
就是像Lustre

631
00:20:29,000 --> 00:20:31,166
Ceph等一些文件系统

632
00:20:31,166 --> 00:20:33,866
支持EB级别的数据的吞吐

633
00:20:33,900 --> 00:20:35,133
因为在HPC场景

634
00:20:35,133 --> 00:20:35,966
数据量

635
00:20:35,966 --> 00:20:38,066
是非常非常的惊人

636
00:20:38,100 --> 00:20:39,200
算天算地

637
00:20:39,200 --> 00:20:40,366
数据量还不惊人

638
00:20:40,366 --> 00:20:43,000
算AI那Lustre的整体的带宽

639
00:20:43,000 --> 00:20:44,366
可以利用硬件

640
00:20:44,366 --> 00:20:48,300
实现1TB每秒的一个互传跟互联存储

641
00:20:48,500 --> 00:20:49,000
那另外的话

642
00:20:49,000 --> 00:20:51,266
看一下AI驱动的一个存储优化

643
00:20:51,300 --> 00:20:52,566
包括weka的IO

644
00:20:52,566 --> 00:20:53,833
还有VAST的data

645
00:20:53,833 --> 00:20:56,100
就通过SSD加RDMA

646
00:20:56,133 --> 00:20:59,766
实现选闪存的一个互联的集群

647
00:21:01,833 --> 00:21:03,466
那高性能存储

648
00:21:03,500 --> 00:21:05,700
其实还有很多的发展历程

649
00:21:05,700 --> 00:21:06,733
现在

650
00:21:06,733 --> 00:21:08,300
现在来到了第三个阶段

651
00:21:08,300 --> 00:21:11,033
就是新的存储器的革命

652
00:21:11,033 --> 00:21:11,566
那第一个

653
00:21:11,566 --> 00:21:12,366
就是SMC

654
00:21:12,366 --> 00:21:14,366
存储级别的内存

655
00:21:14,466 --> 00:21:16,600
例如在早期英特尔的Optane

656
00:21:16,600 --> 00:21:18,700
就提供了持久化的内存

657
00:21:18,733 --> 00:21:19,633
来去弥补

658
00:21:19,633 --> 00:21:23,166
内存跟存储之间的一个性能的问题

659
00:21:23,166 --> 00:21:25,766
所以这里面的这个概念很重要

660
00:21:25,966 --> 00:21:26,633
那第二个

661
00:21:26,633 --> 00:21:28,166
就是现在呀

662
00:21:28,600 --> 00:21:31,833
大家都非常缺的训练模型的时候

663
00:21:31,833 --> 00:21:34,100
都觉得HBM显存不够用

664
00:21:34,133 --> 00:21:36,400
内存不够用就是HBM

665
00:21:36,400 --> 00:21:37,900
高带宽的内存

666
00:21:37,933 --> 00:21:38,433
那这里面

667
00:21:38,433 --> 00:21:39,266
基本上

668
00:21:39,333 --> 00:21:41,133
GPU会做一个贴合封装

669
00:21:41,133 --> 00:21:43,566
因为一块GPU已经不够用了

670
00:21:43,566 --> 00:21:46,766
CPU旁边会挂很多块HBM

671
00:21:46,766 --> 00:21:48,266
而真正的HBM

672
00:21:48,300 --> 00:21:51,333
是由DRAM进行一个堆叠

673
00:21:51,333 --> 00:21:52,833
是往上发展

674
00:21:52,833 --> 00:21:53,866
那多个HBM

675
00:21:53,900 --> 00:21:54,800
进行一个堆叠

676
00:21:54,800 --> 00:21:57,000
最后合成到一个die里面

677
00:21:57,000 --> 00:21:58,966
就变成HBM

678
00:21:58,966 --> 00:22:01,200
具体你看到的外观的形态了

679
00:22:01,200 --> 00:22:02,233
那架构图

680
00:22:02,233 --> 00:22:07,033
就像右边的所设有很多个HBM的DRAM die

681
00:22:07,133 --> 00:22:10,833
进行一个对应的上层的封装

682
00:22:10,966 --> 00:22:11,966
这种HBM

683
00:22:11,966 --> 00:22:15,066
用的更多的应该是在NPU跟GPU里面

684
00:22:15,100 --> 00:22:17,333
非常高度的集成和依赖

685
00:22:17,333 --> 00:22:19,766
那现在已经发展到HBM3了

686
00:22:19,766 --> 00:22:20,900
每个引脚的速率

687
00:22:20,933 --> 00:22:23,333
可以到达6.4 GB每秒

688
00:22:23,333 --> 00:22:25,133
然后单设备的带宽

689
00:22:25,133 --> 00:22:27,366
可以接近一个T GBPS

690
00:22:27,366 --> 00:22:28,833
非常的惊人

691
00:22:29,333 --> 00:22:30,133
那看一下

692
00:22:30,133 --> 00:22:32,200
高性能存储的一个未来的发展趋势

693
00:22:32,200 --> 00:22:32,500
第一个

694
00:22:32,533 --> 00:22:35,966
就是近层的计算和层级的优化

695
00:22:35,966 --> 00:22:38,233
那首先看一下层级优化

696
00:22:38,233 --> 00:22:40,000
就是存储级别的内存

697
00:22:40,000 --> 00:22:41,466
SMC的相关的优化

698
00:22:41,500 --> 00:22:44,533
那英特尔就推出了CXL的3.0的协议

699
00:22:44,533 --> 00:22:45,566
去推动

700
00:22:45,566 --> 00:22:48,966
就希望CPU跟GPU共享一个内存

701
00:22:48,966 --> 00:22:50,400
当然这里面也有一个博弈

702
00:22:50,400 --> 00:22:53,300
因为刚才讲到了英伟达

703
00:22:53,333 --> 00:22:54,500
包括华为昇腾

704
00:22:54,500 --> 00:22:55,933
也推出自己的CPU

705
00:22:55,933 --> 00:22:58,800
实现CPU跟GPU直接共享内存

706
00:22:58,800 --> 00:23:01,866
通过自己的私有的网络协议

707
00:23:01,966 --> 00:23:02,600
那另外的话

708
00:23:02,600 --> 00:23:05,166
看到HBM31跟HBM 4

709
00:23:05,166 --> 00:23:05,900
也在发展

710
00:23:05,933 --> 00:23:07,966
现在来看到了2025年

711
00:23:07,966 --> 00:23:11,066
HBM 3整体的带宽突破了1 TB/S了

712
00:23:11,100 --> 00:23:11,966
非常的夸张

713
00:23:11,966 --> 00:23:14,666
已经成为AI的芯片的标配

714
00:23:14,666 --> 00:23:17,433
如果你的芯片还是用LPDDR

715
00:23:17,433 --> 00:23:18,466
那证明你的芯片

716
00:23:18,500 --> 00:23:20,966
绝对不是用在服务器集群上面

717
00:23:20,966 --> 00:23:22,233
可能更多的是用在板

718
00:23:22,233 --> 00:23:23,400
卡模组

719
00:23:23,400 --> 00:23:25,966
甚至个人的PC上面

720
00:23:25,966 --> 00:23:27,400
那现在的4090

721
00:23:27,400 --> 00:23:30,633
5090 4080这种英伟达的消费级显卡

722
00:23:30,633 --> 00:23:31,633
用的是LPDDR

723
00:23:31,633 --> 00:23:33,100
而不是用HBM

724
00:23:33,633 --> 00:23:34,200
那另外

725
00:23:34,200 --> 00:23:35,633
讲到近存计算

726
00:23:35,633 --> 00:23:37,966
最重要的就算存算一体了

727
00:23:37,966 --> 00:23:38,600
存算一体

728
00:23:38,600 --> 00:23:39,366
有相关的架构

729
00:23:39,366 --> 00:23:41,200
有相关的元器件

730
00:23:41,200 --> 00:23:42,000
那相关的架构

731
00:23:42,000 --> 00:23:43,666
就计算单元嵌入存储单元

732
00:23:43,700 --> 00:23:45,200
还是存储单元嵌入计算单元

733
00:23:45,200 --> 00:23:45,900
都一样

734
00:23:45,933 --> 00:23:47,300
反正上下堆叠

735
00:23:47,300 --> 00:23:49,100
去减少数据的搬运

736
00:23:49,100 --> 00:23:50,100
上面是HBM

737
00:23:50,100 --> 00:23:52,133
下面是计算的芯片

738
00:23:52,133 --> 00:23:52,833
这种方式

739
00:23:52,833 --> 00:23:54,266
来进行互联互存

740
00:23:54,300 --> 00:23:57,300
而不是从旁边做一个贴合封装

741
00:23:57,300 --> 00:23:57,700
这样的话

742
00:23:57,700 --> 00:23:58,766
IO

743
00:23:58,766 --> 00:24:02,100
中间需要一个非常高速的一个IO  Die
 
744
00:24:02,133 --> 00:24:03,200
来进行传输

745
00:24:03,200 --> 00:24:04,900
这种存算一体的架构

746
00:24:04,933 --> 00:24:08,766
直接通过半导体来进行一个互存

747
00:24:08,766 --> 00:24:10,633
所以说整体的IO非常的高

748
00:24:10,633 --> 00:24:12,166
时延非常的低

749
00:24:12,600 --> 00:24:14,666
那看一下存算一体的器件

750
00:24:14,700 --> 00:24:17,366
现在出现了一些新的Memristor

751
00:24:17,366 --> 00:24:19,366
还有一些相变的存储器

752
00:24:19,366 --> 00:24:22,100
PCM支持内存计算

753
00:24:22,133 --> 00:24:24,166
降低一个搬运的功耗

754
00:24:24,300 --> 00:24:26,766
内存也可以算了

755
00:24:26,766 --> 00:24:27,366
你的计算

756
00:24:27,366 --> 00:24:29,800
不仅仅只能放在ALU里面去算

757
00:24:29,800 --> 00:24:33,066
现在内存也能够有一定的计算能力

758
00:24:33,100 --> 00:24:36,133
有没有有一点像那个DPU

759
00:24:37,233 --> 00:24:39,300
哎聊了很多废话

760
00:24:39,333 --> 00:24:40,800
现在才来到了第四个内容

761
00:24:40,800 --> 00:24:43,066
看一下高性能的服务器了

762
00:24:43,133 --> 00:24:44,433
Server & Cooling

763
00:24:44,433 --> 00:24:45,833
那为什么说服务器

764
00:24:45,833 --> 00:24:48,000
最重要的其实就是两个内容

765
00:24:48,200 --> 00:24:48,733
第一个内容

766
00:24:48,733 --> 00:24:50,433
就是服务器本身

767
00:24:50,433 --> 00:24:50,833
第二个

768
00:24:50,833 --> 00:24:53,466
就是液冷跟功耗相关的内容

769
00:24:53,500 --> 00:24:55,366
都放在服务器这里面了

770
00:24:55,366 --> 00:24:58,166
那看一下整体的发展一个历程

771
00:24:58,166 --> 00:24:58,466
第一个

772
00:24:58,500 --> 00:25:01,400
就是很明显的就是性能导向的阶段

773
00:25:01,400 --> 00:25:02,500
一开始服务器

774
00:25:02,533 --> 00:25:04,100
都是大型机

775
00:25:04,100 --> 00:25:06,633
大型机就之前讲到的一个机柜

776
00:25:06,633 --> 00:25:07,866
其实是一台机器

777
00:25:07,900 --> 00:25:08,966
一个操作系统

778
00:25:09,033 --> 00:25:10,066
一个操作系统里面

779
00:25:10,100 --> 00:25:13,566
一块板卡里面直接焊死了300多个

780
00:25:13,566 --> 00:25:16,500
70多个非常多的CPU

781
00:25:16,566 --> 00:25:17,066
那后来

782
00:25:17,100 --> 00:25:18,900
现在来到了整个HPC

783
00:25:18,900 --> 00:25:20,333
一个以性能导向为阶段

784
00:25:20,333 --> 00:25:23,366
就是刀片式的服务器的普及了

785
00:25:23,366 --> 00:25:25,400
那左边的这个就是刀片式的服务器

786
00:25:25,400 --> 00:25:27,833
可以看到一个大的一个机柜上面

787
00:25:27,833 --> 00:25:30,633
插了很多这种小的刀片的服务器

788
00:25:30,633 --> 00:25:31,466
每个服务器里面

789
00:25:31,500 --> 00:25:33,400
可能放几张CPU

790
00:25:33,400 --> 00:25:34,033
比较明确

791
00:25:34,033 --> 00:25:36,900
有惠普跟IBM相关的产品

792
00:25:36,933 --> 00:25:38,833
通过高密度的去设计

793
00:25:38,833 --> 00:25:40,866
整个刀片的服务器

794
00:25:40,900 --> 00:25:42,966
才提升机架的利用率

795
00:25:43,133 --> 00:25:44,400
那这个时候

796
00:25:44,400 --> 00:25:45,266
刀片式服务器

797
00:25:45,300 --> 00:25:46,566
其实还没有用到液冷

798
00:25:46,566 --> 00:25:48,866
因为它的整体的功耗没那么的大

799
00:25:48,900 --> 00:25:52,033
所以说它以风冷散热作为主要

800
00:25:52,033 --> 00:25:52,966
但是风冷散热

801
00:25:52,966 --> 00:25:55,233
其实也是瓶颈蛮明显

802
00:25:55,233 --> 00:25:56,033
单柜的功耗

803
00:25:56,033 --> 00:25:58,833
如果超过20千瓦的时候

804
00:25:59,166 --> 00:26:00,700
传统风冷的效率

805
00:26:00,733 --> 00:26:02,766
这个效率的评价指标PUE

806
00:26:02,766 --> 00:26:04,966
就会上升到1.5了

807
00:26:04,966 --> 00:26:06,166
说实话PUE

808
00:26:06,166 --> 00:26:07,266
可能小于1.3

809
00:26:07,300 --> 00:26:08,233
甚至1.1

810
00:26:08,233 --> 00:26:10,000
可能是最合适

811
00:26:10,033 --> 00:26:11,300
那往后发展

812
00:26:11,333 --> 00:26:13,766
就变成来到了绿色的阶段了

813
00:26:13,766 --> 00:26:15,466
从传统的风冷的机架

814
00:26:15,500 --> 00:26:17,733
向高密度的液冷的机架发展

815
00:26:17,833 --> 00:26:19,633
刚才其实还漏了一个点

816
00:26:19,633 --> 00:26:21,100
刀片式服务器

817
00:26:21,133 --> 00:26:22,033
慢慢的发展着

818
00:26:22,033 --> 00:26:24,200
就变成了机架式服务器

819
00:26:24,200 --> 00:26:25,266
那最明显的区别

820
00:26:25,300 --> 00:26:27,600
看一下左右两边的一个图案

821
00:26:27,700 --> 00:26:28,733
刀片式服务器

822
00:26:28,733 --> 00:26:30,300
就像左边的这种形态

823
00:26:30,300 --> 00:26:32,033
一片片刀这么插进去

824
00:26:32,033 --> 00:26:33,000
机架式服务器

825
00:26:33,000 --> 00:26:36,066
就你会发现1U 2 u这种方式

826
00:26:36,100 --> 00:26:39,333
去嵌进去整个大型的机柜

827
00:26:39,333 --> 00:26:40,033
相信

828
00:26:40,033 --> 00:26:41,566
其实应该有很多的小伙伴

829
00:26:41,566 --> 00:26:43,466
没有去过机房去看

830
00:26:43,500 --> 00:26:45,000
ZOMI有幸

831
00:26:45,000 --> 00:26:45,866
在参加

832
00:26:45,900 --> 00:26:48,600
华为的一个千卡到万卡集群的计算

833
00:26:48,600 --> 00:26:49,466
的时候

834
00:26:49,500 --> 00:26:50,966
领导说不能讲万卡

835
00:26:50,966 --> 00:26:51,766
不管怎么样了

836
00:26:51,766 --> 00:26:53,433
其实大家都知道了这个秘密

837
00:26:53,433 --> 00:26:55,233
然后也进了很多次机房

838
00:26:55,233 --> 00:26:56,300
而且甚至

839
00:26:56,333 --> 00:26:58,033
在23年年底的时候

840
00:26:58,033 --> 00:26:59,466
在商汤的机房里面

841
00:26:59,500 --> 00:27:00,733
睡了整整一周

842
00:27:00,733 --> 00:27:04,100
去帮他们部署这个机房的机架

843
00:27:04,100 --> 00:27:05,400
昇腾的服务器

844
00:27:05,533 --> 00:27:06,166
那不管怎么样

845
00:27:06,166 --> 00:27:07,600
这些话外题了

846
00:27:07,600 --> 00:27:10,100
还是回到正式的流程里面

847
00:27:10,133 --> 00:27:10,700
整体

848
00:27:10,700 --> 00:27:13,366
现在向绿色化去发展了

849
00:27:13,366 --> 00:27:14,433
那这里面的绿色

850
00:27:14,433 --> 00:27:16,500
更多是清洁能源的绿色

851
00:27:16,533 --> 00:27:19,000
而不是指这里面的这个绿色

852
00:27:19,000 --> 00:27:20,866
或者吃的很健康

853
00:27:21,100 --> 00:27:23,366
那整体看一下整体散热的情况

854
00:27:23,366 --> 00:27:25,200
从传统的风冷的机架

855
00:27:25,300 --> 00:27:28,166
向高密度的液冷的机架去发展

856
00:27:28,166 --> 00:27:28,700
那液冷

857
00:27:28,733 --> 00:27:29,966
有分两种

858
00:27:29,966 --> 00:27:31,400
第一种就是板冷

859
00:27:31,500 --> 00:27:34,100
就直接冷却CPU GPU或者NPU

860
00:27:34,200 --> 00:27:36,366
第二种就是浸没式的液冷

861
00:27:36,366 --> 00:27:37,966
就把整个板卡

862
00:27:37,966 --> 00:27:40,000
都放在一些非导电

863
00:27:40,000 --> 00:27:41,566
一些液冷里面了

864
00:27:41,566 --> 00:27:43,366
整体放到水里面了

865
00:27:43,366 --> 00:27:44,066
可以这么去理解

866
00:27:44,100 --> 00:27:46,133
当然它不是所谓的水了

867
00:27:46,133 --> 00:27:49,300
那从左边的下面的这个图

868
00:27:49,300 --> 00:27:50,166
可以看到

869
00:27:50,166 --> 00:27:53,066
那中间的这种和左边的这种更

870
00:27:53,100 --> 00:27:54,433
多的是板冷式

871
00:27:54,433 --> 00:27:55,233
液冷

872
00:27:55,233 --> 00:27:58,033
通过这个绿色的就是冷口

873
00:27:58,033 --> 00:28:00,433
然后红色的是热口

874
00:28:00,666 --> 00:28:03,166
冷口输入热口输出这种方式

875
00:28:03,166 --> 00:28:04,800
去连接过

876
00:28:04,800 --> 00:28:07,633
或者穿过每一款CPU跟GPU

877
00:28:07,633 --> 00:28:10,400
和功耗发热比较大的一些芯片

878
00:28:10,400 --> 00:28:11,066
或者模组

879
00:28:11,100 --> 00:28:14,000
散热鳞把热源带走

880
00:28:14,000 --> 00:28:14,700
那这种

881
00:28:14,733 --> 00:28:17,400
往上看就是一个冷管一个热管

882
00:28:17,400 --> 00:28:18,500
这么这种方式

883
00:28:18,533 --> 00:28:19,900
那具体的实物形态

884
00:28:19,900 --> 00:28:21,033
就像这种

885
00:28:21,033 --> 00:28:23,033
上面挂了非常多的液管

886
00:28:23,033 --> 00:28:25,766
冷当然里面也是要开空调

887
00:28:25,766 --> 00:28:27,300
不能说不开空调

888
00:28:27,333 --> 00:28:28,700
所以说现在基本上

889
00:28:28,700 --> 00:28:32,000
更多是风冷加液冷这么一个组合

890
00:28:32,133 --> 00:28:32,766
那另外的话

891
00:28:32,766 --> 00:28:33,266
看到

892
00:28:33,300 --> 00:28:36,033
现在用的最多的就是模块化的设计

893
00:28:36,033 --> 00:28:38,066
一开始的超算

894
00:28:38,100 --> 00:28:39,566
更多的是一个机

895
00:28:39,566 --> 00:28:40,300
一个大型机

896
00:28:40,333 --> 00:28:41,100
一个大型机

897
00:28:41,100 --> 00:28:42,233
现在的大型机

898
00:28:42,233 --> 00:28:45,200
更多的是一个模块化的设计的实现

899
00:28:45,200 --> 00:28:47,466
计算网络存储的灵活

900
00:28:47,500 --> 00:28:49,600
可插拔式的扩展

901
00:28:49,600 --> 00:28:51,500
那这种方式来去实现

902
00:28:51,633 --> 00:28:53,433
当然了未来趋势

903
00:28:53,600 --> 00:28:57,233
ZOMI印象非常深刻的就是看水浒传

904
00:28:57,233 --> 00:28:59,566
不是是西游记吗

905
00:28:59,600 --> 00:29:00,466
不是不是

906
00:29:00,500 --> 00:29:02,566
是三国演义

907
00:29:02,566 --> 00:29:04,900
里面第一句话就是天下大势

908
00:29:04,933 --> 00:29:05,833
合久必分

909
00:29:05,833 --> 00:29:07,666
分久必合

910
00:29:07,700 --> 00:29:08,600
现在

911
00:29:08,600 --> 00:29:09,833
基本上机柜

912
00:29:09,833 --> 00:29:12,700
也开始慢慢的迎来了整机柜的设计

913
00:29:12,733 --> 00:29:13,533
那像华为

914
00:29:13,533 --> 00:29:16,833
就推出了一个Cloud Matrix的384节点

915
00:29:16,833 --> 00:29:17,966
一个超节点

916
00:29:18,033 --> 00:29:18,500
英伟达

917
00:29:18,533 --> 00:29:21,633
就推出了自己的NVL 72 ，72个卡

918
00:29:21,633 --> 00:29:23,566
放在一个机柜里面

919
00:29:23,566 --> 00:29:26,700
机柜跟机柜之间再经过光进行传输

920
00:29:26,733 --> 00:29:30,766
72之间经过铜进行一个传输

921
00:29:30,766 --> 00:29:32,166
也就是电缆

922
00:29:32,200 --> 00:29:33,566
所以说现在

923
00:29:33,566 --> 00:29:35,400
也在做整机柜

924
00:29:35,400 --> 00:29:36,700
设计那当然了

925
00:29:36,733 --> 00:29:38,333
现在已经比较明显

926
00:29:38,333 --> 00:29:40,333
就来到了一个液冷的普及了

927
00:29:40,333 --> 00:29:41,133
那欧盟里面

928
00:29:41,133 --> 00:29:43,400
就明确要求了数据中心的整个PUE

929
00:29:43,400 --> 00:29:44,900
是降到了1.3

930
00:29:44,933 --> 00:29:47,000
也就是往绿色能源的发展

931
00:29:47,000 --> 00:29:48,666
液冷也慢慢的从实验室

932
00:29:48,700 --> 00:29:51,600
走向一个比较明确的标准的方案

933
00:29:51,600 --> 00:29:53,066
也希望华为昇腾

934
00:29:53,100 --> 00:29:54,000
有更多的白皮书

935
00:29:54,000 --> 00:29:57,766
需要去指导整个业界的发展

936
00:29:59,000 --> 00:30:00,600
哎呀一口气讲了好多

937
00:30:00,600 --> 00:30:01,766
喝一口水

938
00:30:03,400 --> 00:30:04,433
再吃一口杨梅

939
00:30:04,433 --> 00:30:05,100
然后再回来

940
00:30:05,133 --> 00:30:07,133
看一下整个硬件的发展

941
00:30:07,133 --> 00:30:08,366
整体的驱动力

942
00:30:08,433 --> 00:30:10,433
还是回到整个HPC

943
00:30:10,533 --> 00:30:11,366
现在看到

944
00:30:11,366 --> 00:30:12,566
刚才跟大家分享了

945
00:30:12,566 --> 00:30:14,433
一个整个HPC的一个领域

946
00:30:14,566 --> 00:30:16,100
有高性能处理器啦

947
00:30:16,100 --> 00:30:17,033
高性能的网络

948
00:30:17,033 --> 00:30:17,833
高性能的服务器

949
00:30:17,833 --> 00:30:19,566
还有高性能的存储

950
00:30:19,600 --> 00:30:21,766
但变化比较大的有高性能的处理器啦

951
00:30:21,766 --> 00:30:23,266
到网络到存储

952
00:30:23,300 --> 00:30:24,133
到服务器

953
00:30:24,133 --> 00:30:24,966
所有的发展

954
00:30:24,966 --> 00:30:26,200
都是这么下来

955
00:30:26,200 --> 00:30:28,300
整体的处理器的驱动力

956
00:30:28,333 --> 00:30:31,100
就是提升计算的效率

957
00:30:31,200 --> 00:30:33,866
跟一些不同的精度的格式

958
00:30:33,900 --> 00:30:34,766
当然啦到最后

959
00:30:34,766 --> 00:30:37,833
因为整体的制成工艺的受限

960
00:30:37,833 --> 00:30:40,766
所以现在走的更多的往chiplet的封装

961
00:30:40,766 --> 00:30:41,766
芯粒的封装

962
00:30:41,766 --> 00:30:42,566
横向的封

963
00:30:42,566 --> 00:30:43,566
竖向的封

964
00:30:43,566 --> 00:30:44,466
纵向的封

965
00:30:45,233 --> 00:30:46,400
那网络

966
00:30:46,400 --> 00:30:48,700
最重要就是突破通讯的瓶颈

967
00:30:48,733 --> 00:30:50,033
降低时延

968
00:30:50,033 --> 00:30:51,633
提升带宽

969
00:30:51,633 --> 00:30:53,200
所以就通过RDMA

970
00:30:53,200 --> 00:30:54,900
就提出了一个RoCE

971
00:30:54,933 --> 00:30:56,200
InfiniBand IB

972
00:30:56,200 --> 00:30:57,766
还有相关的DPU

973
00:30:57,766 --> 00:31:00,166
去承担对应的负载

974
00:31:00,366 --> 00:31:01,766
那在服务器场景

975
00:31:01,766 --> 00:31:03,366
希望突破功耗墙

976
00:31:03,366 --> 00:31:04,600
降低整个PV

977
00:31:04,600 --> 00:31:07,000
所以现在出现了液冷的方案

978
00:31:07,000 --> 00:31:10,366
液冷跟风冷做一个整体的组合

979
00:31:10,666 --> 00:31:11,500
那内存

980
00:31:11,533 --> 00:31:14,600
希望打破内存墙跟存储墙

981
00:31:14,600 --> 00:31:15,566
所以内存

982
00:31:15,566 --> 00:31:18,300
现在来到了多级的内存

983
00:31:18,333 --> 00:31:20,166
还有往着HBM

984
00:31:20,166 --> 00:31:23,233
把DRAM进行一个垂直的堆叠

985
00:31:23,233 --> 00:31:25,066
提供实验更低带宽

986
00:31:25,100 --> 00:31:28,500
更大的互联的方式

987
00:31:30,200 --> 00:31:31,033
那硬件的部分

988
00:31:31,033 --> 00:31:32,600
已经讲的差不多了

989
00:31:32,600 --> 00:31:33,433
在下期视频

990
00:31:33,433 --> 00:31:34,466
再跟大家去分享

991
00:31:34,500 --> 00:31:37,100
基础软件HPC里面相关的内容

992
00:31:37,233 --> 00:31:40,566
但是虽然现在讲的是HPC

993
00:31:40,566 --> 00:31:43,300
但ZOMI整个系列是AI infra

994
00:31:43,433 --> 00:31:44,800
大模型系统

995
00:31:44,800 --> 00:31:46,266
大模型基础设施的内容

996
00:31:46,300 --> 00:31:49,300
是希望通过借鉴HPC的内容

997
00:31:49,300 --> 00:31:50,400
或者学习HPC的内容

998
00:31:50,400 --> 00:31:54,600
看一下HPC对AI整个AI infra的建设

999
00:31:54,600 --> 00:31:56,166
有哪些可参考的意义

1000
00:31:56,166 --> 00:31:57,833
那大家可以回顾一下

1001
00:31:57,833 --> 00:31:59,166
整个AI infra了

1002
00:31:59,166 --> 00:32:00,433
到底需要哪些

1003
00:32:00,433 --> 00:32:01,400
需要参考哪些

1004
00:32:01,400 --> 00:32:02,266
借鉴哪些

1005
00:32:02,300 --> 00:32:04,333
在关于AI的集群的时候

1006
00:32:04,333 --> 00:32:06,366
有哪些新的知识点的变化

1007
00:32:06,366 --> 00:32:08,433
这个还是需要大家去思考

1008
00:32:08,433 --> 00:32:10,633
那今天的内容就先到这里为止

1009
00:32:10,633 --> 00:32:11,666
谢谢各位

1010
00:32:11,733 --> 00:32:12,833
拜了个拜

