<!--Copyright 适用于[License](https://github.com/chenzomi12/AIInfra)版权许可-->

# GPU与NPU精度误差

## 硬件浮点运算如何引入误差

### 浮点表示

十进制中我们使用科学计数法表示一个浮点数，例如

$(-4.5)_{10}\times10^{0} = -1\times(4\times10^{0}+5\times10^{-1})$

同样的数用二进制表示为

$(-1.001)_{2}\times2^{2}=-1\times(1\times2^2+0\times2^1+0\times2^0+1\times2^{-1})$

他们的值都是-4.5，是同一个数。

因此，表示一个浮点数，我们只需要三个部分：

1. 符号位表示该数为正数还是负数，如上述例子中的-1；
2. 小数点左边只有一位数的小数，如上述例子中十进制的4.5，或者二进制的1.001；
3. 指数部分，如上述例子中十进制的指数0，或二进制的指数2。


计算机硬件也是使用这三个部分表示一个浮点数：**符号（sign，S），尾数（fraction，F），指数（exponent，E）**。

<img src="image\浮点表示.png" alt="浮点表示" style="zoom:40%;" />

我们对浮点数的表示做一些改进：

1. 二进制下浮点数总是可以写成$±1.xxxx\times2^{yyyyy}$的形式，最左边的数字总是1，可以**省去**，这样可以为硬件节省一位的空间；
2. 如果需要比较两个浮点数的大小，我们知道指数部分大的浮点数一定比指数部分小的浮点数大，可以先比较两个浮点数的指数部分。我们把浮点数的指数加上一个**bias**得到指数E，保证E为非负数（无符号数），相较于比较有符号数，硬件可以更快地比较两个无符号数的大小。假设有n位指数，则$bias=2^{n-1}-1$。

对于一个（S，F，E）组合而成的浮点数，其对应的浮点数的值为：
$$
value = (-1)^S\times (1.F)\times 2^{(E-bias)}
$$
上述表示存在一个问题：当$(E-bias)=0$时，正浮点数的值为$1.F$，最小只能表示到1.0，无法表示 (0,1)之间的数，负浮点数也是一样，无法表示(-1,0)。这种表示方法也无法表示0。为了解决这一问题，IEEE 754标准使用一种**非规格化**方法，约定当$(E-bias)=0$时，不再假定尾数为$1.F$的规格化形式，而是$0.F$的非规格化形式，且指数值被固定为$1-bias$，即
$$
value = (-1)^S\times (0.F)\times 2^{(1-bias)}
$$
此外，IEEE还规定了0、无穷、NaN的表示，这里不做重点介绍。

为简化理解，我们使用1位符号、2位指数（此时bias=1）、2位尾数表示一个浮点数，且S=0（即只考虑非负浮点数）。一共可以表示的数如下表所示：

| E    | 指数值       | F    | S=0时，表示的数字                                            |
| ---- | ------------ | ---- | ------------------------------------------------------------ |
| 00   | 1-bias = 0   | 00   | 0                                                            |
| 00   | 1-bias = 0   | 01   | $(0.01)_2\times2^{0}=1\times2^{-2}=0.25$                     |
| 00   | 1-bias = 0   | 10   | $(0.10)_2\times2^{0}=2\times2^{-2}=0.5$                      |
| 00   | 1-bias = 0   | 11   | $(0.11)_2\times2^{0}=3\times2^{-2}=0.75$                     |
| 01   | E - bias = 0 | 00   | $(1.00)_2\times2^{0}=1\times2^{0}=1$                         |
| 01   | E - bias = 0 | 01   | $(1.01)_2\times2^{0}=1\times2^{0}+1\times2^{-2}=1.25$        |
| 01   | E - bias = 0 | 10   | $(1.10)_2\times2^{0}=1\times2^{0}+1\times2^{-1}=1.5$         |
| 01   | E - bias = 0 | 11   | $(1.11)_2\times2^{0}=1\times2^{0}+1\times2^{-1}+1\times2^{-2}=1.75$ |
| 10   | E - bias = 1 | 00   | $(1.00)_2\times2^{1}=1\times2^{1}=2$                         |
| 10   | E - bias = 1 | 01   | $(1.01)_2\times2^{1}=1\times2^{1}+1\times2^{-1}=2.5$         |
| 10   | E - bias = 1 | 10   | $(1.10)_2\times2^{1}=1\times2^{1}+1\times2^{0}=3$            |
| 10   | E - bias = 1 | 11   | $(1.11)_2\times2^{1}=1\times2^{1}+1\times2^{0}+1\times2^{-1}=3.5$ |
| 11   |              | 00   | 特殊值无穷大，∞                                              |
| 11   |              | 非0  | 不是一个数，NaN                                              |

上表一共表示了从0到3.5之间的12个数，如下图所示。

![可表示的数](image\示例.png)

然而，在0到3.5之间存在无数个实数，我们使用5位的浮点数只能准确表示其中的12个数。如果要表示其他的浮点数，比如表示2.25这个数，怎么办？要么**增加更多位尾数**，比如增加一位表示尾数F，F从2位增加到3位，F=001，使用$(1.001)\times2^1$表示2.25；要么就只能进行**舍入**操作，使用距离2.25比较近的两个浮点数之一，即2或者2.5来表示了。**当一个浮点数需要太多位尾数才能准确表示，就会发生舍入，而舍入会引入精度误差。**

IEEE 754规定了五种舍入规则：

- 向最接近可表示值舍入 (Round to nearest, ties to even)

- 向正无穷方向舍入 (Round toward +∞)

- 向负无穷方向舍入 (Round toward -∞)

- 向零舍入 (Round toward zero)

- 向最接近可表示值舍入，中间值远离零方向 (Round to nearest, ties away from zero)

硬件厂商可以选择其中任意一种舍入模式，并没有强制规定必须使用哪一种，其中最常用且默认的是向最接近可表示值舍入模式。如果硬件厂商选择的舍入模式不同，且计算时涉及舍入操作，那么不同产品得到的结果很可能是不同的。

为了量化了浮点数表示的不确定性和舍入误差，我们使用**ULP**（Unit in the Last Place）衡量误差，ULP表示**在给定指数下两个相邻可表示浮点数之间的最小间隔**。一种更直观的理解是，ULP是浮点数末尾1个bit（最低有效位）所代表的值。例如在上述例子中，2.25的两个相邻可表示浮点数分别为2和2.5，则$ULP=2.5-2=0.5$。

  一次舍入操作带来的精度误差不会超过1ULP，似乎并不大，但**使用舍入之后的浮点数再进行算术运算，可能会发生误差累计或者放大误差**，最典型的就是除法运算，且除数接近0，例如用上面的浮点数计算$0.25/0.125$，精确的结果应该是2，但0.125会被舍入到0.25或者0，如果舍入到0.25，得到的结果是1，是精确结果的一半；如果舍入到0，会发生除0，得到的结果是无穷，误差更大。



### 浮点运算

我们以浮点数的加法为例，说明浮点运算操作如何带来误差。为了便于理解，我们使用两个只有4位有效位，指数为2位的十进制数作为示例：$9.999\times10^1+1.610\times10^{-1}$。

**步骤一：**指数对齐。对指数较小的数进行调整，使其指数等于较大的数的指数。这里会使用到右移操作，由于只有4位有效位，最后一位1会被丢弃。
$$
1.610\times10^{-1}=0.016\times10^{1}
$$
**步骤二：**有效位相加。
$$
9.999+0.016=10.015
$$
**步骤三：**规格化，并检查结果中的指数位是否发生上溢或者下溢，若发生，抛出异常。
$$
10.015\times10^1=1.0015\times10^2
$$
**步骤四：**若没有发生上溢或者下溢，对结果进行舍入。
$$
1.0015\times10^2=>1.002\times10^2
$$
**步骤五：**检查步骤四的结果是否为规格化数，若不是，返回步骤三，若是，得出结果。

上面的例子可以总结出，加法操作有**两个地方**会引入误差：步骤二的**移位**操作，步骤四的**舍入**操作。

**移位操作**。假设两个浮点数的指数部分相差为n，则较小的浮点数需要右移n位与较大的浮点数指数对齐，较小的浮点数会丧失其最低n位的精度。这在两个浮点数的大小相差非常大的时候会很明显。例如：计算$a+b+(-a)$的值，准确的答案应该是b，但**如果a和b的指数相差太大，b会因为移位操作丧失最低n位的数值，使b变成一个更靠近0的数**，最后的结果不等于b。

```
#Python3, 64位计算机

a = 1000
b = 0.0000000000000125

a+(-a)+b 
#输出1.25e-14

a+b+(-a) 
#输出0.0
```

假如我们需要计算多个数的和，比如$a+b+b+b+...+b$，一共$10^{14}$个b，$10^{14}\times b=1.25$，正确的结果应该是1001.25，但由于计算顺序为$a+b+b+b+...+b$，计算机不停地执行$a+b=a$，最后结果为1000。应该如何尽可能避免这种误差呢？一种可行的操作是，将加法中的元素按照**升序排序之后再相加**。较小的浮点数累加成较大的浮点数后，再与更大的浮点数相加，可以减少两个浮点数的指数之间的差距，从而减少右移的位数。

在并行计算中，常会将数字分成组，并行计算每一组内的数字的和，类似的，将这些数字进行预先排序，使较为接近的数字分在一组，可以减少移位操作带来的误差。

**舍入操作。**上一节已经介绍过，这里不再赘述。

上面介绍了加法操作，乘法操作可以转化为加法操作，除法操作和超越函数（如三角函数）则更为复杂，往往通过多项式逼近的算法实现，具体精度与硬件实现方式有关，可以查看硬件供应商是否提供精度保证，例如英伟达对其数学操作的舍入模式和精度保证进行了说明（https://developer.nvidia.com/zh-cn/blog/cuda-math-method-cn/）。



## 实际应用中的浮点误差

### 浮点运算不满足数学上的交换律和结合律

```
#Python3, 64位计算机

a = 0.1
b = 0.2
c = 0.3
d = 0.4
e = 0.5
f = 0.6

x = (a+b) + (c+d) + (e+f) 
y = (a+d) + (b+e) + (c+f) 

#计算的结果为
#x = 2.1
#y = 2.0999999999996 
```

在数学认识上，上面两个累加的结果x和y应该相等才对，那么到底计算机得出的结果中哪个才是准确的呢？

**两个结果都不是准确的！**

计算机是不能准确表示0.1这个浮点数的，0.1在二进制中是一个无限循环小数（0.0001100110011...），因此无法精确表示，必须进行舍入。

而$2.1=2+0.1=2^1+0.1$，二进制也不能准确表示2.1这个数，之所以显示x=2.1，是由于Python将浮点数转换为字符串进行打印时，它会进行一些处理以提供“友好”的输出。如果我们打印查看更多更多位数，变量x就“原形毕露”了，这就是为什么说这两个结果都不准确：

```
print("{:.20f}".format(x))
#输出2.10000000000000008882

print("{:.20f}".format(y))
#输出2.09999999999999964473
```

但是，相对而言x比y更准确，计算x的时候，累加的元素是按照**升序顺序计算**的，涉及的右移操作更少，比如计算0.1+0.2时，只需要将0.1右移一位就能与0.2进行指数对齐，最多带来1ULP的误差，而计算0.1+0.4时需要将0.1右移两位，最多带来3ULP的误差。



因此，在进行计算的时候，要特别注意**计算的顺序**，同一硬件上不同的计算顺序可能得出不同的结果。比如对于算子来说，同样的输入，同样的芯片，如果使用不同的数据切分策略，数据计算的顺序改变了，计算的结果可能会不一样。



### 硬件实现差异

**浮点运算单元差异**，硬件计算过程中，中间结果的保留位数会影响精度。例如进行16位的乘加操作$a\times b+c$，如果硬件先进行乘法操作$a\times b$，得到一个中间结果tmp，理论上tmp必须是32位的才能保证没有精度损失，但实际上只有16位，中间结果经历一次**舍入**。然后tmp与c相加，可能还会经历一次舍入。如果使用**融合乘加（FMA）单元**，使用32位保留中间结果，可以避免一次中间结果的舍入误差。



**数值近似优化**，不同硬件对低精度计算（FP16）中的非规格化数的处理可能不同。例如在Tensor Cores (Volta及以后)：矩阵乘法（如FP16 MMA），**输入非规格化数通常被默认置零**（ Flush-To-Zero，FTZ），这是速度优化的一部分。



**浮点数格式**，计算中使用不同的浮点数格式，所具备的精度不同。深度学习可能采用更少位数的浮点格式进行更快的计算。

![image-20250622195948872](image\浮点格式.png)

下面以FP16、FP8-E5M2、FP8-E4M3三种格式为例，说明使用浮点表示0.1时产生的误差。

```
#Python3，torch2.7.0+cu126，RTX2070

import torch

# 检查设备支持
torch.cuda.is_available() 
device = torch.device("cuda")

# 创建变量a、b、c分别等于0.1 (格式为FP16、FP8-E5M2、FP8-E4M3)
a = torch.tensor(0.1, dtype=torch.float16, device=device)
b = torch.tensor(0.1, dtype=torch.float8_e5m2, device=device)
c = torch.tensor(0.1, dtype=torch.float8_e4m3fn, device=device)

#结果
a.item(),b.item(),c.item()
#(0.0999755859375, 0.09375, 0.1015625)
#与0.1相比分别对应约 0.02%，6.25%，1.56%的相对误差
```



### **软件栈与算法实现的差异**

**数学库的底层实现**，NV cuBLAS 与昇腾 CANN 算子库在矩阵乘法的分块（Tiling）、循环展开（Loop Unrolling）、内存访问的实现上存在差异。不同库对矩阵乘法的并行拆分策略（GEMM分块大小）会影响浮点累加的顺序

**编译器优化**，编译器对指令重排（Instruction Reordering）、融合乘加（FMA）指令使用影响中间结果的精度。昇腾CANN底层的编译器与英伟达的NVCC指令序列不同。





### 其他差异

**线程调度与计算顺序不同**，并行计算中，线程块的执行顺序和线程间的数据同步存在非确定性。E.g.，CUDA 多线程 warp 调度策略与昇腾的多进程核函数调度不同。



**内存访问竞争**，共享内存或缓存（如L1/L2）的访问中，不同硬件内存一致性可能影响数据更新的时序，间接导致计算结果的微小偏差。



## 总结

浮点运算时要特别留意**舍入**和**移位**操作带来的误差；

硬件层面的不同实现方式可能影响舍入操作；

计算**顺序**的改变可能通过影响移位操作的舍入误差积累的方向进而影响到计算结果；

一些底层库的实现不同和编译优化，可能带来计算顺序的改变。

