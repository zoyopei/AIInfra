{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870dd018-27b0-4f8a-a72c-5cfc31c69da9",
   "metadata": {},
   "source": [
    "# 《11MOECode》解读 by【AI 布道 Mr.Jin】\n",
    "\n",
    "其实在 DeepSeek-R1 爆火之前，DeepSeek V2 在我们行业就已经妇孺皆知了，它独特的 MOE 结构值得研究一下。这篇文章是基于 ZOMI 酱 的这个视频写的：《使用昇腾 NPU 手撕 MoE 单机版代码！没想到如此简单！》。\n",
    "\n",
    "通过《09MOECore 解读》，我们知道了 MOE 的结构原理是什么样的，接下来看一下代码上是怎么实现的！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfe3b0-37aa-4abe-8e4e-1fac5b850423",
   "metadata": {},
   "source": [
    "## MOE 计算代码\n",
    "\n",
    "下面是 zomi 酱课程中提供的完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705965c4-b8ac-4637-a7e4-5a323bbe4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\jupyter-env\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval output shape: torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.expert_capacity = expert_capacity\n",
    "        \n",
    "        # 路由网络\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "        \n",
    "        # 专家集合\n",
    "        self.experts = nn.ModuleList(\n",
    "            [Expert(input_dim, hidden_dim, output_dim) for _ in range(num_experts)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, input_dim = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        # 路由计算\n",
    "        logits = self.gate(x)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, self.top_k, dim=-1)\n",
    "        # 辅助损失计算\n",
    "        if self.training:\n",
    "            # 重要性损失（专家利用率均衡）\n",
    "            importance = probs.sum(0)\n",
    "            importance_loss = torch.var(importance) / (self.num_experts ** 2)\n",
    "            \n",
    "            # 负载均衡损失（样本分配均衡）\n",
    "            mask = torch.zeros_like(probs, dtype=torch.bool)\n",
    "            mask.scatter_(1, topk_indices, True)\n",
    "            routing_probs = probs * mask\n",
    "            expert_usage = mask.float().mean(0)\n",
    "            routing_weights = routing_probs.mean(0)\n",
    "            load_balance_loss = self.num_experts * (expert_usage * routing_weights).sum()\n",
    "            \n",
    "            aux_loss = importance_loss + load_balance_loss\n",
    "        else:\n",
    "            aux_loss = 0.0\n",
    "\n",
    "        # 专家分配逻辑\n",
    "        flat_indices = topk_indices.view(-1)\n",
    "        flat_probs = topk_probs.view(-1)\n",
    "        sample_indices = torch.arange(batch_size, device=device)[:, None]\\\n",
    "                            .expand(-1, self.top_k).flatten()\n",
    "\n",
    "        # 初始化输出\n",
    "        outputs = torch.zeros(batch_size, self.experts[0].net[-1].out_features, \n",
    "                            device=device)\n",
    "\n",
    "        # 处理每个专家\n",
    "        for expert_idx in range(self.num_experts):\n",
    "            # 获取分配给当前专家的样本\n",
    "            expert_mask = flat_indices == expert_idx\n",
    "            expert_samples = sample_indices[expert_mask]\n",
    "            expert_weights = flat_probs[expert_mask]\n",
    "\n",
    "            # 容量控制\n",
    "            if len(expert_samples) > self.expert_capacity:\n",
    "                expert_samples = expert_samples[:self.expert_capacity]\n",
    "                expert_weights = expert_weights[:self.expert_capacity]\n",
    "\n",
    "            if len(expert_samples) == 0:\n",
    "                continue\n",
    "\n",
    "            # 处理专家计算\n",
    "            expert_input = x[expert_samples]\n",
    "            expert_output = self.experts[expert_idx](expert_input)\n",
    "            weighted_output = expert_output * expert_weights.unsqueeze(-1)\n",
    "            \n",
    "            # 累加输出\n",
    "            outputs.index_add_(0, expert_samples, weighted_output)\n",
    "\n",
    "        return outputs, aux_loss\n",
    "\n",
    "# 测试示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_dim = 5\n",
    "    output_dim = 10\n",
    "    num_experts = 8\n",
    "    top_k = 3\n",
    "    expert_capacity = 32\n",
    "    hidden_dim = 512\n",
    "    batch_size = 10\n",
    "\n",
    "    # add\n",
    "    device = torch.device(\"cpu\")\n",
    "    moe = MoE(input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim).to(device)\n",
    "    x = torch.randn(batch_size, input_dim).to(device)\n",
    "    moe.eval()\n",
    "    output, _ = moe(x)\n",
    "    print(f\"Eval output shape: {output.shape}\") # torch.Size([64, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a346e-dc2e-4e5a-9ddb-9118efa260aa",
   "metadata": {},
   "source": [
    "接下来，我们把每一部分拆解进行解读。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc23c0-352d-444d-baf8-117b48eb34d8",
   "metadata": {},
   "source": [
    "### 初始化函数定义\n",
    "\n",
    "首先，定义了 Expert 类，也就是“专家”，可以看到，专家是由线性层和激活函数构成的简单模型。\n",
    "\n",
    "然后开始定义 MOE 类。在初始化函数中，定义了这样几个变量：\n",
    "\n",
    "self.num_experts：专家的数量，也就是上面提到的“并列线性层”的个数，训练后的每个专家的权重都是不同的，代表它们所掌握的“知识”是不同的。\n",
    "\n",
    "self.top_k：每个输入 token 激活的专家数量。\n",
    "\n",
    "self.expert_capacity：代表计算每组 token 时，每个专家能被选择的最多次数。\n",
    "\n",
    "self.gate：路由网络，一般是一个线性层，用来计算每个专家被选择的概率。\n",
    "\n",
    "self.experts：实例化 Expert 类，生成多个专家。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d67664-f8da-4c2a-ac10-b61f825c25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experts = num_experts\n",
    "top_k = top_k\n",
    "expert_capacity = expert_capacity\n",
    "# 路由网络\n",
    "gate = nn.Linear(input_dim, num_experts)\n",
    "# 专家集合\n",
    "experts = nn.ModuleList(\n",
    "    [Expert(input_dim, hidden_dim, output_dim) for _ in range(num_experts)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e34da-b13b-431d-909c-81c9938a9409",
   "metadata": {},
   "source": [
    "### 前向计算逻辑\n",
    "\n",
    "接下来看一下 forward 函数。\n",
    "\n",
    "首先是输入 x，shape 是（batch_size, input_dim），batch_size 我们可以看作是 token 的数量，也就是序列长度。然后通过 self.gate 和 softmax 计算每个 token 在每个专家上的激活概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b54957a1-6d7a-41cb-b64f-6f6f217d3294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs:  tensor([[0.1105, 0.0906, 0.1629, 0.1508, 0.2257, 0.1269, 0.0388, 0.0938],\n",
      "        [0.0668, 0.1061, 0.0902, 0.1864, 0.2158, 0.1080, 0.0913, 0.1354],\n",
      "        [0.0482, 0.0661, 0.0373, 0.1738, 0.2768, 0.0696, 0.1436, 0.1845],\n",
      "        [0.1450, 0.0297, 0.0412, 0.1784, 0.2312, 0.1261, 0.0879, 0.1605],\n",
      "        [0.2216, 0.0650, 0.0464, 0.0996, 0.0547, 0.3725, 0.0915, 0.0487],\n",
      "        [0.1987, 0.0730, 0.1046, 0.0963, 0.0684, 0.3503, 0.0533, 0.0553],\n",
      "        [0.0512, 0.1033, 0.0112, 0.2495, 0.0582, 0.1068, 0.3491, 0.0707],\n",
      "        [0.1033, 0.1161, 0.0553, 0.2258, 0.1429, 0.1449, 0.1225, 0.0892],\n",
      "        [0.0377, 0.1224, 0.1002, 0.1947, 0.2121, 0.0792, 0.0942, 0.1596],\n",
      "        [0.0441, 0.1337, 0.0439, 0.1240, 0.1968, 0.1091, 0.2043, 0.1441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = gate(x)\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "print(\"probs: \", probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0511e2-69be-4cbd-92d4-b66f91e1a339",
   "metadata": {},
   "source": [
    "probs 的打印结果如上：我们设置的 batch_size 是 10，num_experts 是 8，所以 probs 是个 10 行 8 列的矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d192c38-b5e0-4a9c-8e4c-4a951c60ebf5",
   "metadata": {},
   "source": [
    "接着，再用 topk 算子把每个 token 的激活专家选出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c37acc98-f2b3-4f79-a647-2c2de4333072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk_probs:  tensor([[0.2257, 0.1629, 0.1508],\n",
      "        [0.2158, 0.1864, 0.1354],\n",
      "        [0.2768, 0.1845, 0.1738],\n",
      "        [0.2312, 0.1784, 0.1605],\n",
      "        [0.3725, 0.2216, 0.0996],\n",
      "        [0.3503, 0.1987, 0.1046],\n",
      "        [0.3491, 0.2495, 0.1068],\n",
      "        [0.2258, 0.1449, 0.1429],\n",
      "        [0.2121, 0.1947, 0.1596],\n",
      "        [0.2043, 0.1968, 0.1441]], grad_fn=<TopkBackward0>)\n",
      "topk_indices:  tensor([[4, 2, 3],\n",
      "        [4, 3, 7],\n",
      "        [4, 7, 3],\n",
      "        [4, 3, 7],\n",
      "        [5, 0, 3],\n",
      "        [5, 0, 2],\n",
      "        [6, 3, 5],\n",
      "        [3, 5, 4],\n",
      "        [4, 3, 7],\n",
      "        [6, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "topk_probs, topk_indices = torch.topk(probs, top_k, dim=-1)\n",
    "print(\"topk_probs: \", topk_probs)\n",
    "print(\"topk_indices: \", topk_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51498f7d-8e4f-4948-af76-882d05de2ad8",
   "metadata": {},
   "source": [
    "topk_probs 和 topk_indices 的打印结果如上，因为我们设置的 top_k=3，所以每个 token 都把排名前三的概率选出来了，同时 topk_indices 把这些概率对应的专家编号也选出来了。\n",
    "\n",
    "self.training 分支对应的是训练过程中计算损失函数的部分，我们后面再讲。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedcf34-623b-4fb2-9881-cdab5419ff5e",
   "metadata": {},
   "source": [
    "选择好专家后，就要开始计算了。计算规则是，对于每个 token，假如它选择的专家是 e1、e2、e3，概率分别是 p1、p2、p3，那么这个 token 的计算结果就是 p1xe1_out+p2xe2_out+p3xe3_out。\n",
    "\n",
    "由于计算个体是每个专家，所以代码中用 for 循环遍历每个专家。我们以第 0 个专家为例，看看它的计算过程是怎样的。\n",
    "\n",
    "首先需要确定 0 号专家的输入。由于不是每个 token 都选择了 0 号专家，所以不能把 x 直接作为输入，而是要确定一个下标向量 idxes，把 x[idxes]作为 0 号专家的输入，idxes 的值就是激活了 0 号专家的所有 token 编号，那么怎么得到 idxes 呢？代码里面是这样做的：\n",
    "\n",
    "首先计算一个 mask（假设 expert_idx=0）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6f4144-902b-4f49-8cd9-5ca54eecb25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "flat_indices = topk_indices.view(-1)\n",
    "expert_idx = 0\n",
    "expert_mask = flat_indices == expert_idx\n",
    "print(expert_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b8992-a287-4997-ad2d-08bdfe741575",
   "metadata": {},
   "source": [
    "flat_indices 是 topk_indices 平铺之后的向量。通过对比，可以看到 expert_mask 中 True 的位置和 topk_indices 中 0 的位置铺平之后是一致的，代表第 0 个专家被第 4 个和第 5 个 token 激活了。\n",
    "\n",
    "而且 expert_mask 代表的含义是：只要它的第 0-2 的位置是 True 的话，就代表被第 0 个 token 激活了，只要它的第 3-5 的位置是 True 的话，就代表被第 1 个 token 激活了，以此类推，我们可以声明一个 sample_indices 向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11bda11b-ea22-4c06-b839-b56bcf0077ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,\n",
      "        8, 8, 8, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "sample_indices = torch.arange(batch_size, device=device)[:, None].expand(-1, top_k).flatten()\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1991b4-4536-4df2-b692-d50e92c0c5fa",
   "metadata": {},
   "source": [
    "再通过下面的代码就可以把 idxes 取出来了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6a2739f-b2db-4f69-91f9-2b54557773f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5])\n"
     ]
    }
   ],
   "source": [
    "expert_samples = sample_indices[expert_mask]\n",
    "print(expert_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9d6c5-1eed-4642-94f7-b53333daf672",
   "metadata": {},
   "source": [
    "也顺便把概率权重取出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6313b87e-24c3-4ba5-8b38-fe229ccef75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2216, 0.1987], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "flat_probs = topk_probs.view(-1)\n",
    "expert_weights = flat_probs[expert_mask]\n",
    "print(expert_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2567e-c58f-449a-b127-1c23217736ab",
   "metadata": {},
   "source": [
    "接着把输入取出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c19a212c-13e1-4784-a8d5-507cf58263c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7454, -1.4269, -1.1833, -0.2611,  1.4887],\n",
      "        [-0.9482, -1.9723, -0.2507,  0.4739,  1.0142]])\n"
     ]
    }
   ],
   "source": [
    "expert_input = x[expert_samples]\n",
    "print(expert_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41966b39-936f-4def-a98b-d61de36d623d",
   "metadata": {},
   "source": [
    "再进行专家计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ae1e1ba-c7fa-4ccc-aba2-b0913f831f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_output = experts[expert_idx](expert_input)\n",
    "weighted_output = expert_output * expert_weights.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3110a-a695-4a95-844c-93684ef0ab23",
   "metadata": {},
   "source": [
    "最后还需要把计算结果叠加到对应的 token 上面去："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f24cd12d-ed80-4504-96f6-dcfd95f13d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0145, -0.0041,  0.0212, -0.0435, -0.0893, -0.0695, -0.0123, -0.0462,\n",
       "         -0.1006,  0.0255],\n",
       "        [-0.0135,  0.0327,  0.0766, -0.0206, -0.0717, -0.0597, -0.0358, -0.0326,\n",
       "         -0.0773,  0.0074],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]], grad_fn=<IndexAddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = torch.zeros(batch_size, experts[0].net[-1].out_features)\n",
    "outputs.index_add_(0, expert_samples, weighted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914be091-ebe7-42f1-976e-a99e80f63c58",
   "metadata": {},
   "source": [
    "完成上面的 for 循环之后，就把所有专家的计算任务完成了，通过 index_add_的操作，把每个 token 的计算结果也汇总了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdd2c3-8750-47b1-8e09-7fd815d15812",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "损失函数包含 2 部分：专家利用率均衡和样本分配均衡。\n",
    "\n",
    "首先是专家利用率均衡，如果每个专家被选择的概率相近，那么说明分配越均衡，损失函数越小：\n",
    "\n",
    "```\n",
    "importance = probs.sum(0)\n",
    "importance_loss = torch.var(importance) / (self.num_experts ** 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333a684-9308-437b-b442-a05df6b8fc2d",
   "metadata": {},
   "source": [
    "然后是样本分配均衡，首先得到每个 token、每个专家的分配概率矩阵：\n",
    "\n",
    "```\n",
    "mask = torch.zeros_like(probs, dtype=torch.bool)\n",
    "mask.scatter_(1, topk_indices, True)\n",
    "routing_probs = probs * mask\n",
    "```\n",
    "\n",
    "然后按照 token 维度（样本维度）求平均，得到每个专家被分配的 token 平均数量和平均概率：\n",
    "\n",
    "```\n",
    "expert_usage = mask.float().mean(0)\n",
    "routing_weights = routing_probs.mean\n",
    "```\n",
    "\n",
    "两者相乘求和得到负载均衡损失：\n",
    "\n",
    "```\n",
    "load_balance_loss = self.num_experts * (expert_usage * routing_weights).sum()\n",
    "```\n",
    "\n",
    "样本分配越均衡，这个损失函数越小。举个例子，10 个专家，10 个样本，如果所有样本都分到 1 个专家，那么损失函数值为 10x1+0+0...+0=10，如果平均分给 10 个专家，那么损失函数值为 1x0.1+1x0.1+...+1x0.1=1。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
