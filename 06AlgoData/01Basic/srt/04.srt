1
00:00:00,000 --> 00:00:02,233
内容/录制:Z0MI 酱，视频后期/字幕:梁嘉铭

2
00:00:02,233 --> 00:00:03,000
hello 大家好

3
00:00:03,000 --> 00:00:05,200
我是那个也想乘风破浪

4
00:00:05,200 --> 00:00:07,566
奈何肉身太胖的 ZOMI

5
00:00:10,500 --> 00:00:12,933
今天来到了整个变形金刚

6
00:00:12,933 --> 00:00:16,233
transformer 的注意力机制的全解析

7
00:00:16,233 --> 00:00:17,500
为什么叫全解析

8
00:00:17,533 --> 00:00:19,500
后面会重点去看一下

9
00:00:19,500 --> 00:00:19,833
现在

10
00:00:19,833 --> 00:00:22,600
回到整个 transformer 架构的一个内容

11
00:00:22,600 --> 00:00:24,566
现在来到了一个核心机制

12
00:00:24,600 --> 00:00:28,100
重点去看看里面的所谓的 Attention

13
00:00:28,266 --> 00:00:30,033
经常很多人搞不清楚 Attention

14
00:00:30,033 --> 00:00:32,766
Transformer 包括 QKV 是什么意思

15
00:00:32,766 --> 00:00:33,700
whatever 了

16
00:00:33,733 --> 00:00:35,433
现在简单的来看一下

17
00:00:35,433 --> 00:00:37,233
整个 Transformer 或者 Attention

18
00:00:37,233 --> 00:00:38,766
解决的主要的问题

19
00:00:39,000 --> 00:00:41,566
就是传统的序列模型

20
00:00:41,566 --> 00:00:43,266
或者时序模型

21
00:00:43,366 --> 00:00:45,166
最重要的一个局限性

22
00:00:45,166 --> 00:00:48,500
就是长距离的依赖丢失

23
00:00:48,533 --> 00:00:51,366
而且并行计算非常困难

24
00:00:51,366 --> 00:00:53,233
回顾一下 RNN 时代

25
00:00:53,233 --> 00:00:55,800
基本上都用 CPU 进行处理

26
00:00:55,800 --> 00:00:57,900
所以在 2016 年之前

27
00:00:58,033 --> 00:01:00,066
时序问题都是很难解决

28
00:01:00,166 --> 00:01:01,666
那解决这个问题

29
00:01:01,700 --> 00:01:04,033
就提出了一个所谓的 Attention

30
00:01:04,033 --> 00:01:06,100
那就通过权重分配

31
00:01:06,166 --> 00:01:08,200
聚焦关键信息

32
00:01:08,200 --> 00:01:09,000
Attention

33
00:01:09,000 --> 00:01:10,166
关键信息

34
00:01:10,166 --> 00:01:11,366
聚焦

35
00:01:11,366 --> 00:01:14,000
那后面就会详细的去展开

36
00:01:14,000 --> 00:01:14,700
这里面

37
00:01:14,733 --> 00:01:16,233
之所以说这个视频

38
00:01:16,233 --> 00:01:17,433
可能有点长

39
00:01:17,433 --> 00:01:17,900
但是

40
00:01:17,933 --> 00:01:19,500
ZOMI 希望能够通过这个视频

41
00:01:19,500 --> 00:01:22,233
真正的去讲明白什么是 Attention

42
00:01:22,233 --> 00:01:24,400
因为之前在 ZOMI 查阅大量的资料

43
00:01:24,400 --> 00:01:26,966
之前其实我知道 Attention 的原理

44
00:01:26,966 --> 00:01:29,566
它是怎么来的其实没有很好的考究

45
00:01:29,566 --> 00:01:30,433
那这期视频

46
00:01:30,433 --> 00:01:33,500
希望能跟大家去娓娓道来

47
00:01:33,533 --> 00:01:35,333
当然听不懂的或者听不习惯

48
00:01:35,333 --> 00:01:37,566
或者听不了那么长的视频

49
00:01:37,566 --> 00:01:38,466
小伙伴们

50
00:01:38,500 --> 00:01:39,700
也可以简单的跳过了

51
00:01:39,700 --> 00:01:41,400
其实 Attention 的机制很简单

52
00:01:41,400 --> 00:01:43,033
就是 QKV 相乘嘛

53
00:01:43,166 --> 00:01:45,700
那现在回到整个视频的目录大纲

54
00:01:45,733 --> 00:01:47,033
虽然废话多了一点

55
00:01:47,166 --> 00:01:49,633
开始先看一下 Attention 的由来

56
00:01:49,633 --> 00:01:51,233
它到底是怎么来

57
00:01:51,366 --> 00:01:52,466
那来了之后

58
00:01:52,500 --> 00:01:55,100
看下它的一个核心的技术

59
00:01:55,133 --> 00:01:55,766
了解完之后

60
00:01:55,766 --> 00:01:58,066
打开所谓的 Self-Attention

61
00:01:58,100 --> 00:01:58,966
加了个 self

62
00:01:58,966 --> 00:02:00,300
到底是什么意思

63
00:02:00,366 --> 00:02:03,966
这里面其实整个原理是很简单

64
00:02:03,966 --> 00:02:06,833
重点就是在这里面 Attention 的技术

65
00:02:06,833 --> 00:02:08,233
那有了 Self-Attention 之后

66
00:02:08,233 --> 00:02:10,566
后面又有了 multi-head Attention

67
00:02:10,566 --> 00:02:12,666
到底 multi-head 又多了个什么

68
00:02:12,700 --> 00:02:15,366
比 Self-Attention 还有一个 mask self

69
00:02:15,366 --> 00:02:17,033
那这个 mask Self-Attention

70
00:02:17,033 --> 00:02:19,100
跟 Self-Attention 之间又是什么关系

71
00:02:19,133 --> 00:02:20,033
这期视频

72
00:02:20,033 --> 00:02:22,766
主要是跟大家搞清楚这些概念

73
00:02:24,133 --> 00:02:25,633
正式开始这个内容之前

74
00:02:25,633 --> 00:02:27,800
其实还是要提几个问题

75
00:02:27,800 --> 00:02:28,966
就带着这几个问题

76
00:02:28,966 --> 00:02:30,200
往下思考

77
00:02:30,200 --> 00:02:30,500
第一个

78
00:02:30,533 --> 00:02:33,733
就是 Attention 是不是等于 Self-Attention

79
00:02:34,000 --> 00:02:37,033
注意力机制跟自注意力机制

80
00:02:37,400 --> 00:02:39,466
跟多头自注意力机制

81
00:02:39,500 --> 00:02:41,200
哎呀这几个字太拗口了

82
00:02:41,200 --> 00:02:42,300
是不是一样

83
00:02:42,366 --> 00:02:43,800
到底有什么区别

84
00:02:43,800 --> 00:02:45,833
大家一定要搞清楚这个问题

85
00:02:46,133 --> 00:02:48,833
那接着看一下所谓的 Attention

86
00:02:48,833 --> 00:02:50,833
这里面只是笼统的跟大家介绍一下

87
00:02:50,833 --> 00:02:51,900
后面会详细

88
00:02:51,933 --> 00:02:52,833
第一个就是 Attention

89
00:02:52,833 --> 00:02:55,266
它主要是通过一个通用

90
00:02:55,500 --> 00:02:56,766
动态的信息筛选

91
00:02:56,766 --> 00:02:59,666
为不同的输入分配不同的权重了

92
00:02:59,700 --> 00:03:00,800
就针对不同的输入

93
00:03:00,800 --> 00:03:02,800
我有不同的一个权重

94
00:03:02,800 --> 00:03:06,300
让模型更关注于当前的任务

95
00:03:06,566 --> 00:03:07,566
那这里面

96
00:03:07,566 --> 00:03:09,466
比较明确的就是计算 q

97
00:03:09,500 --> 00:03:11,100
跟 k 的相似度

98
00:03:11,133 --> 00:03:13,333
得到注意力的权重

99
00:03:13,333 --> 00:03:14,166
再对 v

100
00:03:14,166 --> 00:03:16,000
进行加权求和

101
00:03:16,000 --> 00:03:18,300
形成新的语义表征

102
00:03:18,333 --> 00:03:19,100
听不懂没关系

103
00:03:19,100 --> 00:03:20,766
后面会详细的介绍

104
00:03:20,766 --> 00:03:22,866
那接着看一下 Self-Attention

105
00:03:22,933 --> 00:03:23,800
Self-Attention

106
00:03:23,800 --> 00:03:26,966
其实只是 Attention 的一种特殊形态

107
00:03:26,966 --> 00:03:30,300
也就是 Attention 其实是大于 Self-Attention

108
00:03:30,333 --> 00:03:33,333
那这里面就要求 QKV 是同源

109
00:03:33,333 --> 00:03:35,200
也就是输入同一个

110
00:03:35,200 --> 00:03:36,666
就 x 输给 QS

111
00:03:36,700 --> 00:03:38,900
输给 K，X 输给 v

112
00:03:39,233 --> 00:03:40,266
那上面 Attention

113
00:03:40,300 --> 00:03:41,533
它的是不同源

114
00:03:41,533 --> 00:03:44,366
不同的输入可以分配不同的权重

115
00:03:44,366 --> 00:03:45,066
那这里面

116
00:03:45,100 --> 00:03:47,633
就让序列当中的每一个元素

117
00:03:47,633 --> 00:03:50,400
跟其他所有的元素都有所交集

118
00:03:50,400 --> 00:03:52,566
捕捉内部的一个依赖关系

119
00:03:52,566 --> 00:03:55,766
所以说需要通过一个 x 同源的输入

120
00:03:55,766 --> 00:03:57,066
让模型

121
00:03:57,100 --> 00:03:59,300
更多的去感知到不同的内容

122
00:03:59,300 --> 00:04:01,833
这个就是 Self-Attention 的一个意义了

123
00:04:02,300 --> 00:04:03,433
那听不懂没关系

124
00:04:03,433 --> 00:04:05,666
后面的真的是娓娓道来

125
00:04:05,700 --> 00:04:05,933
首先

126
00:04:05,933 --> 00:04:08,700
第一个看看 Attention 的一个来源

127
00:04:08,700 --> 00:04:09,833
Attention 是怎么来

128
00:04:10,133 --> 00:04:11,800
那想要了解 Attention

129
00:04:11,800 --> 00:04:13,433
首先我觉得重点

130
00:04:13,900 --> 00:04:15,133
因为第一个很核心

131
00:04:15,133 --> 00:04:15,933
就要看一下

132
00:04:15,933 --> 00:04:19,233
所谓的 encoder 跟 decoder 的一个框架了

133
00:04:19,333 --> 00:04:21,133
那在文本生成的时候

134
00:04:21,133 --> 00:04:23,533
一般都会把一些文本

135
00:04:23,533 --> 00:04:26,000
就是跟信号编码其实相类似

136
00:04:26,000 --> 00:04:29,733
需要把中文先 encoder 进行编码

137
00:04:29,766 --> 00:04:30,833
编码完之后

138
00:04:30,833 --> 00:04:33,800
就变成中间的一个语义编码信息

139
00:04:33,800 --> 00:04:34,766
但这个语义编码信息

140
00:04:34,766 --> 00:04:35,900
不知道是什么

141
00:04:35,966 --> 00:04:38,200
要把它翻译成为英文

142
00:04:38,200 --> 00:04:40,666
那这个时候再进行一个解码

143
00:04:40,833 --> 00:04:42,866
所以说编解码就是这么来

144
00:04:42,900 --> 00:04:43,833
那对于问答问题

145
00:04:43,833 --> 00:04:45,866
encoder 是一个问题

146
00:04:45,900 --> 00:04:47,033
那对于 decoder

147
00:04:47,033 --> 00:04:47,700
它可能就是

148
00:04:47,733 --> 00:04:49,766
一个回答的问题了

149
00:04:49,766 --> 00:04:51,400
所以我就是 ask 个问题

150
00:04:51,400 --> 00:04:54,700
然后 answer question 两个这么一个过来

151
00:04:54,733 --> 00:04:56,766
encoder 先编码后解码

152
00:04:56,766 --> 00:04:59,000
打电话也是一样

153
00:04:59,000 --> 00:05:01,266
先编码后解码

154
00:05:01,733 --> 00:05:03,000
那了解完 encoder 跟 decoder

155
00:05:03,000 --> 00:05:05,600
看一下所谓的 Attention 的由来

156
00:05:05,600 --> 00:05:06,433
那其实

157
00:05:06,433 --> 00:05:07,800
一开始提出 Attention 的时候

158
00:05:07,800 --> 00:05:09,466
是希望模型

159
00:05:09,500 --> 00:05:11,833
关注于输入的信息

160
00:05:11,833 --> 00:05:14,233
例如我是一个学生

161
00:05:14,233 --> 00:05:16,000
虽然 ZOMI 已经不是个学生了

162
00:05:16,133 --> 00:05:18,700
但是这里面只是举个例子嘛

163
00:05:18,700 --> 00:05:19,566
那希望模型

164
00:05:19,566 --> 00:05:22,033
可以在翻译 student 的时候

165
00:05:22,033 --> 00:05:24,300
更关注于学生这个单词

166
00:05:24,333 --> 00:05:25,233
因为这个句子

167
00:05:25,233 --> 00:05:26,666
最核心就是学生嘛

168
00:05:26,700 --> 00:05:28,166
而不是一个

169
00:05:28,166 --> 00:05:29,366
对吧一个有什么意思

170
00:05:29,366 --> 00:05:30,500
没什么意思

171
00:05:31,833 --> 00:05:32,300
首先

172
00:05:32,333 --> 00:05:36,566
还是回到 encoder 跟 decoder 的这个框架

173
00:05:36,566 --> 00:05:37,366
那框架里面

174
00:05:37,366 --> 00:05:37,966
看一下

175
00:05:37,966 --> 00:05:39,600
每一个都有一个输出

176
00:05:39,600 --> 00:05:43,366
Y1 Y2 到 Yi 中间是，，，，

177
00:05:43,366 --> 00:05:45,366
它们使用的是同一个语义编码

178
00:05:45,366 --> 00:05:47,266
c 去生成

179
00:05:47,300 --> 00:05:48,900
那这个很反直觉

180
00:05:49,200 --> 00:05:51,800
同一个语音编码生成很长的序列

181
00:05:51,800 --> 00:05:52,966
肯定是不行

182
00:05:52,966 --> 00:05:54,566
因为我一个语音编码

183
00:05:54,566 --> 00:05:56,200
可以生成一个简单的序列

184
00:05:56,200 --> 00:05:57,466
但是序列越来越长

185
00:05:57,500 --> 00:05:58,900
生成不同的内容

186
00:05:58,966 --> 00:06:00,800
翻译每一个单词的时候

187
00:06:00,800 --> 00:06:03,233
其实注意力都是有所侧重

188
00:06:03,233 --> 00:06:04,900
而不是漫无目的的搜索

189
00:06:04,933 --> 00:06:07,600
不是简单的从一个语义编码里面

190
00:06:07,600 --> 00:06:09,633
解码出各种各样的东西

191
00:06:09,633 --> 00:06:10,066
所以说

192
00:06:10,100 --> 00:06:12,600
这个时候希望有一个注意力

193
00:06:12,766 --> 00:06:13,366
那这个时候

194
00:06:13,366 --> 00:06:15,233
就提出了一个注意力了

195
00:06:15,233 --> 00:06:17,466
当需要预测 Yi 的时候

196
00:06:17,500 --> 00:06:19,333
就第 Yi 个信息的时候

197
00:06:19,333 --> 00:06:20,833
应该利用

198
00:06:20,833 --> 00:06:22,433
前一个时间段的隐藏层

199
00:06:22,433 --> 00:06:24,666
的输出 h i 的信息

200
00:06:24,733 --> 00:06:26,100
跟 encode 的过程当中

201
00:06:26,100 --> 00:06:27,900
每个隐空间

202
00:06:27,900 --> 00:06:30,233
或者隐时间输出的 h i

203
00:06:30,233 --> 00:06:32,033
进行一个计算

204
00:06:32,033 --> 00:06:33,500
再经过 Softmax

205
00:06:33,800 --> 00:06:34,200
得到

206
00:06:34,200 --> 00:06:37,600
对应的 score 的每一个位置的概率

207
00:06:37,600 --> 00:06:39,833
也就是我每一个输出

208
00:06:39,833 --> 00:06:42,000
假设 i am a student 我是个学生

209
00:06:42,000 --> 00:06:42,966
做个翻译

210
00:06:42,966 --> 00:06:46,566
那 student 其实跟前面

211
00:06:46,566 --> 00:06:48,066
中文的一个学生

212
00:06:48,200 --> 00:06:49,633
是有对应关系

213
00:06:49,633 --> 00:06:51,633
所以它不应该编码成一个

214
00:06:51,633 --> 00:06:52,800
简单的一个向量

215
00:06:52,800 --> 00:06:56,000
而是应该跟前面的编码 h i 相类似

216
00:06:56,000 --> 00:06:58,300
或者有相关的关联关系

217
00:06:58,333 --> 00:06:59,900
因此可以看到

218
00:06:59,900 --> 00:07:02,233
在整个 encoder decoder 的时候

219
00:07:02,233 --> 00:07:03,600
在做英文翻译

220
00:07:03,600 --> 00:07:05,266
因为一开始 encoder decoder

221
00:07:05,300 --> 00:07:07,233
用的最多就是做翻译任务

222
00:07:07,400 --> 00:07:08,633
那做翻译文中的时候

223
00:07:08,633 --> 00:07:10,033
看到 Attention 的时候

224
00:07:10,033 --> 00:07:11,100
就亮的地方

225
00:07:11,133 --> 00:07:12,833
就所对应的英文跟法文

226
00:07:12,833 --> 00:07:14,400
是有关联关系

227
00:07:14,400 --> 00:07:16,300
也就是我其中的 European

228
00:07:16,333 --> 00:07:19,900
跟 European 是有点相关联

229
00:07:19,900 --> 00:07:21,400
就跟刚才讲到

230
00:07:21,400 --> 00:07:24,000
学生跟 student 是有关联

231
00:07:24,000 --> 00:07:27,433
不是简单的通过一个语义编码

232
00:07:27,433 --> 00:07:29,033
去解决所有的问题

233
00:07:29,033 --> 00:07:31,900
而是应该跟我的一个 HI

234
00:07:31,933 --> 00:07:34,566
跟我的 Yi 是有强关联关系

235
00:07:34,566 --> 00:07:34,900
于是

236
00:07:34,933 --> 00:07:37,566
这里面因为这个概念就提出了

237
00:07:37,566 --> 00:07:38,500
Attention

238
00:07:38,533 --> 00:07:40,900
中间多了一个 HI

239
00:07:40,966 --> 00:07:43,866
跟 Yi 之间建立一个连接

240
00:07:43,900 --> 00:07:44,566
那这里面

241
00:07:44,566 --> 00:07:47,200
就来到了 Attention 的一个核心了

242
00:07:47,200 --> 00:07:47,866
那现在

243
00:07:47,900 --> 00:07:48,500
为了得到

244
00:07:48,500 --> 00:07:51,100
每个 Yi 的 Attention 的注意力的分布

245
00:07:51,100 --> 00:07:54,166
通过加权求和的方式去计算

246
00:07:54,166 --> 00:07:54,900
就可以得到

247
00:07:54,933 --> 00:07:57,366
预测 Yi 的时候的语义编码了

248
00:07:57,366 --> 00:07:59,900
所所谓真正的刚才的一个 c 了

249
00:08:00,000 --> 00:08:00,800
那其中可

250
00:08:00,800 --> 00:08:01,633
以看到

251
00:08:01,633 --> 00:08:03,800
A1 A12 A13

252
00:08:03,800 --> 00:08:04,766
分别表示

253
00:08:04,766 --> 00:08:06,800
预测第一个单词的时候

254
00:08:06,800 --> 00:08:09,033
一个 Attention 的分布的概率

255
00:08:09,100 --> 00:08:10,166
那通过概率

256
00:08:10,166 --> 00:08:11,266
可以看到

257
00:08:11,300 --> 00:08:14,500
对 c 进行一个处理

258
00:08:14,500 --> 00:08:15,200
之前的 c

259
00:08:15,200 --> 00:08:17,066
就是一个完全我不知道是什么的东西

260
00:08:17,100 --> 00:08:18,733
现在有了 Attention 之后

261
00:08:18,733 --> 00:08:22,433
通过 Softmax 进行一个求概率的分布

262
00:08:22,433 --> 00:08:24,366
如果我最后翻译的学生

263
00:08:24,366 --> 00:08:26,633
跟 student 是有关联关系

264
00:08:26,633 --> 00:08:28,500
那这里面的一个 A11

265
00:08:28,533 --> 00:08:30,166
假设是 student 学生

266
00:08:30,166 --> 00:08:32,266
那它的概率会更大

267
00:08:32,300 --> 00:08:34,833
占一个隐编码空间

268
00:08:34,833 --> 00:08:37,500
c 的权重就会更大了

269
00:08:37,533 --> 00:08:38,433
所以 Attention

270
00:08:38,433 --> 00:08:40,700
是通过概率分布来去显示

271
00:08:40,733 --> 00:08:44,166
我一开始的输入的权重表示的更核心

272
00:08:44,200 --> 00:08:45,400
那了解完这个之后

273
00:08:45,400 --> 00:08:48,200
基本上就做到数据的表示了

274
00:08:48,200 --> 00:08:49,966
就是利用整个 Attention 的分布

275
00:08:49,966 --> 00:08:51,233
对一个

276
00:08:51,366 --> 00:08:53,800
每个时间的隐空间的状态

277
00:08:53,800 --> 00:08:55,900
h i 进行加权求和

278
00:08:55,933 --> 00:08:58,300
就得到预测每一个单词的时候

279
00:08:58,300 --> 00:09:00,833
一个语义编码的信息了

280
00:09:00,833 --> 00:09:04,400
那这里面有一些简单的小的符号

281
00:09:04,400 --> 00:09:04,666
l

282
00:09:04,700 --> 00:09:06,933
就是表示原始文本的长度了

283
00:09:06,933 --> 00:09:09,966
Hi 就是表示每个时刻的隐藏空间

284
00:09:09,966 --> 00:09:11,366
就隐空间的输出

285
00:09:11,366 --> 00:09:13,166
那只是刚才已经讲完了

286
00:09:13,166 --> 00:09:14,200
那下面这个图

287
00:09:14,200 --> 00:09:16,266
就更加明显了

288
00:09:16,300 --> 00:09:18,633
假设我现在要预测一个

289
00:09:18,633 --> 00:09:20,966
还是那个学生的问题

290
00:09:20,966 --> 00:09:22,500
这里面是 student

291
00:09:22,533 --> 00:09:24,400
就是 s t u d e n t 了

292
00:09:24,400 --> 00:09:26,500
那 x i 是代表 STUDENT

293
00:09:26,600 --> 00:09:28,200
那学生 y i

294
00:09:28,200 --> 00:09:28,900
是输出

295
00:09:28,933 --> 00:09:29,633
这个时候

296
00:09:29,633 --> 00:09:31,800
因为每一个 h i

297
00:09:31,800 --> 00:09:33,800
也就每一个隐空间的时间

298
00:09:33,800 --> 00:09:35,833
都对应一个独立的 c

299
00:09:35,900 --> 00:09:36,633
那这个 c

300
00:09:36,633 --> 00:09:40,100
就是所谓的一个注意力了

301
00:09:40,133 --> 00:09:42,033
每一个具体的生成

302
00:09:42,033 --> 00:09:43,200
每个 Yi

303
00:09:43,200 --> 00:09:44,633
都有自己的注意力

304
00:09:44,633 --> 00:09:46,700
每个都有自己的权重的分布

305
00:09:46,733 --> 00:09:47,800
通过这种方式

306
00:09:47,800 --> 00:09:50,900
就得到了所谓的注意力的问题

307
00:09:50,933 --> 00:09:52,300
Attention 的问题

308
00:09:52,300 --> 00:09:54,333
所以这里面就说到了每一次预测

309
00:09:54,333 --> 00:09:57,500
都会先计算与之匹配的语义编码

310
00:09:57,500 --> 00:09:59,700
Ci 以前是统一个 c

311
00:09:59,700 --> 00:10:01,500
现在变成一个 Ci 了

312
00:10:01,500 --> 00:10:03,400
就是 Attention 的提出

313
00:10:03,833 --> 00:10:05,500
现在来到了第二个内容

314
00:10:05,533 --> 00:10:06,900
Attention 的核心原理

315
00:10:06,900 --> 00:10:08,600
刚才整个 Attention 的来源

316
00:10:08,600 --> 00:10:10,100
不知道大家听得懂没听懂

317
00:10:10,133 --> 00:10:12,333
反正以前一个统一的向量编码

318
00:10:12,333 --> 00:10:15,733
现在就变成概率分布的问题了

319
00:10:15,733 --> 00:10:17,800
所以说 ZOMI 觉得还是比较好理解

320
00:10:17,800 --> 00:10:19,300
现在来看看第二个内容

321
00:10:19,833 --> 00:10:21,633
Attention 的核心原理

322
00:10:22,000 --> 00:10:22,233
那

323
00:10:22,233 --> 00:10:25,766
相信了解过 Attention 机制的小伙伴们

324
00:10:25,766 --> 00:10:27,833
都知道这条公式了

325
00:10:27,833 --> 00:10:28,966
就是整个 Attention

326
00:10:28,966 --> 00:10:32,500
就是一个 QK v 相乘

327
00:10:32,600 --> 00:10:34,466
但是为什么 QK v 相乘

328
00:10:34,500 --> 00:10:37,166
其实很多的内容里面没讲清楚

329
00:10:37,166 --> 00:10:38,600
只是讲怎么 q

330
00:10:38,600 --> 00:10:40,100
怎么 k 怎么乘

331
00:10:40,300 --> 00:10:43,000
那这里面还是看一下事物的本质

332
00:10:43,000 --> 00:10:43,666
那 zomi

333
00:10:43,700 --> 00:10:46,033
就还是想跟大家一起探讨一下

334
00:10:46,033 --> 00:10:47,033
首先这里面

335
00:10:47,033 --> 00:10:49,500
把整个 score 看成一个对

336
00:10:49,533 --> 00:10:51,333
那对于每一个输入

337
00:10:51,333 --> 00:10:53,033
那 q 就是输入

338
00:10:53,366 --> 00:10:54,566
整个 Attention 机制里面

339
00:10:54,566 --> 00:10:57,600
把 Attention 里面的输入 q

340
00:10:57,600 --> 00:11:00,833
跟每一个 k 进行一个对比

341
00:11:00,833 --> 00:11:03,066
那这里面只是讲对比

342
00:11:03,100 --> 00:11:04,700
不是讲说相乘

343
00:11:04,700 --> 00:11:06,900
后面会讲到为什么会用相乘

344
00:11:06,900 --> 00:11:08,400
那得到的值

345
00:11:08,400 --> 00:11:09,000
跟

346
00:11:09,000 --> 00:11:10,600
一个 value 的权重

347
00:11:10,600 --> 00:11:14,866
进行一个相乘或者进行一个计算

348
00:11:14,933 --> 00:11:16,433
然后就得到 q 里面

349
00:11:16,433 --> 00:11:18,200
在整个时序里面

350
00:11:18,200 --> 00:11:22,066
因为时序从 123 到各种各样的 i

351
00:11:22,333 --> 00:11:23,900
在时序里面

352
00:11:23,900 --> 00:11:26,633
每一个位置的一个权重

353
00:11:26,700 --> 00:11:29,633
那例如我这里面是一个学生

354
00:11:29,633 --> 00:11:31,433
然后我可能某一个权重

355
00:11:31,433 --> 00:11:33,366
student 特别的重要

356
00:11:33,366 --> 00:11:35,366
所以说可能 value 3 的值

357
00:11:35,366 --> 00:11:36,500
会非常的高

358
00:11:36,533 --> 00:11:37,700
那通过这种方式

359
00:11:37,700 --> 00:11:40,566
就整个 Attention 的机制的核心了

360
00:11:40,566 --> 00:11:41,766
那通过这个方式

361
00:11:41,766 --> 00:11:43,633
叫做算 score

362
00:11:43,633 --> 00:11:45,500
算得分那这个得分

363
00:11:45,533 --> 00:11:47,700
就是一个权重的概率

364
00:11:47,700 --> 00:11:49,833
然后就得到 Attention 的一个 value 了

365
00:11:49,833 --> 00:11:51,400
那通过这种方式来去计算

366
00:11:51,400 --> 00:11:52,000
现在

367
00:11:52,000 --> 00:11:54,566
把每一步进行一个拆开

368
00:11:54,566 --> 00:11:55,766
所谓的 Attention

369
00:11:55,766 --> 00:11:58,500
实际上就是学习从大量的信息当中

370
00:11:58,533 --> 00:12:01,033
筛选出以当前的输入

371
00:12:01,033 --> 00:12:03,800
也就 query 最相关的信息

372
00:12:03,800 --> 00:12:04,833
那最相关的信息

373
00:12:04,833 --> 00:12:06,366
里面有很多个

374
00:12:06,366 --> 00:12:08,100
其中值越大

375
00:12:08,133 --> 00:12:11,000
就宣明这个信息的一个重要性

376
00:12:11,000 --> 00:12:12,066
就越重要

377
00:12:12,100 --> 00:12:12,566
那下面

378
00:12:12,566 --> 00:12:14,100
分开三步

379
00:12:14,133 --> 00:12:14,633
那第一步

380
00:12:14,633 --> 00:12:16,466
就将输入 query

381
00:12:16,500 --> 00:12:20,233
跟每一个 key 进行一个计算

382
00:12:20,233 --> 00:12:21,266
那这里面的计算

383
00:12:21,300 --> 00:12:23,533
就是 FQ 跟 KI

384
00:12:23,533 --> 00:12:25,233
因为每一个 i 进行计算

385
00:12:25,233 --> 00:12:27,200
那就得到了一个 q

386
00:12:27,200 --> 00:12:29,666
跟每一个 value 的相关性

387
00:12:29,700 --> 00:12:31,833
的 SI 了就相关性嘛

388
00:12:31,833 --> 00:12:32,400
那这里面

389
00:12:32,400 --> 00:12:34,833
为什么现在都用 q 乘以 k

390
00:12:34,833 --> 00:12:35,700
是因为

391
00:12:35,733 --> 00:12:38,166
对与矩阵的点乘的核心意义在于

392
00:12:38,166 --> 00:12:40,400
对齐位置的一个元素

393
00:12:40,400 --> 00:12:41,666
那一开始的时候

394
00:12:41,700 --> 00:12:44,300
主要是做那个翻译的任务

395
00:12:44,300 --> 00:12:46,400
所以翻回这个图

396
00:12:46,800 --> 00:12:48,033
可以看到 q

397
00:12:48,033 --> 00:12:51,066
如果跟 k 相同的时候

398
00:12:51,100 --> 00:12:53,333
就很方便的举成一个矩阵

399
00:12:53,366 --> 00:12:56,233
然后保证里面的翻译里面

400
00:12:56,433 --> 00:12:58,466
经常会最核心的信息

401
00:12:58,500 --> 00:13:00,533
都在对角线上面

402
00:13:00,533 --> 00:13:01,300
所以说

403
00:13:01,300 --> 00:13:02,800
现在来看到

404
00:13:02,800 --> 00:13:05,233
回到刚才的那一家公式

405
00:13:05,233 --> 00:13:06,866
就真正的这个计算

406
00:13:06,900 --> 00:13:07,966
可以有很多种

407
00:13:07,966 --> 00:13:10,600
但是最常用的就是 q 乘以 k

408
00:13:10,600 --> 00:13:13,033
当然了 q 或者 k 做一个转置

409
00:13:13,033 --> 00:13:15,233
才能够保证他们的元素相等

410
00:13:15,233 --> 00:13:17,433
然后进行一个矩阵的点乘

411
00:13:17,566 --> 00:13:18,066
那现在

412
00:13:18,100 --> 00:13:19,333
基本上矩阵的点乘

413
00:13:19,333 --> 00:13:21,000
就成为了整个 transformer

414
00:13:21,000 --> 00:13:22,466
一个架构的核心

415
00:13:22,500 --> 00:13:25,933
因为点乘可以有效的保留空间的结构

416
00:13:25,933 --> 00:13:27,833
和局部的信息

417
00:13:28,066 --> 00:13:29,400
那了解完第一步之后

418
00:13:29,400 --> 00:13:30,600
看一下第二步

419
00:13:30,600 --> 00:13:30,866
第二步

420
00:13:30,900 --> 00:13:34,900
就把第一步得到的相关的一个信息

421
00:13:34,900 --> 00:13:36,366
就相关的权重的信息

422
00:13:36,366 --> 00:13:38,566
进行一个 Softmax 的归一化的处理

423
00:13:38,566 --> 00:13:39,600
也就把所有东西

424
00:13:39,600 --> 00:13:42,033
都变成一个概率分布的形式

425
00:13:42,100 --> 00:13:45,200
a1 a2 跟 A3 A4 相加是等于一

426
00:13:45,200 --> 00:13:47,366
就变成概率分布的形态了

427
00:13:47,366 --> 00:13:48,633
这第二步比较简单

428
00:13:48,633 --> 00:13:50,300
所以大家都要经过 Softmax

429
00:13:50,333 --> 00:13:52,533
q K 的一个原因

430
00:13:52,633 --> 00:13:54,066
那第三步这里面

431
00:13:54,100 --> 00:13:54,733
应该 3 了

432
00:13:54,733 --> 00:13:55,433
那第三步

433
00:13:55,433 --> 00:13:58,166
就根据第二步的一个权重的系数

434
00:13:58,166 --> 00:14:00,200
对所有的 value 值

435
00:14:00,200 --> 00:14:02,633
进行一个加权求和

436
00:14:02,733 --> 00:14:04,133
那通过加权求和的方式

437
00:14:04,133 --> 00:14:06,566
就得到了整个 Attention

438
00:14:06,566 --> 00:14:07,700
整体的 value

439
00:14:07,733 --> 00:14:09,900
就知道这个 query 了

440
00:14:09,900 --> 00:14:12,433
对于每一个或者对于哪一个序列

441
00:14:12,433 --> 00:14:14,400
或者对于哪一个时序的点

442
00:14:15,200 --> 00:14:16,900
它的权重的意义更大

443
00:14:16,900 --> 00:14:17,933
那通过这种方式

444
00:14:17,933 --> 00:14:19,366
就得到整个 Attention

445
00:14:19,366 --> 00:14:20,900
机制的核心原理了

446
00:14:21,600 --> 00:14:23,000
下面

447
00:14:23,000 --> 00:14:25,600
这期视频还是有点无聊

448
00:14:25,600 --> 00:14:26,466
有点废话有点多

449
00:14:26,500 --> 00:14:28,100
因为概念实在太多了

450
00:14:29,966 --> 00:14:30,866
现在来到了

451
00:14:30,900 --> 00:14:33,500
Self-Attention 的核心的原理

452
00:14:33,500 --> 00:14:35,700
为什么会多了一个 self

453
00:14:35,700 --> 00:14:38,433
其实这里面说了非常多的信息

454
00:14:38,433 --> 00:14:40,233
这个就是整个 Self-Attention

455
00:14:40,233 --> 00:14:41,566
注意力的机制

456
00:14:41,633 --> 00:14:42,500
跟刚才一样

457
00:14:42,533 --> 00:14:44,233
有一个输入 x

458
00:14:44,233 --> 00:14:47,000
然后进行一个 q k v 的相乘

459
00:14:47,000 --> 00:14:48,100
然后有个 soft Max

460
00:14:48,133 --> 00:14:49,966
然后再进行一个累加

461
00:14:50,033 --> 00:14:52,166
那其实是比较相似

462
00:14:52,166 --> 00:14:53,566
这个 self 的 self

463
00:14:53,566 --> 00:14:55,766
就多就多在这个 self 自身

464
00:14:55,766 --> 00:14:58,766
也就是我的一个输入都是相同

465
00:14:58,766 --> 00:15:01,200
那回到刚才的一个公式

466
00:15:01,200 --> 00:15:03,066
就整个 Attention 的机制

467
00:15:03,100 --> 00:15:04,733
就 q k v 相乘

468
00:15:04,866 --> 00:15:06,300
然后基本上这条公式

469
00:15:06,333 --> 00:15:07,433
但是 Self-Attention

470
00:15:07,433 --> 00:15:09,166
就保证我的所有的输入

471
00:15:09,166 --> 00:15:10,400
其实都是一样

472
00:15:10,400 --> 00:15:12,866
不管是 q k v 哪哪个

473
00:15:12,900 --> 00:15:15,900
我都是使用 s 进行一个输入

474
00:15:15,966 --> 00:15:18,266
这种方式就保证一个目标

475
00:15:18,300 --> 00:15:19,566
跟一个输入

476
00:15:19,566 --> 00:15:22,833
在 Attention 机制及下面是一模一样

477
00:15:22,833 --> 00:15:23,766
就我自己

478
00:15:23,766 --> 00:15:24,600
卷我自己

479
00:15:24,600 --> 00:15:24,966
我自己

480
00:15:24,966 --> 00:15:28,433
看我自己的一个重要性到底在哪里

481
00:15:28,833 --> 00:15:30,766
那可以看一下下面

482
00:15:30,766 --> 00:15:31,266
蛮有意思

483
00:15:31,300 --> 00:15:34,600
就是你会发现所谓的自注意力

484
00:15:34,633 --> 00:15:37,766
就是我输入的是一个 x 的一个数据

485
00:15:37,766 --> 00:15:38,833
我这里面

486
00:15:38,833 --> 00:15:40,033
也是寻求 x

487
00:15:40,166 --> 00:15:43,700
跟他自身的其他元素的一个相关性

488
00:15:43,700 --> 00:15:45,733
所以说到了就是 Self-Attention

489
00:15:45,733 --> 00:15:46,900
一定程度上面

490
00:15:46,900 --> 00:15:48,766
是捕捉一个句子当中

491
00:15:48,833 --> 00:15:51,100
单词之间的一个句法的特征

492
00:15:51,133 --> 00:15:54,433
或者一个语义的特征相关性

493
00:15:54,600 --> 00:15:55,700
学习自己

494
00:15:55,700 --> 00:15:57,100
相关性那这里面

495
00:15:57,100 --> 00:15:59,100
还是简单的打开一下

496
00:15:59,100 --> 00:16:01,233
整个 Self-Attention 的一个原理

497
00:16:01,233 --> 00:16:03,100
同样的分开三步

498
00:16:03,133 --> 00:16:04,333
首先第一个

499
00:16:04,333 --> 00:16:05,900
就是跟刚才不一样了

500
00:16:05,900 --> 00:16:08,500
现在变成输入是一个 x

501
00:16:08,500 --> 00:16:09,533
同样的输入

502
00:16:09,533 --> 00:16:12,300
然后我需要进行一个 q

503
00:16:12,300 --> 00:16:14,733
k v 三个矩阵的相乘

504
00:16:14,733 --> 00:16:15,433
那三个矩阵

505
00:16:15,433 --> 00:16:18,166
就定义 Wq Wk Wv

506
00:16:18,166 --> 00:16:19,900
然后乘以一个 x 输出矩阵

507
00:16:19,933 --> 00:16:22,166
于是得到 3 个输出

508
00:16:22,166 --> 00:16:23,866
QKV 的输出了

509
00:16:23,900 --> 00:16:25,366
当然了因为矩阵很多

510
00:16:25,366 --> 00:16:27,100
或者元素很多

511
00:16:27,133 --> 00:16:28,800
因为这里面是有时序

512
00:16:28,800 --> 00:16:29,433
第一个单词

513
00:16:29,433 --> 00:16:30,066
第二个单词

514
00:16:30,100 --> 00:16:31,133
第三个单词

515
00:16:31,133 --> 00:16:32,500
所以说有很多时序

516
00:16:32,500 --> 00:16:35,766
就得到很多个 QI KI VI 了

517
00:16:35,766 --> 00:16:37,266
得到这些之后

518
00:16:37,300 --> 00:16:39,233
需要对所有的东西

519
00:16:39,233 --> 00:16:41,066
进行一个点乘

520
00:16:41,100 --> 00:16:42,166
就刚才的一个

521
00:16:42,166 --> 00:16:43,800
Self-Attention 的一个原理了

522
00:16:43,800 --> 00:16:45,266
那为什么是点乘

523
00:16:45,300 --> 00:16:46,900
是因为点乘计算起来比较简单

524
00:16:46,900 --> 00:16:49,966
能够捕捉空间的就矩阵空间的信息

525
00:16:49,966 --> 00:16:52,300
所以就变成一个点乘的方式了

526
00:16:52,333 --> 00:16:54,533
当然了有很多其他的计算方式了

527
00:16:54,566 --> 00:16:55,400
那算完之后

528
00:16:55,400 --> 00:16:57,233
第二步就来到了第三步

529
00:16:57,233 --> 00:16:57,900
第三步

530
00:16:57,933 --> 00:17:00,033
就是做一个缩放系数

531
00:17:00,033 --> 00:17:01,066
所谓的缩放系数

532
00:17:01,100 --> 00:17:03,700
就保证了累积之后

533
00:17:03,700 --> 00:17:05,100
因为 q 乘以 k

534
00:17:05,100 --> 00:17:06,400
就是做一个累积嘛

535
00:17:06,400 --> 00:17:07,400
累积之后

536
00:17:07,400 --> 00:17:08,300
整个的答案

537
00:17:08,333 --> 00:17:09,833
不会随着维度而增加

538
00:17:09,833 --> 00:17:11,666
就除以那个根号 d 了

539
00:17:11,700 --> 00:17:15,400
维度保证标准化整体的输出

540
00:17:15,566 --> 00:17:16,600
最后

541
00:17:16,600 --> 00:17:17,433
就第四步了

542
00:17:17,433 --> 00:17:19,166
就算那个 Attention score 了

543
00:17:19,166 --> 00:17:20,800
那当然刚才其实中间漏了一步

544
00:17:20,800 --> 00:17:22,600
就是 Softmax 的一个计算了

545
00:17:22,600 --> 00:17:23,800
那现在第四步了就

546
00:17:23,800 --> 00:17:26,000
算一个 value 的值

547
00:17:26,066 --> 00:17:26,700
那最后

548
00:17:26,733 --> 00:17:29,300
就把 value 的值进行一个加权求和

549
00:17:29,300 --> 00:17:30,633
所以跟刚才讲到

550
00:17:30,633 --> 00:17:32,433
一个 Attention 的机制是一样

551
00:17:32,433 --> 00:17:35,166
对一个 AI 进行一个加权求和

552
00:17:35,166 --> 00:17:36,166
就得到了

553
00:17:36,166 --> 00:17:38,900
一个中间的隐空间变量

554
00:17:38,933 --> 00:17:41,900
编码 Ci 那当然了这里面是 Z2

555
00:17:41,900 --> 00:17:43,033
有 Z2

556
00:17:43,033 --> 00:17:45,233
Z3 各种各样的隐空间变量

557
00:17:45,500 --> 00:17:47,100
来代表输出

558
00:17:47,100 --> 00:17:48,833
一个注意力的内容

559
00:17:48,833 --> 00:17:50,966
那不记得翻回去前面

560
00:17:51,300 --> 00:17:54,633
对于以前是统一一个隐空间

561
00:17:54,633 --> 00:17:56,233
有了注意力之后

562
00:17:56,233 --> 00:17:57,300
现在就变成

563
00:17:57,333 --> 00:18:00,433
每一个输出都有自己对应的 Ci

564
00:18:00,433 --> 00:18:02,500
对应自己的隐空间变量

565
00:18:02,533 --> 00:18:05,000
通过这种方式来去求得

566
00:18:05,233 --> 00:18:06,833
原理实际上很简单

567
00:18:06,833 --> 00:18:08,000
所有的 Self-Attention

568
00:18:08,000 --> 00:18:10,500
都是来自于 Attention 最核心的那个内容

569
00:18:10,533 --> 00:18:11,800
当然网上有很多

570
00:18:11,800 --> 00:18:13,833
去讲那个类似于这种

571
00:18:13,833 --> 00:18:15,300
这个矩阵是怎么乘

572
00:18:15,333 --> 00:18:16,966
就 QKB 怎么乘

573
00:18:16,966 --> 00:18:18,966
其实 ZOMI 觉得怎么乘不重要

574
00:18:18,966 --> 00:18:21,200
重要的是看懂它是怎么来

575
00:18:21,266 --> 00:18:22,000
那当然了

576
00:18:22,000 --> 00:18:23,966
后面还有很多的不同的版本

577
00:18:23,966 --> 00:18:24,666
包括李弘毅

578
00:18:24,700 --> 00:18:27,533
就讲了就这个 q 跟 KV 是怎么成

579
00:18:27,533 --> 00:18:28,566
就整的很复杂

580
00:18:28,566 --> 00:18:29,966
ZOMI 觉得还是没有必要

581
00:18:29,966 --> 00:18:32,600
大家还有网上那就是所谓的就这图

582
00:18:32,600 --> 00:18:34,100
花花绿绿的感觉很好看

583
00:18:34,133 --> 00:18:34,700
但实际上

584
00:18:34,700 --> 00:18:36,766
是没有太多的必要

585
00:18:36,833 --> 00:18:38,300
那已经讲完了

586
00:18:38,333 --> 00:18:40,133
整个 self-Attention 的机制了

587
00:18:40,366 --> 00:18:41,066
现在

588
00:18:41,100 --> 00:18:44,100
来到了一个所谓的 multi-head self-Attention

589
00:18:44,100 --> 00:18:46,300
当然了一般来说会叫 multi-Attention

590
00:18:46,300 --> 00:18:49,100
或者简称 m h a

591
00:18:49,100 --> 00:18:52,633
这里面就是多头注意力机制啦

592
00:18:54,633 --> 00:18:55,700
那比较有意思

593
00:18:55,733 --> 00:18:58,200
就是整个 Multi head Self-Attention

594
00:18:58,200 --> 00:18:59,766
其实多了

595
00:18:59,766 --> 00:19:02,600
就是把刚才的一个 Self-Attention

596
00:19:02,600 --> 00:19:04,466
做了一个并行

597
00:19:04,500 --> 00:19:06,333
就多了好几个

598
00:19:06,333 --> 00:19:07,133
那同时

599
00:19:07,133 --> 00:19:08,800
所以叫做 Multihead

600
00:19:08,800 --> 00:19:10,400
这里面讲的是一个 head

601
00:19:10,400 --> 00:19:12,033
然后有很多个就是 Multihead

602
00:19:12,300 --> 00:19:12,966
就这么简单

603
00:19:12,966 --> 00:19:14,233
没有其他的意思

604
00:19:14,233 --> 00:19:15,633
所以说可以看到

605
00:19:15,633 --> 00:19:18,466
就还是看一下它的一个计算公式了

606
00:19:18,500 --> 00:19:21,033
所谓的多头自注意力机制

607
00:19:21,033 --> 00:19:22,600
就是 Self-Attention 的一个扩展

608
00:19:22,600 --> 00:19:25,800
通过并行运算多个独立的注意力

609
00:19:25,800 --> 00:19:27,033
多个 Attention

610
00:19:27,033 --> 00:19:29,100
这里面抽象成一个 head 的概念

611
00:19:29,133 --> 00:19:31,800
所以说使得一个因为输入

612
00:19:31,800 --> 00:19:33,200
都是同一个输入

613
00:19:33,200 --> 00:19:34,400
就是同一个输入 x

614
00:19:34,400 --> 00:19:36,866
然后给到 q k v 进行一个计算嘛

615
00:19:36,900 --> 00:19:37,566
所以说

616
00:19:37,566 --> 00:19:41,000
重要的就是把一个 x 输入

617
00:19:41,233 --> 00:19:43,633
得到不同的特征的子空间

618
00:19:43,633 --> 00:19:44,666
通过多个头

619
00:19:44,700 --> 00:19:47,600
然后将所有的 head 的结果

620
00:19:47,600 --> 00:19:49,100
进行 concat 到一起

621
00:19:49,133 --> 00:19:50,366
就合并到一起

622
00:19:50,366 --> 00:19:53,000
然后经过一个线性层的融合

623
00:19:53,100 --> 00:19:55,000
所以说整体公式就变成这样了

624
00:19:55,000 --> 00:19:56,100
那每个头的计算公式

625
00:19:56,133 --> 00:19:58,033
其实跟刚才的 Attention 是一样

626
00:19:58,033 --> 00:20:00,666
重要的就是对同一一个输入

627
00:20:00,700 --> 00:20:02,600
通过多个头来去发现

628
00:20:02,600 --> 00:20:05,200
过来来去计算它不同的特征的空间

629
00:20:05,200 --> 00:20:06,666
挖掘更多的内容

630
00:20:06,733 --> 00:20:07,366
所以这里面

631
00:20:07,366 --> 00:20:08,900
就做了一个简单的对比

632
00:20:08,933 --> 00:20:10,033
有兴趣的小伙伴们

633
00:20:10,033 --> 00:20:11,766
也可以停下来这里面看一下

634
00:20:11,766 --> 00:20:12,866
self 跟 Attention

635
00:20:12,900 --> 00:20:14,300
跟 Multi head Attention

636
00:20:14,400 --> 00:20:16,400
里面的一个具体的区别

637
00:20:17,533 --> 00:20:18,766
那现在很快

638
00:20:18,766 --> 00:20:20,233
就来到了第五个内容

639
00:20:20,233 --> 00:20:22,100
看一下 mask Self-Attention

640
00:20:22,133 --> 00:20:25,166
那刚才仔细讲到了 Self-Attention 跟 MHA

641
00:20:25,300 --> 00:20:26,800
现在多了一个 mask

642
00:20:26,800 --> 00:20:28,966
到底为什么要经过一个 mask

643
00:20:29,100 --> 00:20:29,900
那这里面

644
00:20:29,900 --> 00:20:31,933
很简单的做了一个简单的对比

645
00:20:31,933 --> 00:20:33,533
首先 Self-Attention 的特点

646
00:20:33,533 --> 00:20:35,833
是双向序列都是可见

647
00:20:36,200 --> 00:20:38,366
也就是允许每个位置的 Token

648
00:20:38,366 --> 00:20:40,300
跟序列当中所有 Token 进行交互

649
00:20:40,333 --> 00:20:41,933
例如这个单词里面的每个

650
00:20:41,933 --> 00:20:42,766
跟后面的一个

651
00:20:42,766 --> 00:20:43,633
其他位置

652
00:20:43,633 --> 00:20:46,066
我在算后面的位置的时候

653
00:20:46,100 --> 00:20:48,433
我可以看每个前面的一个序列信息

654
00:20:48,633 --> 00:20:50,000
我在前面的序列的时候

655
00:20:50,000 --> 00:20:52,200
可以看后面的序列的信息

656
00:20:52,200 --> 00:20:53,600
所以 x

657
00:20:53,600 --> 00:20:55,466
跟一个或者 query

658
00:20:55,500 --> 00:20:58,333
跟 k 跟 v 是直接相乘

659
00:20:58,333 --> 00:20:59,200
那这种方式

660
00:20:59,200 --> 00:21:01,466
就比较适用于一个编码器

661
00:21:01,500 --> 00:21:02,566
也就是 encoder

662
00:21:02,566 --> 00:21:04,400
因为刚才讲到了 Transformer

663
00:21:04,400 --> 00:21:07,366
它自身也是个 encoder 跟 decoder 的架构嘛

664
00:21:07,366 --> 00:21:09,800
所以说 Self-Attention 更多是用在编码器

665
00:21:10,000 --> 00:21:13,200
那所谓的今个这个小节的内容

666
00:21:13,200 --> 00:21:14,866
就是 Mask Self-Attention

667
00:21:14,900 --> 00:21:18,166
更多的是在一个多头注意力机制里面

668
00:21:18,166 --> 00:21:20,566
引入了一个掩码的功能

669
00:21:20,566 --> 00:21:22,766
限制某些位置可见

670
00:21:22,766 --> 00:21:24,800
实现特定性的约束了

671
00:21:24,800 --> 00:21:25,400
那这个时候

672
00:21:25,400 --> 00:21:28,033
就更多的应用在一个解码器

673
00:21:28,033 --> 00:21:30,400
保证模型在生成的时候

674
00:21:30,500 --> 00:21:33,766
只依赖于前面的序列的信息

675
00:21:33,766 --> 00:21:34,766
也就是生成的时候

676
00:21:34,766 --> 00:21:36,900
就我在看确保的时候

677
00:21:36,933 --> 00:21:39,366
我希望看到下次生成的确保模型

678
00:21:39,366 --> 00:21:40,866
而不是看的更多的信息

679
00:21:40,900 --> 00:21:42,333
在看到确保模型之后

680
00:21:42,333 --> 00:21:44,800
我希望能够看到确保模型在生成

681
00:21:44,933 --> 00:21:46,333
这么一个过程

682
00:21:46,333 --> 00:21:49,300
每一次只偷看未来的一个 Token

683
00:21:49,333 --> 00:21:53,000
保证自回归的生成的因果关系

684
00:21:53,166 --> 00:21:53,966
那这里面

685
00:21:53,966 --> 00:21:56,100
重点讲到了因果关系

686
00:21:56,133 --> 00:21:57,500
才是整个 mask

687
00:21:57,500 --> 00:21:59,133
一个重点

688
00:21:59,166 --> 00:22:00,500
那这里面

689
00:22:00,533 --> 00:22:02,633
其实刚才讲的很抽象

690
00:22:02,633 --> 00:22:04,433
举两个具体的图

691
00:22:04,566 --> 00:22:05,366
Self-Attention

692
00:22:05,366 --> 00:22:07,700
序列当中的 a 的位置

693
00:22:07,733 --> 00:22:09,400
可以跟序列当中的 f

694
00:22:09,400 --> 00:22:12,300
随便一个位置进行相关联

695
00:22:12,333 --> 00:22:13,633
每个位置都可以

696
00:22:13,800 --> 00:22:16,366
但是加了一个 mask 之后

697
00:22:16,366 --> 00:22:17,366
就不一样了

698
00:22:17,366 --> 00:22:20,300
现在假设是 a b c d

699
00:22:20,333 --> 00:22:21,533
我算到 d 的时候

700
00:22:21,533 --> 00:22:24,633
我只能看到下一个序列 e 的关系

701
00:22:24,633 --> 00:22:26,866
我再也看不到后面的序列了

702
00:22:26,900 --> 00:22:30,233
这样保持生成式的时候

703
00:22:30,233 --> 00:22:31,233
有个因果关系

704
00:22:31,233 --> 00:22:32,233
当前的序列

705
00:22:32,233 --> 00:22:34,833
只跟前面的序列是强相关

706
00:22:34,833 --> 00:22:35,900
和下一个序列

707
00:22:35,933 --> 00:22:37,700
而不是跟后续所有的序列

708
00:22:37,700 --> 00:22:38,900
都有关联关系

709
00:22:38,900 --> 00:22:39,533
那这种

710
00:22:39,533 --> 00:22:41,766
就是只允许关注到

711
00:22:41,766 --> 00:22:45,666
输出序列早于当前位置的单词

712
00:22:45,733 --> 00:22:46,300
那这个

713
00:22:46,300 --> 00:22:49,400
就是 mask 的一个具体的作用了

714
00:22:49,566 --> 00:22:50,300
那看一下

715
00:22:50,333 --> 00:22:51,433
在一个具体

716
00:22:51,433 --> 00:22:53,000
一个语义场景里面的训练

717
00:22:53,000 --> 00:22:54,400
就分成 4 个步骤

718
00:22:54,400 --> 00:22:57,100
每一步就处理一个 Token

719
00:22:57,133 --> 00:22:58,700
例如我在第一步的时候

720
00:22:58,700 --> 00:23:00,333
我就处理下个 Token mask

721
00:23:00,400 --> 00:23:01,566
然后我下一次

722
00:23:01,566 --> 00:23:04,300
我输入这么多的一个内容给到 transformer

723
00:23:04,333 --> 00:23:07,233
然后输出的是一个下一个 Token

724
00:23:07,333 --> 00:23:07,800
同样

725
00:23:07,800 --> 00:23:09,700
我下一次是把所有的句子

726
00:23:09,733 --> 00:23:10,933
同样丢给 transformer

727
00:23:11,100 --> 00:23:13,000
然后再输出下一个

728
00:23:13,000 --> 00:23:15,000
那同样的以此类推

729
00:23:15,000 --> 00:23:16,766
所以可以假设

730
00:23:16,766 --> 00:23:18,900
模型的 batch size 为 4 的时候

731
00:23:18,933 --> 00:23:19,733
序列

732
00:23:19,733 --> 00:23:22,400
就作为下一个 batch 来进行一个处理

733
00:23:22,400 --> 00:23:23,866
那同样的在整个 mask 里面

734
00:23:23,900 --> 00:23:27,833
就 mask 掉后面的这坨信息啦

735
00:23:27,833 --> 00:23:29,300
那比较明确

736
00:23:29,766 --> 00:23:31,766
那刚才只是讲到一个训练的过程

737
00:23:31,766 --> 00:23:33,300
当中我的一个 feature

738
00:23:33,333 --> 00:23:34,400
因为训练的时候

739
00:23:34,400 --> 00:23:36,666
是把一堆语料丢进去大模型

740
00:23:36,700 --> 00:23:40,400
让大模型预测下一个单词到底是什么

741
00:23:40,400 --> 00:23:42,233
通过这种方式进行学习

742
00:23:42,433 --> 00:23:44,433
但是如果数据越多了

743
00:23:44,433 --> 00:23:45,666
所以一般来说

744
00:23:45,700 --> 00:23:47,000
就会变成一个矩阵

745
00:23:47,000 --> 00:23:49,633
把 query 跟 k 进行一个相乘

746
00:23:49,633 --> 00:23:50,300
那这里面

747
00:23:50,333 --> 00:23:52,166
就实际上计算的时候不是单词

748
00:23:52,166 --> 00:23:53,500
而是 Token

749
00:23:53,566 --> 00:23:55,900
然后整个矩阵进行计算

750
00:23:55,933 --> 00:23:57,733
那为了使得实现

751
00:23:57,733 --> 00:23:59,700
刚才的一个 mask 的概念

752
00:23:59,700 --> 00:24:02,100
这里面就做了一个很重要的工作

753
00:24:02,100 --> 00:24:04,433
就是加了一个 mask 掩码

754
00:24:04,533 --> 00:24:07,033
把后面的三角形以上的东西

755
00:24:07,033 --> 00:24:10,433
都变成一个负无穷或者是 0

756
00:24:10,500 --> 00:24:11,833
或者非常大的一个负数

757
00:24:11,833 --> 00:24:13,866
使得他不用去计算

758
00:24:13,933 --> 00:24:16,600
那通过这种方式来去实现

759
00:24:16,600 --> 00:24:18,400
那最后经过 soft max 之后

760
00:24:18,400 --> 00:24:21,300
就会所有东西都已经置 0 了

761
00:24:21,333 --> 00:24:22,233
那基本上

762
00:24:22,233 --> 00:24:25,200
mask 就是这么一个过程作用

763
00:24:25,200 --> 00:24:25,600
那当然

764
00:24:25,600 --> 00:24:27,366
也可以简单的对比一下

765
00:24:27,366 --> 00:24:28,800
Self-Attention 跟 mask

766
00:24:28,800 --> 00:24:30,833
Self-Attention 之间的一个区别

767
00:24:30,833 --> 00:24:31,500
其实 ZOMI

768
00:24:31,533 --> 00:24:33,633
觉得最核心的一个机制

769
00:24:33,633 --> 00:24:37,033
就是实现因果关系

770
00:24:37,033 --> 00:24:38,566
真正的对因果关系

771
00:24:38,566 --> 00:24:40,266
进行一个约束

772
00:24:40,533 --> 00:24:42,733
那今天的内容就差不多了

773
00:24:42,733 --> 00:24:45,800
来个简单的总结和思考

774
00:24:45,800 --> 00:24:46,400
首先

775
00:24:46,400 --> 00:24:49,100
整个 Self-Attention 是 transformer 的一个核心

776
00:24:49,133 --> 00:24:50,966
那通过计算序列当中

777
00:24:50,966 --> 00:24:53,966
输入不同位置之间的相关性

778
00:24:53,966 --> 00:24:57,566
实现了全局的时序的建模

779
00:24:57,600 --> 00:25:00,000
所以说整个 Self-Attention

780
00:25:00,000 --> 00:25:01,466
是 Transformer 架构里面

781
00:25:01,566 --> 00:25:04,666
表达能力最核心最强的关键

782
00:25:04,800 --> 00:25:06,366
那今天的内容就到这里为

783
00:25:06,366 --> 00:25:06,966
止谢谢各位

784
00:25:06,966 --> 00:25:08,033
拜了个拜

