# 数据源概述

大模型训练依赖于大规模、高质量、覆盖广泛的数据源。根据不同阶段（如预训练与后训练）的目标差异，对数据的任务适配性、语言覆盖度、格式一致性等要求也各不相同。

目前主流大模型在**预训练阶段**通常使用规模达 10T tokens 甚至更高的数据。例如，**DeepSeek-V3** 使用 14.8T tokens，**Qwen3** 使用了 36T tokens。相比之下，**后训练阶段**（如对齐训练、指令微调、RLHF）侧重于**人类偏好、任务泛化与响应质量**，数据量通常在百万级。

绝大多数高质量开源数据集可在 [Hugging Face Datasets](https://huggingface.co/datasets) 上获取。

---

### 通用网页类数据

主要用于语言模型初始预训练，涵盖广泛领域与话题，但需进行较强的数据清洗与筛选。

| 数据集                      | 简介                                          | 特点                         |
|---------------------------|---------------------------------------------|----------------------------|
| **Common Crawl**         | 每月更新的大规模网页抓取数据，原始 HTML 格式，体量达数百 TB      | 覆盖广泛，高噪声                |
| **C4**                   | 从 Common Crawl 中清洗提取正文构建，T5 模型使用的数据源         | 干净文本，适合英文模型预训练       |
| **RefinedWeb / FineWeb** | 对 CC 网页数据进行过滤与质量控制，面向现代语言模型             | 高质量，结构清晰，适合大规模预训练   |
| **OpenWebText**          | 模拟 Reddit 高质量链接对应网页构建，语料较为精炼               | 社交性强，信息密度高             |
| **Pile-CC**              | Pile 数据集中的网页部分，使用 CC 数据清洗构建                  | 噪声控制好，适合文本生成任务         |

---

### 学术与出版物类数据

该类数据有助于增强模型的专业知识理解与推理能力，广泛用于 STEM 相关能力提升。

| 数据集                  | 简介                                       | 特点                   |
|-----------------------|------------------------------------------|----------------------|
| **arXiv**             | 开源学术论文预印本，涵盖物理、数学、CS 等多个领域            | 内容深度高，结构良好          |
| **PubMed**            | 医学研究文献数据库，包含海量疾病、药物、病例等相关数据         | 医学领域基础语料             |
| **Semantic Scholar**  | 语义理解增强的学术数据集，适合摘要、推荐、引文预测等任务         | 多标签，多任务，结构优良         |
| **BookCorpus**        | 收集自网络小说的长篇文本，用于提升模型的长文本建模能力           | 长上下文，叙事性强            |
| **Gutenberg**         | 公共版权的古典英文小说集                               | 文体多样，语言表达丰富          |

---

### 指令与问答数据

常用于监督微调（SFT）与对齐训练，构建人类对齐的大语言模型必备。

| 数据集                      | 简介                                    | 特点                     |
|---------------------------|---------------------------------------|------------------------|
| **Alpaca**               | 从 Self-Instruct 蒸馏的 52K 条指令数据   | 简洁多样，适合微调       |
| **Self-Instruct**        | 使用 GPT-3 自动构造并解答的人类指令数据  | 泛化性强，任务广泛       |
| **OpenOrca**             | 高质量问答数据，模仿 OpenAI 的训练流程   | 拟合 Chat 系统风格       |
| **UltraChat**            | 多轮人类指令风格对话集，带有多样角色与任务 | 对话连续性佳、场景丰富   |
| **ShareGPT / GPTeacher** | 用户共享真实对话数据，对齐真实使用场景     | 实际对话，语料真实       |

---

### 编程与代码类数据

该类数据能够有效支持代码生成、理解、补全等编程相关任务，其中绝大部分数据来自 GitHub。

| 数据集                  | 简介                            | 特点                  |
|-----------------------|-------------------------------|---------------------|
| **The Stack**        | 大规模多语言代码语料（15+种编程语言）          | 可分语言/文件/函数粒度 |
| **CodeParrot**       | 从 GitHub 抓取的高质量 Python 代码    | 专注单一语言，结构良好        |
| **HumanEval**        | 包含测试用例的函数生成任务，用于评估代码模型的正确性    | 标准评测基准，结构规范         |
| **StarCoderData**    | BigCode 项目整理的训练集，包含许可证过滤与安全审查 | 质量高、兼容 StarCoder 系列 |
| **StackOverflow QA** | 技术问答平台语料，适合编程对话和代码解释等任务       | 问答结构清晰            |

---

### 多语言数据

该类数据是多语种或跨语言模型的基础语料，多语言成为主流大模型重点发展方向之一。

| 数据集                | 简介                                        | 特点             |
|-------------------|-------------------------------------------|----------------|
| **CC100**          | Common Crawl 派生出的 100 种语言网页语料             | 语言覆盖广，质量需筛选    |
| **WikiMatrix**     | 多语言维基百科句对，适合训练翻译与跨语句子对齐任务                 | 对齐语料，结构统一      |
| **Tatoeba**        | 覆盖千种语言的平行语料，适合跨语言嵌入训练                     | 丰富多语种，适合小语种任务  |
| **NLLB Dataset**   | Meta 构建的 No Language Left Behind 多语翻译训练语料 | 大量高质量句对，翻译模型常用 |
| **XGLUE / XTREME** | 多语言评测与微调数据集，适用于跨语 NLP 能力训练与测试             | 提供任务迁移的标准基准    |

---

### 多模态数据

该类数据同时包含文本、图像、视频等，适用于训练 VLM（视觉语言模型）或多模态大模型。

| 数据集                    | 简介                            | 特点                   |
|---------------------- |------------------------------|--------------------|
| **LAION-400M/5B**      | 开源的大规模图文对数据集，图像+文本描述          | 可用作 CLIP/BLIP 训练     |
| **CC3M / CC12M**       | Captioned Images 数据，图像与英文描述配对 | 噪声低，适合训练图像字幕模型       |
| **Visual Genome**      | 图像 + 区域 + 关系 + QA 任务数据集       | 结构复杂，可做多任务学习         |
| **COCO Captions**      | 图像 + 5 条描述句的集合，用于生成图像描述       | 图文精对齐，适合监督学习         |
| **VQAv2 / GQA**        | 图像问答数据集，支持模型对图像内容问答           | 多轮问答、细节推理能力评估        |
| **WebVid2M / HD-VILA** | 视频 + 时间同步字幕，训练视频理解或生成模型       | 用于 GPT-4V/VideoGPT 等 |

---

### 医学领域数据

该类数据包含医学，生物文献，医学考试题目，医药数据等。

| 数据集                    | 简介                                      | 特点                    |
|---------------------- |--------------------------------------- |--------------------- |
| **PubMed**             | 美国国家医学图书馆的生物医学文献数据库，包含超过3500万篇文章的元数据和摘要 | 涵盖广泛的医学领域，适合医学问答和摘要生成 |
| **PMC Open Access**    | PubMed Central 的开源全文医学论文数据集             | 高质量医学文本，适合文本生成与推理     |
| **MIMIC-III/IV**       | ICU 病人临床记录数据库（包括病史、化验、出院摘要等）            | 临床数据丰富，适合临床问答和信息提取    |
| **MedQA**              | 医学执照考试风格的问答数据集                          | 多项选择题，适合医学问答推理        |
| **MedMCQA**            | 20万题医学多选问答数据集                           | 高质量医学多选问答，适合推理与评估     |
| **HealthSearchQA**     | 从医疗搜索引擎提取的用户查询与回答数据集                    | 搜索式问答对齐，适合医疗搜索引擎问答    |
| 
