1
00:00:00,016 --> 00:00:03,183
2018年是整个AI欣欣向荣的一年

2
00:00:03,183 --> 00:00:07,183
但是呢因为2019年2022年之后的两年呢

3
00:00:07,250 --> 00:00:08,016
AI的落地呢

4
00:00:08,016 --> 00:00:10,400
没有人们想象中的那么的快

5
00:00:12,366 --> 00:00:12,850
哈喽大家好

6
00:00:12,850 --> 00:00:14,016
我们现在来到了

7
00:00:14,016 --> 00:00:16,933
2018年的一个AI大事件的回顾了

8
00:00:16,933 --> 00:00:17,733
2018年呢

9
00:00:17,733 --> 00:00:20,250
距离现在已经七八年的时间呢

10
00:00:20,333 --> 00:00:22,766
2018年这个时间点特别有意思的就是

11
00:00:22,766 --> 00:00:25,733
我们现在经常看到的大语言模型也好

12
00:00:26,166 --> 00:00:27,900
所有的大模型也好的突破啊

13
00:00:27,900 --> 00:00:31,216
主要是来自于NLP的首先的突破

14
00:00:31,366 --> 00:00:32,300
所以我们第一个内容呢

15
00:00:32,300 --> 00:00:32,933
去看一下

16
00:00:32,933 --> 00:00:35,816
自然语言处理NLP的一个具体的突破

17
00:00:35,816 --> 00:00:37,816
那在大语言模型里面呢

18
00:00:37,816 --> 00:00:39,366
2018年的时候呢

19
00:00:39,366 --> 00:00:40,933
谷歌就推出了Bert

20
00:00:41,333 --> 00:00:43,933
也就是双向的Transformers架构

21
00:00:43,933 --> 00:00:47,300
然后提出了预训练跟微调的两种模式

22
00:00:47,300 --> 00:00:49,216
通过这个Bert网络模型呢

23
00:00:49,250 --> 00:00:49,900
显著了

24
00:00:49,900 --> 00:00:53,016
提升了NLP语言的一个理解能力

25
00:00:53,216 --> 00:00:55,300
在11项NLP的任务当中呢

26
00:00:55,300 --> 00:00:56,966
刷新了整体的记录

27
00:00:56,966 --> 00:01:00,100
成为NLP领域的新的里程碑

28
00:01:00,100 --> 00:01:02,050
那这个时候我们可以看到啊

29
00:01:02,050 --> 00:01:03,616
Bert这个模型的出现呢

30
00:01:03,616 --> 00:01:05,733
就让我们的预训练模型

31
00:01:05,766 --> 00:01:07,050
产生了一个普及

32
00:01:07,050 --> 00:01:08,500
包括后来的Lemo

33
00:01:08,500 --> 00:01:11,016
还有ULMFiT预训练的模型呢

34
00:01:11,016 --> 00:01:12,166
就进一步推动了

35
00:01:12,166 --> 00:01:14,650
迁移学习在NLP领域的应用

36
00:01:14,650 --> 00:01:15,366
这个时候

37
00:01:15,366 --> 00:01:19,300
2018年标志着NLP的imageNet时代到来了

38
00:01:19,333 --> 00:01:20,216
整体来说

39
00:01:20,216 --> 00:01:21,100
Bert的发布呢

40
00:01:21,100 --> 00:01:23,616
不仅是NLP的发展史的里程碑

41
00:01:23,700 --> 00:01:25,966
更是2018年AI领域的

42
00:01:25,966 --> 00:01:27,450
非常重要的一个事件

43
00:01:27,700 --> 00:01:28,933
它彻底地改变了

44
00:01:28,933 --> 00:01:30,700
语言模型的设计的思路

45
00:01:30,700 --> 00:01:33,133
推动了NLP技术的快速的进步

46
00:01:33,133 --> 00:01:34,366
和实际的应用

47
00:01:34,416 --> 00:01:36,616
为后续的AI研究和商业化呀

48
00:01:36,616 --> 00:01:39,216
奠定了一个非常坚实的基础

49
00:01:39,933 --> 00:01:40,966
那整体来说

50
00:01:40,966 --> 00:01:42,533
我们除了NLP领域呢

51
00:01:42,533 --> 00:01:44,333
还会有其他的算法

52
00:01:44,333 --> 00:01:46,100
产生一个比较大的一个进步

53
00:01:46,100 --> 00:01:47,050
那另外一个就是

54
00:01:47,050 --> 00:01:49,016
BigGAN的一个经验的表现

55
00:01:49,250 --> 00:01:51,050
DeepMind啊谷歌

56
00:01:51,050 --> 00:01:53,450
就发布了BigGAN这个网络模型

57
00:01:53,450 --> 00:01:55,333
在图像生成的领域啊

58
00:01:55,333 --> 00:01:56,733
表现非常的出色

59
00:01:56,816 --> 00:01:58,700
生成图像的逼真度呢

60
00:01:58,700 --> 00:02:01,133
远超于以往的模型展示呢

61
00:02:01,133 --> 00:02:04,933
生成是对抗网络GAN的一个具体的潜力

62
00:02:05,133 --> 00:02:07,500
另外它还有强化学习的突破

63
00:02:07,700 --> 00:02:08,566
OpenAI呢

64
00:02:08,566 --> 00:02:11,933
就发布了强化学习的入门的教程

65
00:02:12,016 --> 00:02:13,566
snipping up并且呢

66
00:02:13,566 --> 00:02:15,450
推出了多巴胺的框架

67
00:02:15,450 --> 00:02:17,900
简化了整个强化学习的研究

68
00:02:17,900 --> 00:02:19,216
和具体的应用

69
00:02:19,416 --> 00:02:20,166
提到2018年

70
00:02:20,166 --> 00:02:22,450
我们不得不提的就是另外一个事情

71
00:02:22,450 --> 00:02:24,650
就是AI框架的整体的发展

72
00:02:24,733 --> 00:02:27,500
那2018年有个很重要的事件的标志呢

73
00:02:27,500 --> 00:02:29,700
就是PyTorch1.0的发布

74
00:02:29,966 --> 00:02:32,616
2018年呢Facebook当时还没有改名哦

75
00:02:32,616 --> 00:02:33,616
它的一个PyTorch

76
00:02:33,616 --> 00:02:35,816
跟Caffe2进行了一个整合

77
00:02:35,816 --> 00:02:37,850
推出了PyTorch 1.0

78
00:02:37,966 --> 00:02:39,333
那PyTorch一个框架呢

79
00:02:39,333 --> 00:02:41,366
它的灵活性和动态图图

80
00:02:41,366 --> 00:02:43,216
也就是动态计算图的机制呢

81
00:02:43,216 --> 00:02:45,016
使得在AI的研究领域了

82
00:02:45,016 --> 00:02:47,133
就迅速的普及起来了

83
00:02:47,133 --> 00:02:47,733
进一步呢

84
00:02:47,733 --> 00:02:50,766
巩固了PyTorch在深度学习框架一个地位

85
00:02:50,766 --> 00:02:51,650
那我们现在啊

86
00:02:51,650 --> 00:02:53,333
基本上叫深度学习框架

87
00:02:53,333 --> 00:02:55,816
和AI框架都混为一体了

88
00:02:55,816 --> 00:02:59,133
尤其是在研究领域和开发者社区呢

89
00:02:59,133 --> 00:03:02,216
成为整个AI领域非常重要的一个框架

90
00:03:02,450 --> 00:03:04,416
我们现在所有的AI的算法啊

91
00:03:04,416 --> 00:03:05,966
你们用到的大模型啊

92
00:03:06,050 --> 00:03:06,766
基本上呢

93
00:03:06,766 --> 00:03:09,333
都构建在PyTorch这个框架之上

94
00:03:09,416 --> 00:03:11,966
有点类似于我们现在所有的应用啊

95
00:03:11,966 --> 00:03:13,100
都在Linux

96
00:03:13,100 --> 00:03:16,300
或者在Windows这个操作系统之上一样

97
00:03:16,300 --> 00:03:17,300
它的重要地位啊

98
00:03:17,300 --> 00:03:18,300
不言而喻

99
00:03:18,616 --> 00:03:19,300
那另外的话

100
00:03:19,300 --> 00:03:22,416
当时还有另外一个谷歌推出的AI框

101
00:03:22,416 --> 00:03:23,933
架叫做TensorFlow

102
00:03:24,050 --> 00:03:25,616
TensorFlow呢在2018年呢

103
00:03:25,616 --> 00:03:28,250
也发布了很多个重要的版本

104
00:03:28,250 --> 00:03:31,850
有1.X/1.XX各种各样的版本里面呢

105
00:03:31,850 --> 00:03:32,616
就增强了

106
00:03:32,616 --> 00:03:35,500
及时执行和发行策略等功能啊

107
00:03:35,500 --> 00:03:37,766
并且推出了TensorFlow.js

108
00:03:37,766 --> 00:03:40,250
TensorFlow Lite等相关的工具

109
00:03:40,250 --> 00:03:43,016
进一步呢扩展TensorFlow的一个应用场景

110
00:03:43,016 --> 00:03:47,300
同期2018年呢微软去主导的一个ONNX

111
00:03:47,300 --> 00:03:50,133
也叫做open nature number is change

112
00:03:50,133 --> 00:03:53,250
我们的一个中间转换表达格式呢

113
00:03:53,250 --> 00:03:55,966
一个整体的标准呢逐渐走向成熟

114
00:03:55,966 --> 00:03:57,966
促使了不同框架之间的模型呢

115
00:03:57,966 --> 00:04:00,450
能够互相操作和互相转换

116
00:04:00,700 --> 00:04:03,100
那说白了ONNX的作用呢就是云端训练

117
00:04:03,100 --> 00:04:04,733
我们大部分都用PyTorch

118
00:04:04,733 --> 00:04:05,900
但是呢推理的时候呢

119
00:04:05,900 --> 00:04:08,133
我们可能会用各种各样的推理框架

120
00:04:08,133 --> 00:04:09,050
推理引擎

121
00:04:09,100 --> 00:04:10,016
通过ONNX呢

122
00:04:10,016 --> 00:04:12,766
大家都可以转成ONNX这种标准格式

123
00:04:12,766 --> 00:04:14,450
云端跟推理端呢

124
00:04:14,450 --> 00:04:17,250
就通过ONNX这个格式呢进行一个打通

125
00:04:17,766 --> 00:04:20,850
第三个聊到AI算法和AI框架

126
00:04:20,850 --> 00:04:23,366
肯定离不开我们底下执行的AI芯片

127
00:04:23,366 --> 00:04:25,166
跟硬件的发展

128
00:04:25,216 --> 00:04:28,016
2018年呢我们重点最重要的一个事情呢

129
00:04:28,016 --> 00:04:30,216
就是谷歌TPU的广泛的应用哦

130
00:04:30,500 --> 00:04:32,133
谷歌的TPU啊为什么叫TPU呢

131
00:04:32,133 --> 00:04:32,966
叫做T呢

132
00:04:32,966 --> 00:04:35,566
就是张亮Tensor possess unit

133
00:04:35,566 --> 00:04:38,016
在2018年的时候呢就进一步普及

134
00:04:38,100 --> 00:04:40,250
支持大规模的训练和推理

135
00:04:40,566 --> 00:04:42,850
特别是推动了Bert等相关的模型呢

136
00:04:42,850 --> 00:04:44,133
进行一个突破

137
00:04:44,133 --> 00:04:46,566
那谷歌同时啊在2018年的时候呢

138
00:04:46,566 --> 00:04:48,333
还推出了Cloud TPU Pod

139
00:04:48,566 --> 00:04:51,250
就是我们的TPU的集群

140
00:04:51,250 --> 00:04:52,250
云端集群

141
00:04:52,333 --> 00:04:54,333
使大规模的机器学习的训练呢

142
00:04:54,333 --> 00:04:55,416
就更加便捷

143
00:04:55,416 --> 00:04:57,650
我们现在经常看到的AI集群呢

144
00:04:57,650 --> 00:04:58,566
AI训练呢

145
00:04:58,616 --> 00:05:00,733
都要用一个超大规模的节点

146
00:05:00,733 --> 00:05:01,766
或者超节点呢

147
00:05:01,766 --> 00:05:03,816
是因为谷歌开的这个先河

148
00:05:03,850 --> 00:05:04,900
那当时候啊

149
00:05:04,900 --> 00:05:07,333
TPU V3在2018年5月份呢

150
00:05:07,333 --> 00:05:10,333
在谷歌的IO开发者大会上面去发布的

151
00:05:10,366 --> 00:05:12,850
性能呢对比起上一代TPU V2呢

152
00:05:12,850 --> 00:05:13,933
提升了8倍

153
00:05:14,016 --> 00:05:16,300
每个TPU V3的Pod的计算能力啊

154
00:05:16,300 --> 00:05:20,100
达到每秒100千万亿次的浮点运算

155
00:05:20,100 --> 00:05:21,133
非常的夸张

156
00:05:21,416 --> 00:05:22,733
那TPUV3的POD呢

157
00:05:22,733 --> 00:05:24,100
主要是由1024个

158
00:05:24,100 --> 00:05:27,166
也就是1,000个TPUV3的芯片组成的

159
00:05:27,216 --> 00:05:28,766
计算能力非常夸张

160
00:05:29,016 --> 00:05:30,766
同年哦在2018年呢

161
00:05:30,766 --> 00:05:32,900
谷歌还发布了Edge TPU

162
00:05:32,900 --> 00:05:35,500
专门为IoT设备和边缘计算呢

163
00:05:35,500 --> 00:05:38,133
来进行设计

164
00:05:38,133 --> 00:05:40,966
能够以每秒啊30帧以上的速度呢

165
00:05:40,966 --> 00:05:42,850
去处理高分辨率的视频 

166
00:05:42,900 --> 00:05:46,616
并且呢运行多个先进的CV的模型哦

167
00:05:46,650 --> 00:05:48,016
那后面的我们可以看到

168
00:05:48,016 --> 00:05:51,450
2019年 包括2020年的寒武纪也好

169
00:05:51,533 --> 00:05:53,933
华为970等相关端测的芯片呢

170
00:05:53,933 --> 00:05:55,766
开始植入AI的功能呢

171
00:05:55,933 --> 00:05:58,300
都是参考着2018年

172
00:05:58,300 --> 00:06:00,333
谷歌的这个套路而来的

173
00:06:00,416 --> 00:06:01,016
那同期

174
00:06:01,016 --> 00:06:03,533
我们还要看一下宇宙最强的英伟达

175
00:06:03,733 --> 00:06:05,450
英伟达在2018年3月份呢

176
00:06:05,450 --> 00:06:07,016
就发布了DGX 2

177
00:06:07,300 --> 00:06:08,300
是全球首款

178
00:06:08,300 --> 00:06:11,650
性能能够达到2,000万亿次浮点运算的

179
00:06:11,700 --> 00:06:13,733
AI超级计算机

180
00:06:13,733 --> 00:06:14,450
那这个时候呢

181
00:06:14,450 --> 00:06:16,966
他就提出了一个新的AI节点了

182
00:06:16,966 --> 00:06:18,566
以前英伟达是卖卡的

183
00:06:18,566 --> 00:06:20,100
现在卖一个节点呢

184
00:06:20,133 --> 00:06:22,533
整体的AI的产品的形态呢

185
00:06:22,533 --> 00:06:24,816
也就是从2018年开始改变的

186
00:06:25,100 --> 00:06:26,733
这款DGX 2呢

187
00:06:26,733 --> 00:06:29,416
由16块Tesla V100 GPU组成的

188
00:06:29,416 --> 00:06:30,366
支持大规模的

189
00:06:30,366 --> 00:06:32,616
深度学习的训练和推理的任务

190
00:06:32,733 --> 00:06:33,416
同时呢

191
00:06:33,416 --> 00:06:36,850
英伟达也推出了内存翻配的Tesla V100 32G

192
00:06:36,850 --> 00:06:37,616
的GPU

193
00:06:37,616 --> 00:06:40,616
进一步的提升了AI训练和推理的性能

194
00:06:40,900 --> 00:06:44,333
另外呢林伟达还发布了Jason AGX啊

195
00:06:44,333 --> 00:06:44,966
那这一款呢

196
00:06:44,966 --> 00:06:47,050
是面向AI的一个机器人

197
00:06:47,050 --> 00:06:48,850
边缘计算的模型

198
00:06:48,850 --> 00:06:50,016
或者叫做模块

199
00:06:50,050 --> 00:06:52,900
比较具备一个高性能和低功耗的特点

200
00:06:52,900 --> 00:06:55,300
反正呢就跟我们的银行卡差不多大小

201
00:06:55,300 --> 00:06:58,250
变成一个谁非常小的一个模组和版卡

202
00:06:58,766 --> 00:07:00,900
那2018年其实在AI芯片里面呢

203
00:07:00,900 --> 00:07:02,816
也发生了很多的大事件呢

204
00:07:02,816 --> 00:07:04,016
我们来数一数啊

205
00:07:04,016 --> 00:07:05,533
其他的华为昇腾

206
00:07:05,533 --> 00:07:06,650
2018年的时候呢

207
00:07:06,650 --> 00:07:09,100
就华为发布基于昇腾系列的芯片

208
00:07:09,100 --> 00:07:11,500
还有Altas智能计算平台

209
00:07:11,566 --> 00:07:12,533
最重要的目的呢

210
00:07:12,533 --> 00:07:13,900
就是打造面向端

211
00:07:13,933 --> 00:07:16,966
边缘全场景的AI的基础设施

212
00:07:16,966 --> 00:07:18,333
现在啊华为基本上啊

213
00:07:18,333 --> 00:07:19,700
你提到它的slogan

214
00:07:19,700 --> 00:07:22,050
都是跟智能强相关的了

215
00:07:22,100 --> 00:07:23,616
在2018年的时候呢

216
00:07:23,616 --> 00:07:25,050
AI的芯片创热热潮啊

217
00:07:25,050 --> 00:07:26,050
非常的火啊

218
00:07:26,100 --> 00:07:28,100
整体AI的芯片的创业公司啊

219
00:07:28,300 --> 00:07:30,533
吸引了超过15亿美金的投资

220
00:07:30,533 --> 00:07:32,366
很多的创业公司呢

221
00:07:32,366 --> 00:07:34,166
专门去开发为AI啊

222
00:07:34,166 --> 00:07:37,450
为深度学习神经网络去优化的硬件

223
00:07:37,450 --> 00:07:39,616
例如神经形态的一些芯片

224
00:07:39,616 --> 00:07:41,416
还有边缘的计算的设备

225
00:07:41,450 --> 00:07:45,016
那同期奥含武器也推出了campers MLU 100

226
00:07:45,166 --> 00:07:48,333
首款面向云端的智能推理AI芯片

227
00:07:48,333 --> 00:07:50,500
那中国的AI初创芯片呢

228
00:07:50,500 --> 00:07:51,500
深监科技呢

229
00:07:51,500 --> 00:07:52,700
也在2018年呢

230
00:07:52,700 --> 00:07:56,966
被美国FPGA塞灵斯进行了收购

231
00:07:56,966 --> 00:07:58,816
后来呢美国FPGA巨头呢

232
00:07:58,816 --> 00:08:00,850
也被AMD来收购啊

233
00:08:00,850 --> 00:08:01,366
所以啊

234
00:08:01,366 --> 00:08:04,050
可以看到这几年的AI的芯片的发展呢

235
00:08:04,100 --> 00:08:05,616
非常的迅猛

236
00:08:05,933 --> 00:08:08,900
我们现在来到2018年的第四个内容了

237
00:08:08,900 --> 00:08:11,333
产品跟相关的解决方案了

238
00:08:11,366 --> 00:08:12,966
那在2018年的时候呢

239
00:08:12,966 --> 00:08:14,533
蛮有意思的就是大家觉得哎呀

240
00:08:14,533 --> 00:08:15,533
AI要落地了

241
00:08:15,533 --> 00:08:17,050
AI真的要落地了

242
00:08:17,216 --> 00:08:19,650
顺呢就推出了很多相关的解决方案

243
00:08:19,700 --> 00:08:21,700
那首先第一个呢就是当时候啊

244
00:08:21,700 --> 00:08:24,816
ZOMI觉得吹的全国都是那个风啊

245
00:08:24,816 --> 00:08:26,133
真的非常的大

246
00:08:26,366 --> 00:08:27,900
是智慧城市

247
00:08:27,900 --> 00:08:28,733
那这里面呢

248
00:08:28,733 --> 00:08:29,733
最重要的就华为呢

249
00:08:29,733 --> 00:08:32,416
就发布了面向智慧城市的数字平台

250
00:08:32,500 --> 00:08:33,766
整合了物联网

251
00:08:33,766 --> 00:08:34,733
大数据视频

252
00:08:34,733 --> 00:08:36,366
云等相关的资源

253
00:08:36,450 --> 00:08:39,533
希望去推动智慧城市的整体的建设

254
00:08:39,566 --> 00:08:40,300
另外的话

255
00:08:40,300 --> 00:08:40,850
地平线呢

256
00:08:40,850 --> 00:08:42,850
也发布了基于AI芯片的

257
00:08:42,850 --> 00:08:44,733
未来城市的解决方案

258
00:08:44,733 --> 00:08:46,733
覆盖多个城市的场景

259
00:08:47,050 --> 00:08:48,250
在智慧医疗里面呢

260
00:08:48,250 --> 00:08:49,100
我们可以看到啊

261
00:08:49,100 --> 00:08:50,366
在2018年的时候

262
00:08:50,366 --> 00:08:52,500
智慧医疗也进一步的去崛起了

263
00:08:52,500 --> 00:08:53,450
例如飞利浦呢

264
00:08:53,450 --> 00:08:55,616
就利用了智能互联网的睡眠

265
00:08:55,616 --> 00:08:57,250
呼吸管理解决方案呢

266
00:08:57,250 --> 00:08:58,500
叫做dream family

267
00:08:58,500 --> 00:09:00,250
可以通过可穿戴的适配

268
00:09:00,250 --> 00:09:02,566
和数字化的联网的技术呢

269
00:09:02,566 --> 00:09:06,416
实现对于老人的年轻人的健康的管理

270
00:09:06,850 --> 00:09:08,650
AI在传统行业里面呢

271
00:09:08,650 --> 00:09:10,166
也是慢慢的渗透的

272
00:09:10,166 --> 00:09:13,016
那开始呢就渗透到更多的传统行业了

273
00:09:13,016 --> 00:09:15,333
例如腾讯呢就跟罗氏制药合作

274
00:09:15,333 --> 00:09:18,333
探索AI在医疗场景的一个具体的应用

275
00:09:18,616 --> 00:09:19,216
另外的话

276
00:09:19,216 --> 00:09:20,050
英特尔呢

277
00:09:20,050 --> 00:09:21,450
跟腾讯优图实验室呢

278
00:09:21,450 --> 00:09:24,566
就合作开发AI的摄像机跟AI的盒子

279
00:09:24,566 --> 00:09:25,933
用于安防领域的

280
00:09:25,933 --> 00:09:26,733
我相信呢

281
00:09:26,733 --> 00:09:27,733
现在很多人呢

282
00:09:27,733 --> 00:09:28,766
也会曾经啊

283
00:09:28,766 --> 00:09:32,216
用过相关的什么天猫精灵这种AI盒子

284
00:09:32,216 --> 00:09:33,933
不过呢现在呢并不多

285
00:09:33,933 --> 00:09:35,650
反而变成我们手机啊

286
00:09:35,650 --> 00:09:38,050
我们的耳机啊都有了AI的功能

287
00:09:38,300 --> 00:09:38,900
那同期呢

288
00:09:38,900 --> 00:09:41,816
在2018年的谷歌IO开发者大会上面呢

289
00:09:41,816 --> 00:09:43,416
谷歌就展示了Duplex

290
00:09:43,416 --> 00:09:45,300
一个能够根据NLP

291
00:09:45,300 --> 00:09:47,333
我们自然语言对话的AI系统

292
00:09:47,333 --> 00:09:49,366
可以代替用户进行打电话啦

293
00:09:49,850 --> 00:09:51,300
约我们的餐馆呢

294
00:09:51,300 --> 00:09:52,816
还有我们的理发店呢

295
00:09:52,816 --> 00:09:55,700
那证明的整个Duplex的流畅程度

296
00:09:55,700 --> 00:09:56,733
和对话能力

297
00:09:56,733 --> 00:09:58,816
跟自然的语音合成技术呢

298
00:09:58,816 --> 00:10:01,366
当时会引起了非常大的轰动的

299
00:10:01,366 --> 00:10:01,966
Duplex呢

300
00:10:01,966 --> 00:10:04,933
展示了NLP的技术的实际的应用场景

301
00:10:05,166 --> 00:10:05,816
但是呢同时

302
00:10:05,816 --> 00:10:08,733
也会引发一些AI伦理和透明性的讨论

303
00:10:08,733 --> 00:10:10,416
那现在有了大模型之后啊

304
00:10:10,416 --> 00:10:12,100
我们谷歌的Dupix啊

305
00:10:12,216 --> 00:10:14,166
这种太前沿的研究啊

306
00:10:14,166 --> 00:10:15,450
真正的才落地啊

307
00:10:15,900 --> 00:10:16,366
那最后呢

308
00:10:16,366 --> 00:10:19,733
还有自动化技术相关的商业化的发展

309
00:10:19,766 --> 00:10:20,700
就是Waymo呢

310
00:10:20,700 --> 00:10:21,933
在2018年的时候呢

311
00:10:21,933 --> 00:10:24,416
就推出了商业化的自动驾驶服务

312
00:10:24,816 --> 00:10:27,216
这个服务呢就标志着自动驾驶技术呢

313
00:10:27,216 --> 00:10:30,650
从测试阶段真正的迈向实际的应用了

314
00:10:30,650 --> 00:10:31,216
另外的话

315
00:10:31,216 --> 00:10:32,566
百度的Apollo啊

316
00:10:32,566 --> 00:10:33,500
无人驾驶呢

317
00:10:33,500 --> 00:10:35,966
在央视晚上去亮相

318
00:10:36,016 --> 00:10:38,966
展示了中国呢在自动驾驶领域的进展

319
00:10:39,166 --> 00:10:41,300
自动驾驶的技术的商业化落地呢

320
00:10:41,300 --> 00:10:44,216
就为未来的交通革命呢奠定了基础

321
00:10:44,216 --> 00:10:47,500
就像我们今年看春晚有很多机器人

322
00:10:47,566 --> 00:10:49,966
2018年的春晚呢也有自动驾驶

323
00:10:49,966 --> 00:10:52,566
我们现在呢自动驾驶还没普及

324
00:10:52,566 --> 00:10:54,500
所以我觉得我们的机器人呢

325
00:10:54,533 --> 00:10:56,966
可能也需要很长的一段时间

326
00:10:57,366 --> 00:10:57,566
最后

327
00:10:57,566 --> 00:11:00,966
我们对2018年做一个简单的总结和思考

328
00:11:01,166 --> 00:11:02,733
2018年呢AI的技术

329
00:11:02,733 --> 00:11:04,250
无论在开源框架

330
00:11:04,366 --> 00:11:05,333
硬件芯片

331
00:11:05,333 --> 00:11:07,733
算法研究和产品应用等方面呢

332
00:11:07,733 --> 00:11:09,900
都取得非常显著的进展的

333
00:11:09,966 --> 00:11:11,250
从Bert的突破

334
00:11:11,333 --> 00:11:14,616
到谷歌Dupix的一个应用的亮相落地

335
00:11:14,616 --> 00:11:16,416
再到TPU跟

336
00:11:16,933 --> 00:11:19,100
整的一个具体的硬件的创新呢

337
00:11:19,100 --> 00:11:20,016
那这些事件呢

338
00:11:20,016 --> 00:11:21,416
都共同推动着整个

339
00:11:21,416 --> 00:11:24,650
AI的技术的快速的发展和实际的落地

340
00:11:24,650 --> 00:11:25,766
2018年呢

341
00:11:25,766 --> 00:11:28,333
是英伟达技术全面爆发的一年

342
00:11:28,500 --> 00:11:31,733
从显卡产品线到更新到AI自动驾驶

343
00:11:31,733 --> 00:11:33,300
数据中心领域的突破

344
00:11:33,566 --> 00:11:34,166
英伟达呢

345
00:11:34,166 --> 00:11:36,100
也展示了在图形计算

346
00:11:36,100 --> 00:11:38,450
和AI领域的领先的地位

347
00:11:38,450 --> 00:11:39,333
那这些发布了

348
00:11:39,333 --> 00:11:42,300
不仅仅推动了游戏和内容创作的进步

349
00:11:42,333 --> 00:11:45,166
也为未来的AI的芯片和AI的产品

350
00:11:45,166 --> 00:11:48,500
和AI的集群的发展奠定了基础

351
00:11:48,500 --> 00:11:51,650
2018年是整个AI欣欣向荣的一年

352
00:11:51,650 --> 00:11:55,650
但是呢因为2019年2022年之后的两年呢

353
00:11:55,700 --> 00:11:56,533
AI的落地呢

354
00:11:56,533 --> 00:11:58,900
没有人们想象中的那么的快

355
00:11:59,100 --> 00:12:00,450
所以说AI 18年呢

356
00:12:00,450 --> 00:12:02,816
应该是当年很多现在的学生

357
00:12:02,816 --> 00:12:04,416
上学非常觉得哎

358
00:12:04,416 --> 00:12:05,966
AI很有前景的一年

359
00:12:05,966 --> 00:12:07,733
但是呢到他们的大二大三

360
00:12:07,733 --> 00:12:09,366
你会发现AI掉下去了

361
00:12:09,366 --> 00:12:11,333
直到现在大模型起来了

362
00:12:11,333 --> 00:12:12,300
大家又觉得哎呦

363
00:12:12,300 --> 00:12:13,933
AI真正能落地了

364
00:12:13,933 --> 00:12:16,366
我们今天的内容呢就回顾到这里

365
00:12:16,366 --> 00:12:17,050
谢谢各位

366
00:12:17,050 --> 00:12:17,933
拜了个拜

