1
00:00:00,000 --> 00:00:00,633
2017 年

2
00:00:00,633 --> 00:00:02,916
是 AI 技术从实验室走向商业化

3
00:00:02,916 --> 00:00:04,116
最重要的一年

4
00:00:04,166 --> 00:00:07,166
AlphaGO 的胜利跟国家战略的一个出台

5
00:00:07,166 --> 00:00:09,433
巨头的布局以及 AI 产品的普及

6
00:00:09,433 --> 00:00:11,966
共同推动 AI 技术的快速的发展

7
00:00:11,966 --> 00:00:13,316
内容/录制:Z0MI 酱，视频剪辑/字幕:梁嘉铭

8
00:00:13,316 --> 00:00:14,366
哈喽大家好

9
00:00:14,366 --> 00:00:15,283
我是 ZOMI

10
00:00:15,283 --> 00:00:16,450
我们现在来回顾一下

11
00:00:16,450 --> 00:00:18,250
2017 年的 AI 的大事件

12
00:00:18,250 --> 00:00:20,000
我们从 2024 年

13
00:00:20,000 --> 00:00:22,366
然后一直往前倒推过去十年

14
00:00:22,366 --> 00:00:24,083
整个 AI 的一个具体的发展

15
00:00:24,083 --> 00:00:25,250
我们还是来到第一个

16
00:00:25,250 --> 00:00:27,600
内容模型的算法的发展

17
00:00:27,683 --> 00:00:29,716
首先 2017 年很重要的一个事情

18
00:00:29,716 --> 00:00:33,250
就是 AlphaGO 再胜人类的棋手

19
00:00:33,516 --> 00:00:34,566
2017 年的 5 月份

20
00:00:34,566 --> 00:00:35,716
AlphaGO 的 master

21
00:00:35,716 --> 00:00:36,683
以 3:0 啊

22
00:00:36,716 --> 00:00:39,850
战胜世界排名第一的围棋选手柯洁啊

23
00:00:39,883 --> 00:00:41,516
那到 2017 年 10 月份

24
00:00:41,516 --> 00:00:43,083
deepMind 在 nature 上面

25
00:00:43,083 --> 00:00:44,000
就发表

26
00:00:44,000 --> 00:00:46,083
关于 AlphaGO Zero 的

27
00:00:46,083 --> 00:00:47,683
一个对应的研究成果

28
00:00:47,683 --> 00:00:49,050
和相关的技术

29
00:00:49,166 --> 00:00:50,000
AlphaGO  Zero

30
00:00:50,000 --> 00:00:53,116
以 100:0 的成绩啊击败 AlphaGO master

31
00:00:53,200 --> 00:00:55,200
展示 AI 通过自我学习

32
00:00:55,200 --> 00:00:57,116
实现超越的能力

33
00:00:57,366 --> 00:00:59,850
不需要任何人类的棋谱的数据

34
00:00:59,850 --> 00:01:01,283
从 0 开始学围棋

35
00:01:01,316 --> 00:01:03,083
并且在很短的时间内

36
00:01:03,083 --> 00:01:05,200
就超越所有的人类棋手

37
00:01:05,200 --> 00:01:07,400
和之前的 AlphaGO 的版本

38
00:01:07,450 --> 00:01:08,850
那这一个事件

39
00:01:08,850 --> 00:01:10,650
就标志着 AlphaGO 的胜利

40
00:01:10,766 --> 00:01:12,250
进一步展示 RL 啊

41
00:01:12,250 --> 00:01:14,083
强化学习的强大的潜力

42
00:01:14,083 --> 00:01:15,883
并且推动 AI

43
00:01:15,916 --> 00:01:16,683
在人工智能

44
00:01:16,683 --> 00:01:19,566
在复杂决策任务当中具体的应用

45
00:01:20,000 --> 00:01:20,683
那另外的话

46
00:01:20,683 --> 00:01:22,800
在 2017 年有很多新的算法

47
00:01:22,800 --> 00:01:23,200
第一个

48
00:01:23,200 --> 00:01:25,083
就是 capture 的一个网络的提出

49
00:01:25,083 --> 00:01:26,883
也就是胶囊网络

50
00:01:27,000 --> 00:01:28,516
在 2017 年的时候

51
00:01:28,516 --> 00:01:30,083
hitton 我们深度学习

52
00:01:30,083 --> 00:01:33,200
之父哦等人就提出胶囊网络

53
00:01:33,200 --> 00:01:34,316
captures 的网络

54
00:01:34,316 --> 00:01:37,116
在 2017 年引发整个广泛的关注的

55
00:01:37,116 --> 00:01:38,316
那这个胶囊网络

56
00:01:38,316 --> 00:01:40,566
主要是解决 CNN 卷积

57
00:01:40,566 --> 00:01:41,050
神经网络

58
00:01:41,050 --> 00:01:43,116
对图像当中的一些对象的知识

59
00:01:43,116 --> 00:01:44,250
和空间的关系

60
00:01:44,316 --> 00:01:46,083
处理能力不足的问题

61
00:01:46,116 --> 00:01:47,250
整个胶囊网络

62
00:01:47,250 --> 00:01:50,250
通过动态路由机制能够更好地理解图

63
00:01:50,250 --> 00:01:52,883
像当中的层次结构和对象关系

64
00:01:52,883 --> 00:01:55,050
为 CV 我们的视觉领域

65
00:01:55,050 --> 00:01:56,566
带来新的研究的方向

66
00:01:56,800 --> 00:01:57,516
那 2017

67
00:01:57,516 --> 00:01:59,166
其实也有一个很重要的技术

68
00:01:59,166 --> 00:02:00,050
就是 GAN 的

69
00:02:00,050 --> 00:02:01,800
一个技术的继续的发展

70
00:02:01,800 --> 00:02:04,400
出现多种多样的变体啊

71
00:02:04,400 --> 00:02:05,683
例如 wGAN

72
00:02:05,883 --> 00:02:07,800
wGAN 主要是解决 GAN 网络

73
00:02:07,800 --> 00:02:10,166
训练不稳定和生成的热门

74
00:02:10,166 --> 00:02:11,600
多样性不足的问题

75
00:02:11,600 --> 00:02:12,883
推动图像生成的

76
00:02:12,883 --> 00:02:15,683
一个数据增强的具体的技术

77
00:02:15,766 --> 00:02:16,766
那 2017 年的

78
00:02:16,766 --> 00:02:17,800
其实最核心

79
00:02:17,800 --> 00:02:18,650
最核心的

80
00:02:18,650 --> 00:02:21,483
主要还是 Transformer 的架构的提出

81
00:02:21,800 --> 00:02:22,450
那谷歌

82
00:02:22,450 --> 00:02:23,450
在 2017 年

83
00:02:23,450 --> 00:02:26,200
发表一篇文章叫做 attention is all your need

84
00:02:26,250 --> 00:02:28,850
首次就提出整个 Transformer 的架构

85
00:02:28,850 --> 00:02:30,566
那这个 Transformer 的架构

86
00:02:30,566 --> 00:02:34,000
就是现在所有大模型的最原始的雏形

87
00:02:34,050 --> 00:02:36,000
它主要的核心的机制

88
00:02:36,000 --> 00:02:38,483
是提供一个自注意力的机制

89
00:02:38,483 --> 00:02:41,366
也就是 self attention 的 mechanism

90
00:02:41,516 --> 00:02:42,683
整个筛选的基础

91
00:02:42,683 --> 00:02:44,116
使得我们整个模型啊

92
00:02:44,116 --> 00:02:45,366
能够同时考虑

93
00:02:45,450 --> 00:02:47,516
输入序列当中的所有的位置

94
00:02:47,516 --> 00:02:50,166
而不像传统的循环神经网络 RNN

95
00:02:50,166 --> 00:02:51,916
或者卷积神经网络 CNN

96
00:02:51,916 --> 00:02:53,766
那种逐步的去处理

97
00:02:53,966 --> 00:02:55,716
整个 Transformer 的架构的提出

98
00:02:55,716 --> 00:02:56,316
就标志着

99
00:02:56,316 --> 00:02:59,316
自然语言处理 NLP 的一个重大的突破

100
00:02:59,316 --> 00:03:00,400
后面的 Bert

101
00:03:00,400 --> 00:03:01,850
2018 年很重要的 Bert

102
00:03:01,850 --> 00:03:03,450
也是基于 Transformer 架构的

103
00:03:03,450 --> 00:03:06,283
还有 GPT123 也是基于 Transformer 架构的

104
00:03:06,316 --> 00:03:07,683
整个 Transformer 架构

105
00:03:07,683 --> 00:03:09,966
不仅提高模型的训练的效率

106
00:03:09,966 --> 00:03:11,250
还显著的提升

107
00:03:11,250 --> 00:03:13,966
模型在处理长距离依赖关系的时候

108
00:03:13,966 --> 00:03:15,800
的一个具体能力

109
00:03:16,200 --> 00:03:20,483
来看看语音模型和相关的助手哦

110
00:03:20,566 --> 00:03:21,516
在 2017 年

111
00:03:21,516 --> 00:03:23,166
AI 在语音合成的领域

112
00:03:23,166 --> 00:03:24,450
取得非常显著的进

113
00:03:24,450 --> 00:03:26,166
展谷歌的 Wavenet

114
00:03:26,166 --> 00:03:27,483
还有 Tacotra

115
00:03:27,483 --> 00:03:29,366
还有百度的 Dboys 等系列

116
00:03:29,366 --> 00:03:30,766
以及 apple 啊

117
00:03:30,766 --> 00:03:33,683
苹果发布的一个 TTS 的技术

118
00:03:33,716 --> 00:03:36,916
显著的提升语音合成和自然度

119
00:03:36,916 --> 00:03:37,850
和流畅度啊

120
00:03:37,883 --> 00:03:39,200
这些技术的应用

121
00:03:39,200 --> 00:03:40,683
推动智能语音助手

122
00:03:40,683 --> 00:03:43,083
和语音交互设备的整体的发展

123
00:03:43,083 --> 00:03:43,916
那另外的话

124
00:03:43,916 --> 00:03:46,083
在智能音箱的市场

125
00:03:46,083 --> 00:03:48,683
2017 年出现一个百箱大战

126
00:03:48,716 --> 00:03:50,316
阿里推出天猫精灵

127
00:03:50,316 --> 00:03:53,000
百度推出一个杜鸦

128
00:03:53,200 --> 00:03:55,400
小米推出小米 AI 音箱

129
00:03:55,450 --> 00:03:56,683
智能音箱的市场

130
00:03:56,683 --> 00:03:59,116
进入一个激烈的竞争的阶段

131
00:03:59,166 --> 00:04:00,766
不知道在座有没有买到

132
00:04:00,766 --> 00:04:02,400
好几年前的智能音箱

133
00:04:02,400 --> 00:04:05,083
一直放在床头当做普通的音箱

134
00:04:05,083 --> 00:04:07,683
为播音乐来使用的智能音箱

135
00:04:07,683 --> 00:04:09,716
被视为啊在 2017 年的时候

136
00:04:09,716 --> 00:04:11,683
整个智能家居的入口

137
00:04:11,683 --> 00:04:12,516
那其普及

138
00:04:12,516 --> 00:04:14,316
推动整个语音识别技术

139
00:04:14,316 --> 00:04:17,433
和自然语言处理的相关技术的发展

140
00:04:17,650 --> 00:04:18,050
第三个

141
00:04:18,050 --> 00:04:20,450
就是 AI 开源框架

142
00:04:20,450 --> 00:04:21,716
2017 年年初的时候

143
00:04:21,716 --> 00:04:23,450
Facebook 啊就发布 PyTorch

144
00:04:23,650 --> 00:04:26,000
一个基于 Python 的 AI 框架

145
00:04:26,000 --> 00:04:29,883
所以 touch 前面加个 py Python 两个字

146
00:04:29,883 --> 00:04:30,683
为研究者

147
00:04:30,683 --> 00:04:31,650
提供灵活的

148
00:04:31,650 --> 00:04:33,916
动态计算图的相关的支持

149
00:04:34,366 --> 00:04:35,650
开拓取的试机理念

150
00:04:35,650 --> 00:04:36,800
主要是 Define by run 板问

151
00:04:36,800 --> 00:04:38,850
也就是动态图机制

152
00:04:38,850 --> 00:04:39,483
这个机制

153
00:04:39,483 --> 00:04:41,883
使得它能够在处理复杂的模型

154
00:04:41,883 --> 00:04:43,283
例如 NLP 跟 GAN 的时候

155
00:04:43,283 --> 00:04:45,166
有非常显著的优势

156
00:04:45,450 --> 00:04:45,966
整体来说

157
00:04:45,966 --> 00:04:47,000
PyTorch 这些框架

158
00:04:47,000 --> 00:04:48,800
在社区贡献度来看

159
00:04:48,883 --> 00:04:51,316
吸引大量的研究者和开发者

160
00:04:51,316 --> 00:04:53,716
为社区贡献大量的三方库和套件

161
00:04:53,716 --> 00:04:54,850
例如 touch vision

162
00:04:54,850 --> 00:04:57,716
touch text 啊等相关的研究和代码

163
00:04:57,716 --> 00:04:59,516
那学术界的 cycleGAN

164
00:04:59,516 --> 00:05:02,083
Pixel to Pixel 等最新的模型哦

165
00:05:02,083 --> 00:05:04,800
也是直接去 PyTorch 来进行开发的

166
00:05:05,083 --> 00:05:07,683
那我们看一下整个 AI 框架的竞争哦

167
00:05:07,766 --> 00:05:08,483
首先

168
00:05:08,483 --> 00:05:11,316
2017 年的时候 TensorFlow 发布 1.0 版本

169
00:05:11,366 --> 00:05:13,083
引入动态图的机制

170
00:05:13,083 --> 00:05:15,450
也就是 Eeager 模式和 Keras 的 API

171
00:05:15,566 --> 00:05:16,000
进一步的

172
00:05:16,000 --> 00:05:16,850
提升

173
00:05:16,850 --> 00:05:20,483
整个 TensorFlow 框架的应用性和灵活性

174
00:05:20,516 --> 00:05:22,283
同时扩展在移动端

175
00:05:22,283 --> 00:05:24,166
和嵌入式设备的一个支持

176
00:05:24,283 --> 00:05:26,116
当时候 2017 年的时候

177
00:05:26,116 --> 00:05:29,350
还是以 TensorFlow 这个 AI 框架作为主流

178
00:05:29,350 --> 00:05:30,716
2017 年的时候

179
00:05:30,716 --> 00:05:31,450
MXNet 啊

180
00:05:31,450 --> 00:05:33,683
正式成为阿帕奇的一个孵化器

181
00:05:33,683 --> 00:05:34,283
的项目

182
00:05:34,283 --> 00:05:37,050
并且发布支持动态图的一个接口

183
00:05:37,516 --> 00:05:38,516
那同时亚马逊

184
00:05:38,516 --> 00:05:41,683
也在开始大力的去推广 MXNet 这个框架

185
00:05:41,716 --> 00:05:43,050
使得整个 MXNet

186
00:05:43,050 --> 00:05:46,366
就成为阿帕奇基金的一个顶级项目

187
00:05:46,450 --> 00:05:48,600
虽然现在整个 MXNet 框架

188
00:05:48,600 --> 00:05:50,450
已经被历史所淡忘

189
00:05:50,450 --> 00:05:51,650
也很少人去用

190
00:05:51,650 --> 00:05:52,166
不过

191
00:05:52,166 --> 00:05:55,250
2017 年的时候它还是非常的引人注目的

192
00:05:55,483 --> 00:05:56,516
整体来说呀

193
00:05:56,650 --> 00:05:59,083
PyTorch 的开源和快速的发展

194
00:05:59,083 --> 00:06:00,650
敦促我们的友商啊

195
00:06:00,650 --> 00:06:02,283
TensorFlow 啊还有 MXNet

196
00:06:02,283 --> 00:06:04,000
去引入动态图的机制

197
00:06:04,000 --> 00:06:05,083
也就一个模式

198
00:06:05,083 --> 00:06:08,000
推动整个 AI 框架的生态的发展

199
00:06:08,000 --> 00:06:09,566
所以 PyTorch 这个框架

200
00:06:09,566 --> 00:06:13,000
对整个 AI 历史的发展非常的重要

201
00:06:13,400 --> 00:06:14,966
现在我们来看看 AI 硬件

202
00:06:14,966 --> 00:06:16,366
还是 AI 相关的芯片

203
00:06:16,366 --> 00:06:17,450
2017 年的时候

204
00:06:17,450 --> 00:06:18,366
AI 硬件领域

205
00:06:18,366 --> 00:06:20,200
也取得非常重要的进展

206
00:06:20,200 --> 00:06:21,116
谷歌的 TPU

207
00:06:21,116 --> 00:06:23,600
和英伟达的 Tesla V100 的 GPU 等

208
00:06:23,600 --> 00:06:25,283
相关的专用的硬件

209
00:06:25,283 --> 00:06:26,766
开始大规模的商用

210
00:06:26,766 --> 00:06:27,766
那这些硬件

211
00:06:27,766 --> 00:06:29,283
为 AI 的训练和推理

212
00:06:29,283 --> 00:06:31,250
提供强大的计算的支持

213
00:06:31,250 --> 00:06:33,200
推动 AI 技术的广泛的应用

214
00:06:33,200 --> 00:06:34,283
那我们细数一下

215
00:06:34,366 --> 00:06:37,083
接下来 2017 年的几个月发生哪些事情

216
00:06:37,116 --> 00:06:38,800
首先 2017 年的 5 月份

217
00:06:38,800 --> 00:06:41,366
谷歌发布第二代张量处理单元

218
00:06:41,366 --> 00:06:43,883
也就是 TPU Tensor process unit

219
00:06:44,116 --> 00:06:46,450
专门为 AI 的训练和推理进行优化的

220
00:06:46,650 --> 00:06:47,600
8 月份的时候

221
00:06:47,600 --> 00:06:48,850
寒武纪科技

222
00:06:48,850 --> 00:06:51,083
完成 1 亿美元的 a 轮融资

223
00:06:51,116 --> 00:06:52,800
成为全球 AI 芯片领域的

224
00:06:52,800 --> 00:06:54,366
首个独角兽企业

225
00:06:54,683 --> 00:06:55,766
2017 年的 9 月份

226
00:06:55,766 --> 00:06:59,116
华为发布全球首款 NPU 的手机芯片

227
00:06:59,116 --> 00:07:00,566
麒麟 970 啊

228
00:07:00,566 --> 00:07:02,200
应用于 Mate 10 的

229
00:07:02,200 --> 00:07:04,966
那这个是跟寒武纪分手之后

230
00:07:04,966 --> 00:07:07,483
首款集成自己的一个 AI 芯片

231
00:07:07,683 --> 00:07:08,716
那 12 月份的时候

232
00:07:08,716 --> 00:07:12,916
英伟达推出 volta 架构的 GPU Tesla V100GPU

233
00:07:12,916 --> 00:07:16,250
进一步提升 AI 训练和推理的性能

234
00:07:16,250 --> 00:07:17,650
的同期

235
00:07:17,650 --> 00:07:19,366
2017 年英特尔

236
00:07:19,366 --> 00:07:20,966
就推出 Nervana

237
00:07:21,083 --> 00:07:22,716
整个神经网络的处理器

238
00:07:22,716 --> 00:07:24,283
我们叫 NNP 啊

239
00:07:24,316 --> 00:07:26,683
专门为深度学习进行优化的

240
00:07:26,916 --> 00:07:29,400
同年英特尔还发布 Loihi 的芯片

241
00:07:29,400 --> 00:07:31,566
采用类脑计算的架构

242
00:07:31,566 --> 00:07:35,166
能效比比 CPU 提升高达 1,000 倍

243
00:07:35,200 --> 00:07:37,200
特斯拉 CEO 埃隆马斯克

244
00:07:37,200 --> 00:07:38,566
也在 2017 年的时候

245
00:07:38,566 --> 00:07:40,316
透露公司正在开发

246
00:07:40,316 --> 00:07:43,116
专门为自动驾驶而设计的 AI 芯片

247
00:07:43,116 --> 00:07:45,916
来减少对英伟达的 GPU 的依赖

248
00:07:46,200 --> 00:07:47,716
微软在 2017 年的时候

249
00:07:47,716 --> 00:07:50,050
也宣布为它的一个 AI 设备

250
00:07:50,050 --> 00:07:51,850
开发专用的 AI 芯片

251
00:07:51,883 --> 00:07:55,000
能够实时地处理视觉和语音的任务

252
00:07:55,000 --> 00:07:57,650
减少对云端的整体的依赖

253
00:07:58,316 --> 00:07:59,766
我们现在来到最后一个内容

254
00:07:59,766 --> 00:08:02,716
看一下国内外的科技巨头对 AI

255
00:08:02,716 --> 00:08:03,683
的一个布局

256
00:08:03,766 --> 00:08:04,966
2017 年的时候

257
00:08:04,966 --> 00:08:05,716
阿里巴巴啊

258
00:08:05,716 --> 00:08:07,316
在杭州云溪大会上面

259
00:08:07,316 --> 00:08:10,166
去宣布达摩院的成立计划

260
00:08:10,166 --> 00:08:12,483
未来三年投入 1,000 亿人民币

261
00:08:12,483 --> 00:08:13,716
用于基础科学

262
00:08:13,716 --> 00:08:16,050
和颠覆性科技的一个创新研究

263
00:08:16,283 --> 00:08:18,716
这是多少 CS 跟 EE 的同学的梦

264
00:08:18,716 --> 00:08:19,916
的开始的地方啊

265
00:08:19,916 --> 00:08:20,966
也有可能

266
00:08:20,966 --> 00:08:22,050
也是日后

267
00:08:22,050 --> 00:08:24,716
达摩院陨落的一个结束的地方

268
00:08:25,116 --> 00:08:26,650
还好 18 年的时候

269
00:08:26,650 --> 00:08:29,600
ZOMI 被达摩院的十大金刚啊面挂

270
00:08:29,600 --> 00:08:31,600
因此没有机会进入达摩院

271
00:08:31,600 --> 00:08:33,050
那我们现在来细数一下

272
00:08:33,050 --> 00:08:34,400
2017 年的 2 月份

273
00:08:34,400 --> 00:08:37,766
前微软亚研的一个常务院长马维英

274
00:08:37,766 --> 00:08:39,916
就出任今日头条的副总裁

275
00:08:39,916 --> 00:08:41,083
管理 AI lap

276
00:08:41,200 --> 00:08:43,766
2017 年京东也成立 AI 的研究院

277
00:08:43,766 --> 00:08:47,116
并且在中国美国欧洲都设有办事处

278
00:08:47,600 --> 00:08:48,650
2017 年的 5 月份

279
00:08:48,650 --> 00:08:51,250
腾讯就宣布任命俞栋博士

280
00:08:51,250 --> 00:08:53,800
为作为整个腾讯的 AI 的副主任

281
00:08:53,883 --> 00:08:56,850
并且成立美国西雅图 AI 实验室

282
00:08:57,166 --> 00:08:58,966
2017 年在国外

283
00:08:58,966 --> 00:09:00,166
微软宣布

284
00:09:00,200 --> 00:09:03,516
专门去研究 AI 的研究实验室

285
00:09:03,516 --> 00:09:05,683
叫做 Microsoft research AI

286
00:09:06,116 --> 00:09:07,450
2017 年的年底啊

287
00:09:07,450 --> 00:09:11,566
谷歌就宣布在北京设立 AI 的中国中心

288
00:09:11,600 --> 00:09:12,966
李飞飞和李佳

289
00:09:12,966 --> 00:09:15,683
作为 AI 中心的一个整体的领导

290
00:09:15,716 --> 00:09:16,716
科技巨头啊

291
00:09:16,716 --> 00:09:18,050
全面的布局

292
00:09:18,050 --> 00:09:18,516
加速

293
00:09:18,516 --> 00:09:21,083
整体 AI 技术的一个商业化的落地

294
00:09:21,083 --> 00:09:22,650
推动 AI 在语音识别

295
00:09:22,650 --> 00:09:25,516
自动驾驶等相关领域的应用

296
00:09:25,883 --> 00:09:27,966
那我们可以看到 2017 年 7 月份的时候

297
00:09:27,966 --> 00:09:30,366
其实国家国务院发布

298
00:09:30,366 --> 00:09:32,400
新一代人工智能的发展规划

299
00:09:32,400 --> 00:09:34,250
提出到 2030 年

300
00:09:34,250 --> 00:09:37,000
使中国成为全球 AI 的创新中心

301
00:09:37,000 --> 00:09:39,516
并且拟定三步走的战略

302
00:09:39,516 --> 00:09:40,116
那这个

303
00:09:40,116 --> 00:09:42,716
是中国首次将 AI 的发展提到

304
00:09:42,716 --> 00:09:44,200
国家战略的后面

305
00:09:44,200 --> 00:09:44,800
每一年

306
00:09:44,800 --> 00:09:47,650
都在国家战略里面不断的去加码

307
00:09:47,650 --> 00:09:49,050
新的一个规划

308
00:09:49,050 --> 00:09:50,400
标志着整个 AI

309
00:09:50,400 --> 00:09:52,200
成为推动经济转型

310
00:09:52,200 --> 00:09:54,966
和科技创新的一个核心动力

311
00:09:55,050 --> 00:09:58,200
我们现在回顾一下 2017 年所发生的事情

312
00:09:58,333 --> 00:09:59,116
2017 年

313
00:09:59,116 --> 00:10:01,400
是 AI 技术从实验室走向商业化

314
00:10:01,400 --> 00:10:02,600
最重要的一年

315
00:10:02,600 --> 00:10:03,733
AlphaGO 的胜利

316
00:10:03,733 --> 00:10:05,650
跟国家战略的一个出台

317
00:10:05,650 --> 00:10:08,250
巨头的布局以及 AI 产品的普及

318
00:10:08,283 --> 00:10:10,966
共同推动 AI 技术的快速的发展

319
00:10:11,083 --> 00:10:14,000
那这些事件和技术的突破表明 2017 年

320
00:10:14,000 --> 00:10:15,250
人工智能领域啊

321
00:10:15,250 --> 00:10:16,200
在算法创新

322
00:10:16,200 --> 00:10:18,250
硬件加速和应用的拓展等方面

323
00:10:18,250 --> 00:10:19,916
都取得显著的进展

324
00:10:19,966 --> 00:10:20,800
那这些事件

325
00:10:20,800 --> 00:10:23,566
不仅仅改变 AI 领域的技术布局

326
00:10:23,566 --> 00:10:25,683
也深刻的影响行业

327
00:10:25,683 --> 00:10:28,850
科技巨头和社会未来的发展方向

